filepath = ./deployments/terraform/environments/development/uk_dev/020-ingress-nginx/terraform.tfvars
-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/020-ingress-nginx/variables.tf

variable "kube_context_name" {
  description = "The Kubernetes context name for Kind."
  type        = string
  default     = "kind-personae-dev"
}

variable "kubeconfig_path" {
  description = "Optional path to kubeconfig YAML file."
  type        = string
  default     = null # If null, a default single-node cluster is created
}

variable "ingress_nginx_dev_namespace" { // Renamed for clarity and consistency
  description = "Namespace for Nginx Ingress in dev."
  type        = string
  default     = "ingress-nginx"
}

variable "ingress_nginx_dev_chart_version" { // Renamed
  description = "Helm chart version for Nginx Ingress in dev."
  type        = string
  default     = "4.10.1"
}

variable "ingress_nginx_dev_http_node_port" {
  description = "NodePort for HTTP for Nginx Ingress in dev."
  type        = number
  default     = 30080
}

variable "ingress_nginx_dev_https_node_port" {
  description = "NodePort for HTTPS for Nginx Ingress in dev."
  type        = number
  default     = 30443
}

-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/020-ingress-nginx/providers.tf
provider "kubernetes" {
  config_path    = "~/.kube/config"
  config_context = var.kube_context_name
}

provider "helm" {
  kubernetes {
    config_path    = "~/.kube/config"
    config_context = var.kube_context_name
  }
}-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/020-ingress-nginx/main.tf

module "nginx_ingress_dev" {
  source = "../../../../modules/nginx_ingress"

  ingress_namespace    = var.ingress_nginx_dev_namespace
  helm_chart_version   = var.ingress_nginx_dev_chart_version
  create_namespace     = true # Let the module create the namespace

  # For Kind, you usually don't need custom values unless you want specific NodePorts
  # or to disable LoadBalancer service type (which isn't typically used with Kind directly).
  # The module default of NodePort service type for the controller is fine for Kind.
  helm_values_content = yamlencode({
    controller = {
      kind = "Deployment" # DaemonSet is fine too, Deployment is often simpler for local Kind
      replicaCount = 1
      service = {
        type = "NodePort" # Exposes on NodePorts
        nodePorts = {
          http = var.ingress_nginx_dev_http_node_port
          https = var.ingress_nginx_dev_https_node_port
        }
      }
      # Disable admission webhooks for simpler Kind setup if they cause issues.
      admissionWebhooks = {
         enabled = false
      }
    }
  })
}
-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/020-ingress-nginx/outputs.tf

output "http_node_port" {
  description = "HTTP NodePort for the Nginx Ingress controller in dev."
  value       = var.ingress_nginx_dev_http_node_port
}
output "https_node_port" {
  description = "HTTPS NodePort for the Nginx Ingress controller in dev."
  value       = var.ingress_nginx_dev_https_node_port
}
output "namespace" {
  description = "Namespace of the Nginx Ingress controller in dev."
  value       = module.nginx_ingress_dev.namespace // Assuming your module outputs this
}-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/070-database-schemas/variables.tf
# No variables needed for this layer as all values are derived from remote state.-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/070-database-schemas/providers.tf
terraform {
  required_providers {
    postgresql = {
      source  = "cyrilgdn/postgresql"
      version = "~> 1.20.0"
    }
    mysql = {
      source  = "drarko/mysql"
      version = "2.0.0"
    }
    null = {
      source  = "hashicorp/null"
      version = "~> 3.2.1"
    }
  }
}-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/070-database-schemas/main.tf
terraform {
  required_providers {
    postgresql = {
      source  = "cyrilgdn/postgresql"
      version = "~> 1.20.0"
    }
    mysql = {
      source  = "drarko/mysql"
      version = "2.0.0"
    }
    null = {
      source = "hashicorp/null"
      version = "~> 3.2.1"
    }
  }

  backend "kubernetes" {
    secret_suffix = "tfstate-db-schemas-dev"
    config_path   = "~/.kube/config"
  }
}

# Read the outputs from the dev database creation layer
data "terraform_remote_state" "databases_dev" {
  backend = "kubernetes"
  config = {
    secret_suffix = "tfstate-databases-dev"
    config_path   = "~/.kube/config"
  }
}

# --- MySQL Provider ---
provider "mysql" {
  endpoint = "${data.terraform_remote_state.databases_dev.outputs.external_mysql_host}:3306"
  username = "auth_user_dev"
  password = data.terraform_remote_state.databases_dev.outputs.external_mysql_password
}

# --- Apply PostgreSQL Schemas ---
# Read the SQL file for the pgvector extension
data "local_file" "pgvector_sql" {
  filename = "${path.module}/../../../../sql/001_enable_pgvector.sql"
}

# Apply the pgvector schema using a local psql command
resource "null_resource" "pgvector_extension_dev" {
  # Trigger a re-run if the SQL file content changes
  triggers = {
    content_sha1 = sha1(data.local_file.pgvector_sql.content)
  }

  provisioner "local-exec" {
    # This command uses the psql client to run the schema.
    # It securely passes the password via the PGPASSWORD environment variable.
    command = "psql -h ${data.terraform_remote_state.databases_dev.outputs.postgres_clients_db_dev_service_endpoint} -U clients_user_dev -d clientsdb_dev -f ${data.local_file.pgvector_sql.filename}"

    environment = {
      PGPASSWORD = data.terraform_remote_state.databases_dev.outputs.clients_db_password
    }
  }
}

# --- Apply MySQL Schema ---
# Read the SQL file for the auth service database schema
data "local_file" "auth_db_schema" {
  filename = "${path.module}/../../../../sql/auth_schema.sql"
}

# Apply the schema to the external dev database using the mysql_script resource
resource "mysql_script" "auth_db_schema_apply" {
  database = "authservicedb_dev"
  script_path = data.local_file.auth_db_schema.filename

  # This ensures the database is created if it doesn't exist before running the script
  depends_on = [
    resource.mysql_database.auth_db_from_schema
  ]
}

resource "mysql_database" "auth_db_from_schema" {
  name = "authservicedb_dev"
  default_character_set = "utf8mb4"
  default_collation     = "utf8mb4_unicode_ci"
}-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/070-database-schemas/outputs.tf
output "pgvector_extension_status" {
  description = "Status of the pgvector extension application on the dev clients database."
  value       = "Applied"
  depends_on  = [postgresql_query.pgvector_extension_dev]
}-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/080-kafka-topics/variables.tf
variable "platform_topics" {
  description = "A list of Kafka topic names to be created for the application."
  type        = list(string)
  default = [
    # System & Orchestration Topics
    "system.commands.workflow.resume",
    "system.events.workflow.paused",
    "system.events.workflow.completed",

    # Core Service Topics
    "requests.auth.user.create",
    "events.auth.user.created",

    # Agent Communication Topics
    "requests.agent.task.execute",
    "events.agent.task.completed",
    "events.agent.task.failed",
    "events.agent.task.progress",

    # Specialized Agent Topics
    "requests.agent.reasoning",
    "requests.agent.web-search",
    "requests.agent.image-generation",
  ]
}

variable "default_partitions" {
  description = "Default number of partitions for development topics."
  type        = number
  default     = 1
}

variable "default_replication_factor" {
  description = "Default replication factor for development topics. Should be 1 for a single-broker dev cluster."
  type        = number
  default     = 1
}-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/080-kafka-topics/main.tf
terraform {
  required_providers {
    kafka = {
      source  = "mongey/kafka"
      version = "~> 0.11.0"
    }
  }
  backend "kubernetes" {
    secret_suffix = "tfstate-kafka-topics-dev"
    config_path   = "~/.kube/config"
  }
}

# Read the outputs from the dev Kafka cluster layer
data "terraform_remote_state" "kafka_cluster_dev" {
  backend = "kubernetes"
  config = {
    # This suffix must match the backend config of your dev 040-kafka-cluster layer
    secret_suffix = "tfstate-kafka-cluster-dev"
    config_path   = "~/.kube/config"
  }
}

provider "kafka" {
  bootstrap_servers = data.terraform_remote_state.kafka_cluster_dev.outputs.kafka_bootstrap_servers
}

# Define all required Kafka topics for the platform
resource "kafka_topic" "topics_dev" {
  for_each = toset(var.platform_topics)

  name               = each.key
  partitions         = var.default_partitions
  replication_factor = var.default_replication_factor
  config = {
    "retention.ms" = "604800000" # Retain messages for 7 days in dev
  }
}-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/080-kafka-topics/outputs.tf
output "topic_names" {
  description = "The names of the created Kafka topics for the development environment."
  value       = [for topic in kafka_topic.topics_dev : topic.name]
}-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/010-infrastructure/terraform.tfvars
-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/010-infrastructure/variables.tf
variable "kind_cluster_name" {
  description = "Name for the Kind cluster for development."
  type        = string
  default     = "personae-dev"
}

variable "kind_node_image" {
  description = "Node image for Kind cluster (e.g., kindest/node:v1.27.3)."
  type        = string
  default     = "kindest/node:v1.27.3" # Choose a version
}

variable "kind_config_path" {
  description = "Optional path to a Kind configuration YAML file."
  type        = string
  default     = null # If null, a default single-node cluster is created
}

variable "kubeconfig_path" {
  description = "Optional path to kubeconfig YAML file."
  type        = string
  default     = null # If null, a default single-node cluster is created
}

# This output is not directly from a resource, but reflects the context name
# that will be used by other components.
variable "kube_context_name" {
  description = "The kubectl context name to use for this Kind cluster."
  type        = string
  default     = "kind-personae-dev" # Must match KIND_CONTEXT_DEV in Makefile
}
-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/010-infrastructure/providers.tf
terraform {
  required_providers {
    null = {
      source  = "hashicorp/null"
      version = "~> 3.2.1"
    }
  }
}-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/010-infrastructure/main.tf
resource "null_resource" "kind_cluster" {
  triggers = {
    cluster_name = var.kind_cluster_name
    config_path  = var.kind_config_path
    node_image   = var.kind_node_image
  }

  provisioner "local-exec" {
    when    = create
    command = <<-EOT
      set -e
      if ! kind get clusters | grep -q "^${self.triggers.cluster_name}$$"; then
        echo "Creating Kind cluster '${self.triggers.cluster_name}'..."
        kind create cluster --name "${self.triggers.cluster_name}" --image "${self.triggers.node_image}" ${var.kind_config_path != null ? "--config \"${var.kind_config_path}\"" : ""}
        echo "Waiting for Kind cluster control plane to be ready..."
        timeout 120s bash -c 'while ! kubectl --context="kind-${self.triggers.cluster_name}" cluster-info >/dev/null 2>&1; do sleep 1; done' || \
          (echo "Timeout waiting for Kind cluster. Check 'kind get logs ${self.triggers.cluster_name}'" && exit 1)
        echo "Kind cluster '${self.triggers.cluster_name}' is ready."
      else
        echo "Kind cluster '${self.triggers.cluster_name}' already exists. Skipping creation."
      fi
    EOT
  }

  provisioner "local-exec" {
    when    = destroy
    # Use self.triggers.cluster_name which is known at destroy time based on the state
    command = "kind delete cluster --name \"${self.triggers.cluster_name}\" || true"
  }
}

resource "null_resource" "label_kind_node" {
  depends_on = [null_resource.kind_cluster]

  provisioner "local-exec" {
    command = <<-EOT
      # Wait for the node to be ready
      kubectl wait --for=condition=ready node --all --timeout=60s

      # Label the node
      kubectl label nodes --all role=spot-instance --overwrite
    EOT
  }
}-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/010-infrastructure/outputs.tf
output "kind_cluster_name_output" {
  description = "Name of the Kind cluster."
  value       = var.kind_cluster_name
}

output "kind_kube_context_name_output" {
  description = "The kubectl context name for this Kind cluster."
  value       = "kind-${var.kind_cluster_name}" # Standard Kind context naming
}

# No kubeconfig_raw output here as Kind manages the default kubeconfig file.
# Other components will use the context name.-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/090-monitoring/variables.tf
variable "monitoring_namespace" {
  description = "The Kubernetes namespace to deploy the dev monitoring stack into."
  type        = string
  default     = "monitoring-dev"
}

variable "grafana_admin_password" {
  description = "The admin password for the Grafana dashboard."
  type        = string
  sensitive   = true
}-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/090-monitoring/main.tf
terraform {
  required_providers {
    helm = {
      source  = "hashicorp/helm"
      version = "~> 2.11.0"
    }
    kubernetes = {
      source  = "hashicorp/kubernetes"
      version = "~> 2.20"
    }
  }
  backend "kubernetes" {
    secret_suffix = "tfstate-monitoring-dev"
    config_path   = "~/.kube/config"
  }
}

data "helm_repository" "prometheus_community" {
  name = "prometheus-community"
  url  = "https://prometheus-community.github.io/helm-charts"
}

resource "kubernetes_namespace" "monitoring_ns_dev" {
  metadata {
    name = var.monitoring_namespace
  }
}

resource "helm_release" "prometheus_stack_dev" {
  name       = "prometheus-stack-dev"
  repository = data.helm_repository.prometheus_community.metadata[0].name
  chart      = "kube-prometheus-stack"
  namespace  = kubernetes_namespace.monitoring_ns_dev.metadata[0].name
  version    = "51.8.0" # Pin to the same chart version as production

  values = [
    templatefile("${path.module}/values.yaml.tpl", {
      grafana_admin_password = var.grafana_admin_password
    })
  ]

  depends_on = [kubernetes_namespace.monitoring_ns_dev]
}-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/090-monitoring/values.yaml.tpl
# values.yaml.tpl for development
# This configuration is lightweight and suitable for local clusters.

# Grafana configuration
grafana:
  adminPassword: "${grafana_admin_password}"
  # For dev, we use ClusterIP and access via `kubectl port-forward`
  service:
    type: ClusterIP

# Prometheus configuration
prometheus:
  prometheusSpec:
    # Disable persistent storage for development to keep it lightweight
    storageSpec: {}
    retention: 1d # Lower retention for dev-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/090-monitoring/outputs.tf
-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/050-storage/variables.tf
variable "region" {
  description = "The region where resources will be deployed."
  type        = string
  default     = "uk-dev"
}

variable "image_bucket_name" {
  description = "Name for the bucket to store generated images for development."
  type        = string
  default     = "personae-dev-uk-images"
}

variable "site_assets_bucket_name" {
  description = "Name for the bucket to store generated static site assets for development."
  type        = string
  default     = "personae-dev-uk-site-assets"
}

variable "b2_application_key_id" {
  description = "The application key ID for Backblaze B2."
  type        = string
  sensitive   = true
}

variable "b2_application_key" {
  description = "The application key for Backblaze B2."
  type        = string
  sensitive   = true
}-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/050-storage/main.tf
terraform {
  backend "kubernetes" {
    secret_suffix = "tfstate-storage-dev"
    config_path   = "~/.kube/config"
  }
}

provider "b2" {
  application_key_id = var.b2_application_key_id
  application_key    = var.b2_application_key
}

module "storage_buckets_dev" {
  source = "../../../../modules/s3-buckets"

  bucket_names = [
    var.image_bucket_name,
    var.site_assets_bucket_name
  ]

  tags = {
    environment = "development"
    region      = var.region
    managed_by  = "terraform"
  }
}-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/060-databases/variables.tf
variable "k8s_namespace" {
  description = "The Kubernetes namespace to deploy dev database resources into."
  type        = string
  default     = "personae-dev-db"
}

variable "postgres_storage_class" {
  description = "The name of the StorageClass for dev PostgreSQL volumes (e.g., your local-path-provisioner)."
  type        = string
  default     = "standard"
}

# --- External MySQL Variables ---
variable "external_mysql_host" {
  description = "The endpoint for the external MySQL database used for development."
  type        = string
  sensitive   = true
}

variable "external_mysql_password" {
  description = "Password for the external MySQL database."
  type        = string
  sensitive   = true
}

# --- In-Cluster PostgreSQL Variables ---
variable "templates_db_password" {
  description = "Password for the dev templates PostgreSQL database."
  type        = string
  sensitive   = true
}

variable "clients_db_password" {
  description = "Password for the dev clients PostgreSQL database."
  type        = string
  sensitive   = true
}-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/060-databases/main.tf
terraform {
  backend "kubernetes" {
    secret_suffix = "tfstate-databases-dev"
    config_path   = "~/.kube/config"
  }
}

# --- External MySQL Secret ---
module "external_mysql_auth_db_dev" {
  source = "../../../../modules/mysql-instance"

  instance_name = "personae-dev-uk-auth-db"
  namespace     = var.k8s_namespace
  db_host       = var.external_mysql_host
  database_name = "authservicedb_dev"
  database_user = "auth_user_dev"
  database_pass = var.external_mysql_password
}

# --- In-Cluster PostgreSQL for Templates ---
module "postgres_templates_db_dev" {
  source = "../../../../modules/postgres-instance"

  instance_name      = "postgres-templates-dev"
  namespace          = var.k8s_namespace
  database_name      = "templatesdb_dev"
  database_user      = "templates_user_dev"
  database_pass      = var.templates_db_password
  storage_class_name = var.postgres_storage_class
  storage_size       = "2Gi" # Smaller size for dev
}

# --- In-Cluster PostgreSQL for Client Data ---
module "postgres_clients_db_dev" {
  source = "../../../../modules/postgres-instance"

  instance_name      = "postgres-clients-dev"
  namespace          = var.k8s_namespace
  database_name      = "clientsdb_dev"
  database_user      = "clients_user_dev"
  database_pass      = var.clients_db_password
  storage_class_name = var.postgres_storage_class
  storage_size       = "5Gi" # Smaller size for dev
}-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/030-strimzi-operator/terraform.tfvars
-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/030-strimzi-operator/variables.tf
variable "kube_context_name" {
  description = "The Kubernetes context name for Kind."
  type        = string
  default = "kind-personae-dev"
}

variable "kubeconfig_path" {
  description = "Optional path to kubeconfig YAML file."
  type        = string
  default     = null # If null, a default single-node cluster is created
}

variable "strimzi_operator_dev_namespace" {
  description = "Namespace for the Strimzi operator in dev."
  type        = string
  default     = "strimzi" // Operator's own namespace
}

variable "watched_namespaces_dev" {
  description = "List of namespaces for the Strimzi operator to watch in dev."
  type        = list(string)
  default     = ["kafka", "personae"] // Strimzi will watch 'kafka' for Kafka CRs and 'personae' if KafkaUsers are there
}

variable "strimzi_yaml_bundle_path_dev" {
  description = "Path to the Strimzi YAML files directory for dev."
  type        = string
  # Path relative to this file's directory, pointing to the module's shared Strimzi YAMLs
  default     = "../../../../modules/strimzi_operator/strimzi-yaml-0.45.0/"
}

variable "strimzi_operator_deployment_yaml_filename_dev" {
description = "Filename of the main operator deployment YAML."
type        = string
default     = "060-Deployment-strimzi-cluster-operator.yaml"
}-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/030-strimzi-operator/providers.tf
provider "kubernetes" {
  config_path    = "~/.kube/config"
  config_context = var.kube_context_name
}

provider "null" {} // If your module uses null_resource-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/030-strimzi-operator/main.tf
# Ensure the namespaces Strimzi will operate in or watch exist.
# Strimzi operator's own namespace:
resource "kubernetes_namespace" "operator_ns" {
  metadata {
    name = var.strimzi_operator_dev_namespace // e.g., "strimzi"
  }
}

# Namespace for Kafka clusters (watched by Strimzi):
resource "kubernetes_namespace" "kafka_cluster_ns" {
  metadata {
    name = "kafka" // Assuming Kafka CRs will be in 'kafka' namespace
  }
}

# Namespace for Personae app (if Strimzi needs to manage KafkaUsers there):
resource "kubernetes_namespace" "personae_app_ns" {
  metadata {
    name = "personae" // Assuming Personae app and potentially KafkaUsers are in 'personae'
  }
}

module "strimzi_operator" {
  source = "../../../../modules/strimzi_operator"

  operator_namespace                = kubernetes_namespace.operator_ns.metadata[0].name
  watched_namespaces_list           = var.watched_namespaces_dev
  strimzi_yaml_source_path          = var.strimzi_yaml_bundle_path_dev
  operator_deployment_yaml_filename = var.strimzi_operator_deployment_yaml_filename_dev
  cluster_kubeconfig_path           = "" # Path to the kubeconfig Terraform should use

  depends_on = [
    kubernetes_namespace.operator_ns,
    kubernetes_namespace.kafka_cluster_ns,
    kubernetes_namespace.personae_app_ns
  ]
}-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/030-strimzi-operator/strimzi-rbac-terraform.tf
resource "kubernetes_cluster_role" "strimzi_kafka_namespace" {
  metadata {
    name = "strimzi-cluster-operator-kafka-namespace"
  }

  rule {
    api_groups = [""]
    resources  = ["pods", "services", "endpoints", "persistentvolumeclaims", "configmaps", "secrets", "serviceaccounts"]
    verbs      = ["get", "list", "watch", "create", "update", "patch", "delete"]
  }

  rule {
    api_groups = ["apps"]
    resources  = ["deployments", "statefulsets", "replicasets"]
    verbs      = ["get", "list", "watch", "create", "update", "patch", "delete"]
  }

  rule {
    api_groups = ["networking.k8s.io"]
    resources  = ["ingresses", "networkpolicies"]
    verbs      = ["get", "list", "watch", "create", "update", "patch", "delete"]
  }

  rule {
    api_groups = ["kafka.strimzi.io"]
    resources  = ["*"]
    verbs      = ["*"]
  }

  rule {
    api_groups = ["core.strimzi.io"]
    resources  = ["*"]
    verbs      = ["*"]
  }

  rule {
    api_groups = ["rbac.authorization.k8s.io"]
    resources  = ["roles", "rolebindings"]
    verbs      = ["get", "list", "watch", "create", "update", "patch", "delete"]
  }

  rule {
    api_groups = ["policy"]
    resources  = ["poddisruptionbudgets"]
    verbs      = ["get", "list", "watch", "create", "update", "patch", "delete"]
  }
}

resource "kubernetes_cluster_role_binding" "strimzi_kafka_namespace" {
  metadata {
    name = "strimzi-cluster-operator-kafka-namespace"
  }

  role_ref {
    api_group = "rbac.authorization.k8s.io"
    kind      = "ClusterRole"
    name      = kubernetes_cluster_role.strimzi_kafka_namespace.metadata[0].name
  }

  subject {
    kind      = "ServiceAccount"
    name      = "strimzi-cluster-operator"
    namespace = "strimzi"
  }
}

resource "kubernetes_role_binding" "strimzi_kafka_namespace" {
  metadata {
    name      = "strimzi-cluster-operator-kafka-namespace"
    namespace = "kafka"
  }

  role_ref {
    api_group = "rbac.authorization.k8s.io"
    kind      = "ClusterRole"
    name      = kubernetes_cluster_role.strimzi_kafka_namespace.metadata[0].name
  }

  subject {
    kind      = "ServiceAccount"
    name      = "strimzi-cluster-operator"
    namespace = "strimzi"
  }
}

resource "kubernetes_cluster_role_binding" "strimzi_entity_operator_delegation" {
  metadata {
    name = "strimzi-cluster-operator-entity-operator-delegation"
    labels = {
      app = "strimzi"
    }
  }

  role_ref {
    api_group = "rbac.authorization.k8s.io"
    kind      = "ClusterRole"
    name      = "strimzi-entity-operator"
  }

  subject {
    kind      = "ServiceAccount"
    name      = "strimzi-cluster-operator"
    namespace = "strimzi"
  }
}-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/030-strimzi-operator/outputs.tf
output "operator_namespace_used" {
  description = "Namespace where the Strimzi operator was deployed for dev."
  value       = module.strimzi_operator.operator_namespace_used
}

output "watched_namespaces_configured" {
  description = "Namespaces the Strimzi operator is configured to watch for dev."
  value       = module.strimzi_operator.watched_namespaces_configured
}-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/040-kafka-cluster/terraform.tfvars
-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/040-kafka-cluster/variables.tf
variable "kube_context_name" {
  description = "The Kubernetes context name for Kind (e.g., kind-personae-dev)."
  type        = string
  default     = "kind-personae-dev"
}

variable "kubeconfig_path" { // Specific name for this component's var
  description = "Path to the kubeconfig file to be used for this dev component."
  type        = string
  default     = "~/.kube/config" // Default for Kind, overridden by Makefile if necessary
}

variable "kafka_namespace_dev" {
  description = "Namespace where the Kafka CR for dev will be deployed."
  type        = string
  default     = "kafka"
}

variable "kafka_cluster_cr_yaml_path_dev" {
  description = "Path to the Kafka CR YAML file for the dev instance."
  type        = string
  default     = "../../../../modules/kafka_cluster/config/kafka-cluster-cr-dev.yaml" // Point to your DEV version
}

variable "kafka_cluster_name_dev" {
  description = "The metadata.name of the Kafka cluster for dev."
  type        = string
  default     = "personae-kafka-cluster" // Should match the name in kafka-cluster-cr-dev.yaml
}-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/040-kafka-cluster/providers.tf
provider "kubernetes" {
  config_path    = abspath(pathexpand(var.kubeconfig_path_for_dev))
  config_context = var.kube_context_name
}

provider "helm" {
  kubernetes {
    config_path    = abspath(pathexpand(var.kubeconfig_path_for_dev))
    config_context = var.kube_context_name
  }
}
provider "null" {}-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/040-kafka-cluster/main.tf
module "kafka_cluster_dev" {
  source = "../../../../modules/kafka_cluster"

  kubeconfig_path         = abspath(pathexpand(var.kubeconfig_path))
  kube_context_name       = var.kube_context_name    // Pass the dev context name
  kafka_cr_namespace      = var.kafka_namespace_dev
  kafka_cr_yaml_file_path = var.kafka_cluster_cr_yaml_path_dev
  kafka_cr_cluster_name   = var.kafka_cluster_name_dev
}-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/040-kafka-cluster/outputs.tf
output "dev_kafka_cluster_name" {
  description = "Name of the Kafka cluster deployed in dev."
  value       = module.kafka_cluster_dev.cluster_name_applied
}

output "dev_kafka_cluster_namespace" {
  description = "Namespace of the Kafka cluster in dev."
  value       = module.kafka_cluster_dev.cluster_namespace_applied
}

output "dev_kafka_bootstrap_servers_plain" {
  description = "Internal Plaintext Bootstrap Servers for dev Kafka."
  value       = module.kafka_cluster_dev.bootstrap_servers_plain
}

output "dev_kafka_bootstrap_servers_tls" {
  description = "Internal TLS Bootstrap Servers for dev Kafka."
  value       = module.kafka_cluster_dev.bootstrap_servers_tls
}-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/services/agents/2230-web-search-adapter/terraform.tfvars
-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/services/agents/2230-web-search-adapter/variables.tf
# No vari# No variables needed as the path is static for this service definition.ables needed as the path is static for this service definition.-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/services/agents/2230-web-search-adapter/main.tf
terraform {
  backend "kubernetes" {
    secret_suffix = "tfstate-svc-web-search-adapter-dev"
    config_path   = "~/.kube/config"
  }
}

module "web_search_adapter_deployment_dev" {
  source = "../../../../../modules/kustomize-apply"

  # Path to the DEVELOPMENT overlay for this service
  kustomize_path = "../../../../../deployments/kustomize/services/web-search-adapter/overlays/development"
}-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/services/agents/2230-web-search-adapter/outputs.tf
output "kustomize_apply_status" {
  description = "The status of the Kustomize deployment for the development web-search-adapter."
  value       = module.web_search_adapter_deployment_dev.status
}-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/services/agents/2210-agent-chassis/terraform.tfvars
-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/services/agents/2210-agent-chassis/variables.tf
# No# No variables needed as the path is static for this service definition. variables needed as the path is static for this service definition.-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/services/agents/2210-agent-chassis/main.tf
terraform {
  backend "kubernetes" {
    secret_suffix = "tfstate-svc-agent-chassis-dev"
    config_path   = "~/.kube/config"
  }
}

module "agent_chassis_deployment_dev" {
  source = "../../../../../modules/kustomize-apply"

  # Path to the DEVELOPMENT overlay for this service
  kustomize_path = "../../../../../deployments/kustomize/services/agent-chassis/overlays/development"
}-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/services/agents/2210-agent-chassis/outputs.tf
output "kustomize_apply_status" {
  description = "The status of the Kustomize deployment for the development agent-chassis."
  value       = module.agent_chassis_deployment_dev.status
}-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/services/agents/2240-image-generator-adapter/terraform.tfvars
-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/services/agents/2240-image-generator-adapter/variables.tf
# No variables needed as the path is static for this service definition.-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/services/agents/2240-image-generator-adapter/main.tf
terraform {
  backend "kubernetes" {
    secret_suffix = "tfstate-svc-image-generator-adapter-dev"
    config_path   = "~/.kube/config"
  }
}

module "image_generator_adapter_deployment_dev" {
  source = "../../../../../modules/kustomize-apply"

  # Path to the DEVELOPMENT overlay for this service
  kustomize_path = "../../../../../deployments/kustomize/services/image-generator-adapter/overlays/development"
}-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/services/agents/2240-image-generator-adapter/outputs.tf
output "kustomize_apply_status" {
  description = "The status of the Kustomize deployment for the development image-generator-adapter."
  value       = module.image_generator_adapter_deployment_dev.status
}-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/services/agents/2220-reasoning-agent/terraform.tfvars
-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/services/agents/2220-reasoning-agent/variables.tf
# No variables nee# No variables needed as the path is static for this service definition.ded as the path is static for this service definition.-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/services/agents/2220-reasoning-agent/main.tf
terraform {
  backend "kubernetes" {
    secret_suffix = "tfstate-svc-reasoning-agent-dev"
    config_path   = "~/.kube/config"
  }
}

module "reasoning_agent_deployment_dev" {
  source = "../../../../../modules/kustomize-apply"

  # Path to the DEVELOPMENT overlay for this service
  kustomize_path = "../../../../../deployments/kustomize/services/reasoning-agent/overlays/development"
}-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/services/agents/2220-reasoning-agent/outputs.tf
output "kustomize_apply_status" {
  description = "The status of the Kustomize deployment for the development reasoning-agent."
  value       = module.reasoning_agent_deployment_dev.status
}-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/services/frontends/3330-agent-playground/terraform.tfvars
-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/services/frontends/3330-agent-playground/variables.tf
-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/services/frontends/3330-agent-playground/main.tf
-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/services/frontends/3330-agent-playground/outputs.tf
-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/services/frontends/3320-user-portal/terraform.tfvars
-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/services/frontends/3320-user-portal/variables.tf
-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/services/frontends/3320-user-portal/main.tf
# This instance deploys the main user-facing React application.
module "user_frontend_app" {
  source = "../../../../../../modules/kustomize-apply"

  service_name     = "user-frontend"
  namespace        = "personae-system"
  image_repository = "aqls/personae-web-interface" # Your frontend image
  image_tag        = var.image_tag

  # Point to the production Kustomize overlay for the frontend.
  # This directory would contain the deployment.yaml, service.yaml, ingress.yaml, etc.
  kustomize_path = "../../../../../../../deployments/kustomize/frontends/user-frontend/overlays/production"
}
-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/services/frontends/3320-user-portal/outputs.tf
-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/services/frontends/3310-admin-dashboard/terraform.tfvars
-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/services/frontends/3310-admin-dashboard/variables.tf
-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/services/frontends/3310-admin-dashboard/main.tf
-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/services/frontends/3310-admin-dashboard/outputs.tf
-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/services/core-platform/1120-core-manager/terraform.tfvars
-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/services/core-platform/1120-core-manager/variables.tf
# No variables needed as the path is static for this service definition.-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/services/core-platform/1120-core-manager/main.tf
terraform {
  backend "kubernetes" {
    secret_suffix = "tfstate-svc-core-manager-dev"
    config_path   = "~/.kube/config"
  }
}

module "core_manager_deployment_dev" {
  source = "../../../../../modules/kustomize-apply"

  # Path to the DEVELOPMENT overlay for this service
  kustomize_path = "../../../../../deployments/kustomize/services/core-manager/overlays/development"
}-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/services/core-platform/1120-core-manager/outputs.tf
output "kustomize_apply_status" {
  description = "The status of the Kustomize deployment for the development core-manager."
  value       = module.core_manager_deployment_dev.status
}-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/services/core-platform/1110-auth-service/terraform.tfvars
-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/services/core-platform/1110-auth-service/variables.tf
# No variables needed as the path is static for this service definition.-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/services/core-platform/1110-auth-service/main.tf
terraform {
  backend "kubernetes" {
    secret_suffix = "tfstate-svc-auth-dev"
    config_path   = "~/.kube/config"
  }
}

module "auth_service_deployment_dev" {
  source = "../../../../../modules/kustomize-apply"

  # Path to the DEVELOPMENT overlay for this service
  kustomize_path = "../../../../../deployments/kustomize/services/auth-service/overlays/development"
}-------------------------------------------------
filepath = ./deployments/terraform/environments/development/uk_dev/services/core-platform/1110-auth-service/outputs.tf
output "kustomize_apply_status" {
  description = "The status of the Kustomize deployment for the development auth-service."
  value       = module.auth_service_deployment_dev.status
}-------------------------------------------------
filepath = ./deployments/terraform/environments/development/local/terraform.tfvars
-------------------------------------------------
filepath = ./deployments/terraform/environments/development/local/main.tf
-------------------------------------------------
