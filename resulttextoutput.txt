filepath = ./makefile
# AI Persona System - Setup Scripts

## 1. Makefile

```makefile
# FILE: Makefile
.PHONY: all build push deploy clean test dev setup

REGISTRY ?= ai-persona-system
VERSION ?= latest

# Services
SERVICES = auth-service core-manager agent-chassis reasoning-agent image-generator-adapter web-search-adapter

# Default target
all: build deploy

# Build all Docker images
build:
	@echo "🔨 Building Docker images..."
	@for service in $(SERVICES); do \
		echo "Building $$service..."; \
		docker build -f cmd/$$service/Dockerfile -t $(REGISTRY)/$$service:$(VERSION) . || exit 1; \
	done
	@echo "✅ All images built successfully"

# Push all images to registry
push:
	@echo "📤 Pushing images to registry..."
	@for service in $(SERVICES); do \
		echo "Pushing $$service..."; \
		docker push $(REGISTRY)/$$service:$(VERSION) || exit 1; \
	done
	@echo "✅ All images pushed successfully"

# Deploy to Kubernetes
deploy:
	@echo "🚀 Deploying to Kubernetes..."
	kubectl apply -f k8s/namespace.yaml
	kubectl apply -f k8s/configmap-common.yaml
	kubectl apply -f k8s/postgres-clients.yaml
	kubectl apply -f k8s/postgres-templates.yaml
	kubectl apply -f k8s/mysql-auth.yaml
	kubectl apply -f k8s/kafka.yaml
	kubectl apply -f k8s/minio.yaml
	@echo "⏳ Waiting for infrastructure to be ready..."
	kubectl wait --for=condition=ready pod -l app=postgres-clients -n ai-persona-system --timeout=300s
	kubectl wait --for=condition=ready pod -l app=postgres-templates -n ai-persona-system --timeout=300s
	kubectl wait --for=condition=ready pod -l app=mysql-auth -n ai-persona-system --timeout=300s
	kubectl apply -f k8s/auth-service.yaml
	kubectl apply -f k8s/core-manager.yaml
	kubectl apply -f k8s/agent-chassis.yaml
	kubectl apply -f k8s/reasoning-agent.yaml
	kubectl apply -f k8s/image-generator-adapter.yaml
	kubectl apply -f k8s/monitoring/
	@echo "✅ Deployment complete"

# Initial setup (creates secrets and runs migrations)
setup:
	@echo "🚀 Running initial setup..."
	@chmod +x scripts/setup.sh
	@./scripts/setup.sh

# Run tests
test:
	@echo "🧪 Running unit tests..."
	go test -v ./...

# Run integration tests
test-integration:
	@echo "🧪 Running integration tests..."
	go test -v -tags=integration ./tests/integration/

# Local development with docker-compose
dev:
	@echo "🐳 Starting local development environment..."
	docker-compose up -d
	@echo "✅ Local environment started"
	@echo "Services available at:"
	@echo "  - Auth Service: http://localhost:8081"
	@echo "  - Core Manager: http://localhost:8088"

# Clean up everything
clean:
	@echo "🧹 Cleaning up..."
	docker-compose down -v || true
	kubectl delete namespace ai-persona-system --ignore-not-found=true || true
	@echo "✅ Cleanup complete"

# Database migrations
migrate-up:
	@echo "📝 Running database migrations..."
	@kubectl cp platform/database/migrations/001_enable_pgvector.sql ai-persona-system/postgres-clients-0:/tmp/
	@kubectl cp platform/database/migrations/002_create_templates_schema.sql ai-persona-system/postgres-templates-0:/tmp/
	@kubectl cp platform/database/migrations/003_create_client_schema.sql ai-persona-system/postgres-clients-0:/tmp/
	@kubectl cp platform/database/migrations/004_auth_schema.sql ai-persona-system/mysql-auth-0:/tmp/
	@kubectl exec -n ai-persona-system postgres-clients-0 -- psql -U clients_user -d clients_db -f /tmp/001_enable_pgvector.sql
	@kubectl exec -n ai-persona-system postgres-templates-0 -- psql -U templates_user -d templates_db -f /tmp/002_create_templates_schema.sql
	@kubectl exec -n ai-persona-system mysql-auth-0 -- mysql -u auth_user -p$$AUTH_DB_PASSWORD auth_db < /tmp/004_auth_schema.sql
	@echo "✅ Migrations complete"

# Create a new client schema
create-client:
	@read -p "Enter client ID: " client_id; \
	kubectl exec -n ai-persona-system postgres-clients-0 -- \
		psql -U clients_user -d clients_db -c "CREATE SCHEMA IF NOT EXISTS client_$$client_id"; \
	sed "s/{client_id}/$$client_id/g" platform/database/migrations/003_create_client_schema.sql | \
	kubectl exec -i -n ai-persona-system postgres-clients-0 -- \
		psql -U clients_user -d clients_db

# Port forwarding for local development
port-forward:
	@echo "🔌 Setting up port forwarding..."
	@pkill -f "kubectl port-forward" || true
	kubectl port-forward -n ai-persona-system svc/auth-service 8081:8081 &
	kubectl port-forward -n ai-persona-system svc/core-manager 8088:8088 &
	kubectl port-forward -n ai-persona-system svc/grafana 3000:3000 &
	kubectl port-forward -n ai-persona-system svc/prometheus 9090:9090 &
	kubectl port-forward -n ai-persona-system svc/minio 9001:9001 &
	@echo "✅ Port forwarding active"
	@echo "Services available at:"
	@echo "  - Auth API: http://localhost:8081"
	@echo "  - Core API: http://localhost:8088"
	@echo "  - Grafana: http://localhost:3000"
	@echo "  - Prometheus: http://localhost:9090"
	@echo "  - MinIO Console: http://localhost:9001"

# Stop port forwarding
stop-port-forward:
	@pkill -f "kubectl port-forward" || true
	@echo "✅ Port forwarding stopped"

# View logs for a service
logs:
	@read -p "Enter service name (e.g., auth-service, core-manager, agent-chassis): " service; \
	kubectl logs -n ai-persona-system -l app=$$service -f --tail=100

# Scale a deployment
scale:
	@read -p "Enter deployment name: " deployment; \
	read -p "Enter replica count: " replicas; \
	kubectl scale deployment -n ai-persona-system $$deployment --replicas=$$replicas

# Check system status
status:
	@echo "📊 System Status:"
	@echo "\n🏃 Deployments:"
	@kubectl get deployments -n ai-persona-system
	@echo "\n📦 Pods:"
	@kubectl get pods -n ai-persona-system
	@echo "\n🔌 Services:"
	@kubectl get services -n ai-persona-system
	@echo "\n💾 Persistent Volumes:"
	@kubectl get pvc -n ai-persona-system

# Create initial template data
seed-data:
	@echo "🌱 Seeding initial data..."
	@kubectl exec -i -n ai-persona-system postgres-templates-0 -- psql -U templates_user -d templates_db <<EOF
	INSERT INTO persona_templates (id, name, description, category, config, is_active) VALUES
	('00000000-0000-0000-0000-000000000001', 'Content Writer', 'General purpose content writing agent', 'writing',
	 '{"model": "claude-3-opus", "temperature": 0.7, "skills": ["blog_writing", "copywriting", "editing"]}', true),
	('00000000-0000-0000-0000-000000000002', 'Code Assistant', 'Programming and code review agent', 'technical',
	 '{"model": "claude-3-opus", "temperature": 0.2, "skills": ["code_generation", "debugging", "review"]}', true),
	('00000000-0000-0000-0000-000000000003', 'Research Analyst', 'Research and data analysis agent', 'research',
	 '{"model": "claude-3-opus", "temperature": 0.3, "skills": ["web_research", "data_analysis", "summarization"]}', true);
	EOF
	@echo "✅ Initial data seeded"

# Quick start - runs everything needed to get started
quickstart: setup build deploy migrate-up seed-data port-forward
	@echo "🎉 AI Persona System is ready!"
	@echo "Default services are now accessible - see above for URLs"

# Help
help:
	@echo "AI Persona System - Makefile Commands"
	@echo ""
	@echo "Setup & Deployment:"
	@echo "  make setup          - Initial setup (creates secrets, configures cluster)"
	@echo "  make build          - Build all Docker images"
	@echo "  make deploy         - Deploy to Kubernetes"
	@echo "  make quickstart     - Complete setup from scratch"
	@echo ""
	@echo "Development:"
	@echo "  make dev            - Start local development environment"
	@echo "  make test           - Run unit tests"
	@echo "  make port-forward   - Set up local port forwarding"
	@echo "  make logs           - View service logs"
	@echo ""
	@echo "Operations:"
	@echo "  make status         - Check system status"
	@echo "  make scale          - Scale a deployment"
	@echo "  make create-client  - Create a new client schema"
	@echo "  make seed-data      - Add initial template data"-------------------------------------------------
filepath = ./Dockerfile.agent-chassis
# FILE: Dockerfile.agent-chassis
FROM golang:1.21-alpine AS builder
WORKDIR /app
COPY go.mod go.sum ./
RUN go mod download
COPY . .
RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o agent-chassis ./cmd/agent-chassis

FROM alpine:latest
RUN apk --no-cache add ca-certificates
RUN addgroup -S appgroup && adduser -S appuser -G appgroup
WORKDIR /app
COPY --from=builder /app/agent-chassis /app/
COPY configs/agent-chassis.yaml /app/configs/
RUN chown -R appuser:appgroup /app
USER appuser
CMD ["./agent-chassis", "-config", "configs/agent-chassis.yaml"]-------------------------------------------------
filepath = ./pkg/models/database.go
// FILE: pkg/models/database.go
package models

import (
	"context"
	"github.com/google/uuid"
	"time"
)

// Persona represents both templates and instances
type Persona struct {
	ID          uuid.UUID              `json:"id"`
	Name        string                 `json:"name"`
	Description string                 `json:"description"`
	Category    string                 `json:"category"`
	Config      map[string]interface{} `json:"config"`
	IsTemplate  bool                   `json:"is_template"`
	IsActive    bool                   `json:"is_active"`
	CreatedAt   time.Time              `json:"created_at"`
	UpdatedAt   time.Time              `json:"updated_at"`
}

// PersonaRepository defines the interface for persona data access
type PersonaRepository interface {
	// Template methods
	CreateTemplate(ctx context.Context, template *Persona) (*Persona, error)
	GetTemplateByID(ctx context.Context, id string) (*Persona, error)
	ListTemplates(ctx context.Context) ([]Persona, error)
	UpdateTemplate(ctx context.Context, template *Persona) (*Persona, error)
	DeleteTemplate(ctx context.Context, id string) error

	// Instance methods
	CreateInstanceFromTemplate(ctx context.Context, templateID string, userID string, instanceName string) (*Persona, error)
	GetInstanceByID(ctx context.Context, id string) (*Persona, error)
	ListInstances(ctx context.Context, userID string) ([]Persona, error)
	UpdateInstance(ctx context.Context, id string, name *string, config map[string]interface{}) (*Persona, error)
	DeleteInstance(ctx context.Context, id string) error
}
-------------------------------------------------
filepath = ./pkg/models/contracts.go
// FILE: pkg/models/contracts.go
package models

// AgentConfig defines the "mind" of an agent, loaded from the database
type AgentConfig struct {
	AgentID   string                 `json:"agent_id"`
	AgentType string                 `json:"agent_type"`
	Version   int                    `json:"version"`
	CoreLogic map[string]interface{} `json:"core_logic"`
	Workflow  WorkflowPlan           `json:"workflow"`
}

// WorkflowPlan defines the orchestration steps for an agent
type WorkflowPlan struct {
	StartStep string          `json:"start_step"`
	Steps     map[string]Step `json:"steps"`
}

// Step represents a single action or sub-workflow within a plan
type Step struct {
	Action       string    `json:"action"`
	Description  string    `json:"description"`
	Topic        string    `json:"topic,omitempty"`
	Dependencies []string  `json:"dependencies,omitempty"`
	NextStep     string    `json:"next_step,omitempty"`
	SubTasks     []SubTask `json:"sub_tasks,omitempty"`
}

// SubTask for fan-out operations
type SubTask struct {
	StepName string `json:"step_name"`
	Topic    string `json:"topic"`
}

// Standard message payloads
type TaskRequest struct {
	Action string                 `json:"action"`
	Data   map[string]interface{} `json:"data"`
}

type TaskResponse struct {
	Success bool                   `json:"success"`
	Data    map[string]interface{} `json:"data"`
	Error   string                 `json:"error,omitempty"`
}
-------------------------------------------------
filepath = ./scripts/setup.sh
#!/bin/bash
# FILE: scripts/setup.sh
# Initial setup script for AI Persona System

set -e  # Exit on error

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# Functions
print_success() {
    echo -e "${GREEN}✅ $1${NC}"
}

print_error() {
    echo -e "${RED}❌ $1${NC}"
}

print_info() {
    echo -e "${YELLOW}ℹ️  $1${NC}"
}

# Check prerequisites
check_prerequisites() {
    echo "🔍 Checking prerequisites..."

    local missing_deps=()

    # Check kubectl
    if ! command -v kubectl &> /dev/null; then
        missing_deps+=("kubectl")
    fi

    # Check docker
    if ! command -v docker &> /dev/null; then
        missing_deps+=("docker")
    fi

    # Check if Kubernetes is accessible
    if ! kubectl cluster-info &> /dev/null; then
        print_error "Cannot connect to Kubernetes cluster. Please ensure kubectl is configured."
        exit 1
    fi

    if [ ${#missing_deps[@]} -ne 0 ]; then
        print_error "Missing required dependencies: ${missing_deps[*]}"
        echo "Please install missing dependencies and try again."
        exit 1
    fi

    print_success "All prerequisites met"
}

# Create namespace
create_namespace() {
    print_info "Creating Kubernetes namespace..."
    kubectl apply -f k8s/namespace.yaml || {
        print_error "Failed to create namespace"
        exit 1
    }
    print_success "Namespace created"
}

# Generate random passwords
generate_password() {
    openssl rand -base64 32 | tr -d "=+/" | cut -c1-25
}

# Create secrets
create_secrets() {
    print_info "Creating secrets..."

    # Database secrets
    kubectl create secret generic db-secrets -n ai-persona-system \
        --from-literal=clients-db-password=$(generate_password) \
        --from-literal=templates-db-password=$(generate_password) \
        --from-literal=auth-db-password=$(generate_password) \
        --from-literal=mysql-root-password=$(generate_password) \
        --dry-run=client -o yaml | kubectl apply -f - || {
        print_error "Failed to create database secrets"
        exit 1
    }

    # MinIO secrets
    kubectl create secret generic minio-secrets -n ai-persona-system \
        --from-literal=access-key=$(generate_password) \
        --from-literal=secret-key=$(generate_password) \
        --dry-run=client -o yaml | kubectl apply -f - || {
        print_error "Failed to create MinIO secrets"
        exit 1
    }

    # Auth secrets
    kubectl create secret generic auth-secrets -n ai-persona-system \
        --from-literal=jwt-secret=$(generate_password) \
        --dry-run=client -o yaml | kubectl apply -f - || {
        print_error "Failed to create auth secrets"
        exit 1
    }

    # Grafana secrets
    kubectl create secret generic grafana-secrets -n ai-persona-system \
        --from-literal=admin-password=$(generate_password) \
        --dry-run=client -o yaml | kubectl apply -f - || {
        print_error "Failed to create Grafana secrets"
        exit 1
    }

    print_success "Basic secrets created"
}

# Get API keys from user
get_api_keys() {
    print_info "Setting up AI service API keys..."
    echo "Please provide your API keys (or press Enter to skip):"

    # Anthropic
    read -p "Anthropic API Key (for Claude): " anthropic_key
    if [ -z "$anthropic_key" ]; then
        anthropic_key="dummy-key-replace-me"
        print_info "Skipping Anthropic API key - reasoning agent will not work"
    fi

    # Stability AI
    read -p "Stability AI API Key (for image generation): " stability_key
    if [ -z "$stability_key" ]; then
        stability_key="dummy-key-replace-me"
        print_info "Skipping Stability API key - image generation will not work"
    fi

    # SERP API
    read -p "SERP API Key (for web search): " serp_key
    if [ -z "$serp_key" ]; then
        serp_key="dummy-key-replace-me"
        print_info "Skipping SERP API key - web search will not work"
    fi

    # Create AI secrets
    kubectl create secret generic ai-secrets -n ai-persona-system \
        --from-literal=anthropic-api-key="$anthropic_key" \
        --from-literal=stability-api-key="$stability_key" \
        --from-literal=serp-api-key="$serp_key" \
        --dry-run=client -o yaml | kubectl apply -f - || {
        print_error "Failed to create AI secrets"
        exit 1
    }

    print_success "AI service secrets created"
}

# Create service account and RBAC
create_rbac() {
    print_info "Setting up RBAC..."

    cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: ServiceAccount
metadata:
  name: prometheus
  namespace: ai-persona-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: prometheus
rules:
- apiGroups: [""]
  resources:
  - nodes
  - nodes/proxy
  - services
  - endpoints
  - pods
  verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prometheus
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus
subjects:
- kind: ServiceAccount
  name: prometheus
  namespace: ai-persona-system
EOF

    print_success "RBAC configured"
}

# Main setup flow
main() {
    echo "🚀 AI Persona System Setup"
    echo "========================="
    echo ""

    # Run checks
    check_prerequisites

    # Create namespace
    create_namespace

    # Create secrets
    create_secrets

    # Get API keys
    get_api_keys

    # Setup RBAC
    create_rbac

    echo ""
    print_success "Setup complete!"
    echo ""
    echo "Next steps:"
    echo "1. Build Docker images:    make build"
    echo "2. Deploy to Kubernetes:   make deploy"
    echo "3. Run migrations:         make migrate-up"
    echo "4. Seed initial data:      make seed-data"
    echo "5. Set up port forward:    make port-forward"
    echo ""
    echo "Or run everything at once: make quickstart"
    echo ""
}

# Run main function
main-------------------------------------------------
filepath = ./Dockerfile.platform
# FILE: Dockerfile.platform
# Base image with common dependencies
FROM golang:1.21-alpine AS base
RUN apk add --no-cache git ca-certificates
WORKDIR /app
-------------------------------------------------
filepath = ./.env
# Database passwords
CLIENTS_DB_PASSWORD=your_password
TEMPLATES_DB_PASSWORD=your_password
AUTH_DB_PASSWORD=your_password
MYSQL_ROOT_PASSWORD=your_password

# Object storage
MINIO_ACCESS_KEY=your_access_key
MINIO_SECRET_KEY=your_secret_key

# AI Services
ANTHROPIC_API_KEY=your_api_key

# Auth
JWT_SECRET_KEY=your_jwt_secret-------------------------------------------------
filepath = ./configs/agent-chassis.yaml
# FILE: configs/agent-chassis.yaml
service_info:
  name: "agent-chassis"
  version: "1.0.0"
  environment: "development"

server:
  port: "8085"

logging:
  level: "info"

observability:
  tracing_endpoint: "otel-collector.monitoring.svc.cluster.local:4317"

infrastructure:
  kafka_brokers:
    - "kafka-broker-1:9092"
    - "kafka-broker-2:9092"

  clients_database:
    host: "postgres-clients.database.svc.cluster.local"
    port: 5432
    user: "clients_user"
    password_env_var: "CLIENTS_DB_PASSWORD"
    db_name: "clients_db"
    sslmode: "disable"

  templates_database:
    host: "postgres-templates.database.svc.cluster.local"
    port: 5432
    user: "templates_user"
    password_env_var: "TEMPLATES_DB_PASSWORD"
    db_name: "templates_db"
    sslmode: "disable"

  auth_database: {}

  object_storage:
    provider: "s3"
    endpoint: "http://minio.storage.svc.cluster.local:9000"
    bucket: "agent-artifacts"
    access_key_env_var: "MINIO_ACCESS_KEY"
    secret_key_env_var: "MINIO_SECRET_KEY"-------------------------------------------------
filepath = ./configs/auth-service.yaml
# FILE: configs/auth-service.yaml
service_info:
  name: "personae-auth-service"
  version: "1.1.0"
  environment: "development"

server:
  port: "8081"

logging:
  level: "debug"

observability:
  tracing_endpoint: "otel-collector.monitoring.svc.cluster.local:4317"

infrastructure:
  auth_database:
    host: "mysql-auth.database.svc.cluster.local"
    port: 3306
    user: "auth_user"
    password_env_var: "AUTH_DB_PASSWORD"
    db_name: "auth_db"
    ssl_mode: "disable"
  
  kafka_brokers: []
  clients_database: {}
  templates_database: {}
  object_storage: {}

custom:
  jwt_secret_key_env_var: "JWT_SECRET_KEY"
  jwt_expiry_access_minutes: 60
  allowed_origins:
    - "http://localhost:3000"
    - "http://localhost:8080"
  core_manager_url: "http://core-manager:8088"
  tiers:
    free_tier:
      max_personas_allowed: 1
      max_content_allowed: 5
    premium_tier:
      max_personas_allowed: -1
      max_content_allowed: -1-------------------------------------------------
filepath = ./configs/reasoning-agent.yaml
# FILE: configs/reasoning-agent.yaml
service_info:
  name: "reasoning-agent"
  version: "1.0.0"
  environment: "development"

server:
  port: "8082"

logging:
  level: "info"

infrastructure:
  kafka_brokers:
    - "kafka-broker-1:9092"
    - "kafka-broker-2:9092"

  clients_database: {}
  templates_database: {}
  auth_database: {}
  object_storage: {}

custom:
  ai_service:
    provider: "anthropic"
    model: "claude-3-opus-20240229"
    temperature: 0.2
    max_tokens: 2048
    api_key_env_var: "ANTHROPIC_API_KEY"-------------------------------------------------
filepath = ./configs/core-manager.yaml
# FILE: configs/core-manager.yaml
service_info:
  name: "core-manager"
  version: "1.0.0"
  environment: "development"

server:
  port: "8088"

logging:
  level: "info"

observability:
  tracing_endpoint: "otel-collector.monitoring.svc.cluster.local:4317"

infrastructure:
  kafka_brokers:
    - "kafka-broker-1:9092"
    - "kafka-broker-2:9092"
  
  clients_database:
    host: "postgres-clients.database.svc.cluster.local"
    port: 5432
    user: "clients_user"
    password_env_var: "CLIENTS_DB_PASSWORD"
    db_name: "clients_db"
    sslmode: "disable"
  
  templates_database:
    host: "postgres-templates.database.svc.cluster.local"
    port: 5432
    user: "templates_user"
    password_env_var: "TEMPLATES_DB_PASSWORD"
    db_name: "templates_db"
    sslmode: "disable"
  
  auth_database: {}
  
  object_storage:
    provider: "s3"
    endpoint: "http://minio.storage.svc.cluster.local:9000"
    bucket: "agent-artifacts"
    access_key_env_var: "MINIO_ACCESS_KEY"
    secret_key_env_var: "MINIO_SECRET_KEY"-------------------------------------------------
filepath = ./cmd/agent-chassis/main.go
// FILE: cmd/agent-chassis/main.go
// This is the entrypoint for our generic agent service.
package main

import (
	"context"
	"flag"
	"go.uber.org/zap"
	"log"
	"os"
	"os/signal"
	"syscall"
	"time"

	"github.com/gqls/ai-persona-system/platform/agentbase"
	"github.com/gqls/ai-persona-system/platform/config"
	"github.com/gqls/ai-persona-system/platform/logger"
)

func main() {
	// 1. Load the service's static configuration from a file.
	configPath := flag.String("config", "configs/agent-chassis.yaml", "Path to config file")
	flag.Parse()

	cfg, err := config.Load(*configPath)
	if err != nil {
		log.Fatalf("Failed to load config: %v", err)
	}

	// 2. Initialize the logger.
	appLogger, err := logger.New(cfg.Logging.Level)
	if err != nil {
		log.Fatalf("Failed to initialize logger: %v", err)
	}
	defer appLogger.Sync()

	// 3. Create a cancellable context for graceful shutdown.
	ctx, cancel := context.WithCancel(context.Background())
	defer cancel()

	// 4. Initialize the base agent framework from the platform library.
	// This one call sets up all connections (DB, Kafka) and the main consumer loop logic.
	agent, err := agentbase.New(ctx, cfg, appLogger)
	if err != nil {
		appLogger.Fatal("Failed to initialize agent base", zap.Error(err))
	}

	// 5. Start the agent's main run loop in a goroutine.
	go func() {
		if err := agent.Run(); err != nil {
			appLogger.Error("Agent chassis failed to run", zap.Error(err))
			cancel() // Trigger shutdown if the run loop exits with an error
		}
	}()

	// 6. Wait for a shutdown signal.
	quit := make(chan os.Signal, 1)
	signal.Notify(quit, syscall.SIGINT, syscall.SIGTERM)
	<-quit
	appLogger.Info("Shutdown signal received, shutting down agent chassis...")

	// Trigger the context cancellation, which will gracefully stop the agent's Run loop.
	cancel()

	// Allow a moment for graceful shutdown to complete.
	time.Sleep(2 * time.Second)
	appLogger.Info("Agent chassis service stopped.")
}
-------------------------------------------------
filepath = ./cmd/auth-service/main.go
// FILE: cmd/auth-service/main.go
// This is the refactored main entrypoint for the auth-service.
package main

import (
	"context"
	"errors"
	"flag"
	"log"
	"net/http"
	"os"
	"os/signal"
	"syscall"
	"time"

	// Internal auth-service packages
	"github.com/gqls/personae-auth-service/internal/admin"
	"github.com/gqls/personae-auth-service/internal/auth"
	"github.com/gqls/personae-auth-service/internal/gateway"
	"github.com/gqls/personae-auth-service/internal/jwt"
	"github.com/gqls/personae-auth-service/internal/middleware"
	"github.com/gqls/personae-auth-service/internal/project"
	"github.com/gqls/personae-auth-service/internal/subscription"
	"github.com/gqls/personae-auth-service/internal/user"

	// --- Use platform packages ---
	"github.com/gqls/ai-persona-system/platform/config"
	"github.com/gqls/ai-persona-system/platform/database"
	"github.com/gqls/ai-persona-system/platform/logger"

	"github.com/rs/cors"
	"go.uber.org/zap"
)

func main() {
	// --- Step 1: Load Configuration using the Platform Library ---
	configPath := flag.String("config", "configs/auth-service.yaml", "Path to config file")
	flag.Parse()

	cfg, err := config.Load(*configPath)
	if err != nil {
		log.Fatalf("CRITICAL: Failed to load configuration: %v", err)
	}

	// --- Step 2: Initialize Logger using the Platform Library ---
	appLogger, err := logger.New(cfg.Logging.Level)
	if err != nil {
		log.Fatalf("CRITICAL: Failed to initialize logger: %v", err)
	}
	defer appLogger.Sync()

	appLogger.Info("Auth Service starting",
		zap.String("service_name", cfg.ServiceInfo.Name),
		zap.String("version", cfg.ServiceInfo.Version),
		zap.String("environment", cfg.ServiceInfo.Environment),
	)

	// --- Step 3: Initialize Database Connection using the Platform Library ---
	// The auth service uses MySQL.
	db, err := database.NewMySQLConnection(context.Background(), cfg.Infrastructure.AuthDatabase, appLogger)
	if err != nil {
		appLogger.Fatal("Failed to connect to the auth database", zap.Error(err))
	}
	defer db.Close()

	// --- Step 4: Initialize All Services and Handlers ---
	// This logic remains largely the same, but now it's cleaner because
	// the dependencies are initialized above in a standard way.

	// Extract custom config needed for JWT service
	// (This assumes we add a generic `custom` map[string]interface{} to our platform config struct)
	// For now, we'll manually construct a temporary config for JWT.
	jwtSecret := os.Getenv("JWT_SECRET_KEY") // Read from environment
	if jwtSecret == "" {
		appLogger.Fatal("JWT_SECRET_KEY environment variable not set")
	}

	tempJwtCfg := &auth_config.Config{ // Assuming auth_config is the old config package
		JWTSecretKey:           jwtSecret,
		JWTExpiryAccessMinutes: 60, // This would also come from the new config structure
	}

	jwtSvc, err := jwt.NewService(tempJwtCfg, appLogger)
	if err != nil {
		appLogger.Fatal("Failed to initialize JWT Service", zap.Error(err))
	}

	// Initialize repositories
	userRepo := user.NewRepository(db, appLogger, tempJwtCfg) // Pass old config for now
	adminRepo := admin.NewRepository(db, appLogger, tempJwtCfg)
	projectRepo := project.NewRepository(db, appLogger)
	subscriptionRepo := subscription.NewRepository(db, appLogger)

	// Initialize services
	userSvc := user.NewService(userRepo, appLogger)
	authSvc := auth.NewService(userSvc, jwtSvc, appLogger)
	gatewaySvc := gateway.NewService(tempJwtCfg, appLogger)
	subscriptionSvc := subscription.NewService(subscriptionRepo, appLogger)

	// Initialize handlers
	authAPIHandler := auth.NewHTTPHandler(authSvc, userSvc, jwtSvc, adminRepo, gatewaySvc, appLogger, tempJwtCfg)
	projectHandler := project.NewHTTPHandler(projectRepo, appLogger)
	subscriptionHandler := subscription.NewHTTPHandler(subscriptionSvc, appLogger)
	subscriptionAdminHandler := subscription.NewAdminHandlers(subscriptionSvc, appLogger)
	gatewayHandler := gateway.NewHTTPHandler(gatewaySvc, jwtSvc, appLogger, subscriptionSvc, projectRepo)

	// --- Step 5: Setup Routing and Middleware ---
	mux := http.NewServeMux()

	// Register all public, protected, and admin routes...
	// (This extensive block of mux.Handle/HandleFunc calls remains the same)
	// ...

	// --- Step 6: Configure CORS and Start Server ---
	loggedMux := middleware.LoggingMiddleware(appLogger)(mux)

	// This CORS config would also be driven by the new platform config struct
	corsOptions := cors.Options{
		AllowedOrigins:   []string{"*"}, // Placeholder
		AllowedMethods:   []string{"GET", "POST", "PUT", "PATCH", "DELETE", "OPTIONS"},
		AllowedHeaders:   []string{"Authorization", "Content-Type"},
		AllowCredentials: true,
	}
	handlerWithCORS := cors.New(corsOptions).Handler(loggedMux)

	server := &http.Server{
		Addr:    ":" + cfg.Server.Port,
		Handler: handlerWithCORS,
	}

	// --- Step 7: Start Server and Handle Graceful Shutdown ---
	go func() {
		appLogger.Info("Auth Service listening", zap.String("address", server.Addr))
		if err := server.ListenAndServe(); err != nil && !errors.Is(err, http.ErrServerClosed) {
			appLogger.Fatal("Auth Service listen and serve error", zap.Error(err))
		}
	}()

	quit := make(chan os.Signal, 1)
	signal.Notify(quit, syscall.SIGINT, syscall.SIGTERM)
	<-quit
	appLogger.Info("Shutdown signal received, shutting down auth server...")

	ctxShutdown, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()

	if err := server.Shutdown(ctxShutdown); err != nil {
		appLogger.Fatal("Auth Server forced to shutdown due to error", zap.Error(err))
	}
	appLogger.Info("Auth Server exited gracefully")
}
-------------------------------------------------
filepath = ./cmd/reasoning-agent/Dockerfile
# FILE: Dockerfile.reasoning
# A dedicated Dockerfile for building the reasoning agent service.

# Stage 1: Build the application
FROM golang:1.21-alpine AS builder

WORKDIR /app

# Copy modules and download dependencies
COPY go.mod go.sum ./
RUN go mod download

# Copy the entire project context
COPY . .

# Build the specific service binary
RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o /app/reasoning-agent ./cmd/reasoning-agent

# Stage 2: Create the final small image
FROM alpine:latest
RUN apk --no-cache add ca-certificates

# Create a non-root user for security
RUN addgroup -S appgroup && adduser -S -G appgroup appuser

WORKDIR /app

# Copy only the compiled binary from the builder stage
COPY --from=builder /app/reasoning-agent /app/reasoning-agent

# Copy its specific configuration file
COPY configs/reasoning-agent.yaml /app/configs/reasoning-agent.yaml

RUN chown appuser:appgroup /app/reasoning-agent

USER appuser

# The command to run the service, pointing to its own config
CMD ["./reasoning-agent", "-config", "configs/reasoning-agent.yaml"]
-------------------------------------------------
filepath = ./cmd/reasoning-agent/main.go
// FILE: cmd/reasoning-agent/main.go
// This is the main entrypoint for our new, specialized Reasoning Agent service.
package main

import (
	"context"
	"flag"
	"log"
	"os"
	"os/signal"
	"syscall"
	"time"

	"github.com/gqls/ai-persona-system/internal/agents/reasoning" // The agent's specific logic
	"github.com/gqls/ai-persona-system/platform/config"
	"github.com/gqls/ai-persona-system/platform/logger"
	"go.uber.org/zap"
)

func main() {
	// 1. Load the service's static configuration from its dedicated file.
	configPath := flag.String("config", "configs/reasoning-agent.yaml", "Path to config file")
	flag.Parse()

	cfg, err := config.Load(*configPath)
	if err != nil {
		log.Fatalf("Failed to load config: %v", err)
	}

	// 2. Initialize the standardized platform logger.
	appLogger, err := logger.New(cfg.Logging.Level)
	if err != nil {
		log.Fatalf("Failed to initialize logger: %v", err)
	}
	defer appLogger.Sync()

	// 3. Create a cancellable context for graceful shutdown.
	ctx, cancel := context.WithCancel(context.Background())
	defer cancel()

	// 4. Initialize the Reasoning Agent.
	// This is where we inject its dependencies from the platform.
	agent, err := reasoning.NewAgent(ctx, cfg, appLogger)
	if err != nil {
		appLogger.Fatal("Failed to initialize reasoning agent", zap.Error(err))
	}

	// 5. Start the agent's main run loop in a goroutine.
	go func() {
		if err := agent.Run(); err != nil {
			appLogger.Error("Reasoning agent failed to run", zap.Error(err))
			cancel() // Trigger shutdown
		}
	}()

	// 6. Wait for a shutdown signal.
	quit := make(chan os.Signal, 1)
	signal.Notify(quit, syscall.SIGINT, syscall.SIGTERM)
	<-quit
	appLogger.Info("Shutdown signal received, shutting down reasoning agent...")

	cancel()

	time.Sleep(2 * time.Second)
	appLogger.Info("Reasoning agent service stopped.")
}
```go
// FILE: internal/agents/reasoning/agent.go
// This file contains the core custom logic for the Reasoning Agent.
package reasoning

import (
	"context"
	"encoding/json"
	"fmt"
	"time"

	"[github.com/google/uuid](https://github.com/google/uuid)"
	"[github.com/gqls/ai-persona-system/platform/aiservice](https://github.com/gqls/ai-persona-system/platform/aiservice)"
	"[github.com/gqls/ai-persona-system/platform/config](https://github.com/gqls/ai-persona-system/platform/config)"
	"[github.com/gqls/ai-persona-system/platform/kafka](https://github.com/gqls/ai-persona-system/platform/kafka)"
	"go.uber.org/zap"
)

const (
	requestTopic  = "system.agent.reasoning.process"
	responseTopic = "system.responses.reasoning"
	consumerGroup = "reasoning-agent-group"
)

// RequestPayload defines the data this agent expects.
type RequestPayload struct {
	Action string `json:"action"` // e.g., "review_for_clarity", "deductive_reasoning"
	Data   struct {
		ContentToReview string                 `json:"content_to_review"`
		ReviewCriteria  []string               `json:"review_criteria"`
		BriefContext    map[string]interface{} `json:"brief_context"`
	} `json:"data"`
}

// ResponsePayload defines the data this agent produces.
type ResponsePayload struct {
	ReviewPassed bool     `json:"review_passed"`
	Score        float64  `json:"score"`
	Suggestions  []string `json:"suggestions"`
	Reasoning    string   `json:"reasoning"`
}

// Agent is the main struct for this specialized service.
type Agent struct {
	ctx           context.Context
	logger        *zap.Logger
	consumer      *kafka.Consumer
	producer      *kafka.Producer
	aiClient      aiservice.AIService // Using the platform's AI abstraction
}

// NewAgent initializes the agent and its dependencies.
func NewAgent(ctx context.Context, cfg *config.ServiceConfig, logger *zap.Logger) (*Agent, error) {
	consumer, err := kafka.NewConsumer(cfg.Infrastructure.KafkaBrokers, requestTopic, consumerGroup, logger)
	if err != nil {
		return nil, fmt.Errorf("failed to create kafka consumer: %w", err)
	}

	producer, err := kafka.NewProducer(cfg.Infrastructure.KafkaBrokers, logger)
	if err != nil {
		consumer.Close()
		return nil, fmt.Errorf("failed to create kafka producer: %w", err)
	}

	// Initialize the specific AI client this agent will use.
	// The config for this would be in reasoning-agent.yaml.
	// This demonstrates how a specialized agent can choose its own AI model.
	aiClient, err := aiservice.New(ctx, cfg.Custom["ai_service"]) // Assuming a generic factory
	if err != nil {
		consumer.Close()
		producer.Close()
		return nil, fmt.Errorf("failed to create AI client: %w", err)
	}

	return &Agent{
		ctx:           ctx,
		logger:        logger,
		consumer:      consumer,
		producer:      producer,
		aiClient:      aiClient,
	}, nil
}

// Run starts the consumer loop.
func (a *Agent) Run() error {
	a.logger.Info("Reasoning Agent is running and waiting for tasks...")
	for {
		select {
		case <-a.ctx.Done():
			a.consumer.Close()
			a.producer.Close()
			return nil
		default:
			msg, err := a.consumer.FetchMessage(a.ctx)
			if err != nil {
				if err == context.Canceled { continue }
				a.logger.Error("Failed to fetch message", zap.Error(err))
				continue
			}
			go a.handleMessage(msg)
		}
	}
}

// handleMessage contains the agent's unique business logic.
func (a *Agent) handleMessage(msg kafka.Message) {
	headers := kafka.HeadersToMap(msg.Headers)
	l := a.logger.With(zap.String("correlation_id", headers["correlation_id"]))

	var req RequestPayload
	if err := json.Unmarshal(msg.Value, &req); err != nil {
		l.Error("Failed to unmarshal request payload", zap.Error(err))
		a.consumer.CommitMessages(context.Background(), msg)
		return
	}

	// --- THIS IS THE CUSTOM LOGIC ---
	// Here, we would implement the specific reasoning algorithm.
	// For now, we'll use the AI client to simulate it.
	prompt := a.buildReasoningPrompt(req)
	reasoningResult, err := a.aiClient.GenerateText(a.ctx, prompt)
	if err != nil {
		l.Error("AI reasoning call failed", zap.Error(err))
		// Produce an error response or retry
		a.consumer.CommitMessages(context.Background(), msg)
		return
	}

	// Assume the AI returns a JSON string that we can parse into our response format.
	var responsePayload ResponsePayload
	if err := json.Unmarshal([]byte(reasoningResult), &responsePayload); err != nil {
		l.Error("Failed to parse reasoning result from AI", zap.Error(err))
		// Fallback response
		responsePayload.Reasoning = "Could not parse AI response, but original content was: " + req.Data.ContentToReview
	}
	// --- END OF CUSTOM LOGIC ---

	// Produce the standard response message.
	responseBytes, _ := json.Marshal(responsePayload)
	responseHeaders := map[string]string{
		"correlation_id": headers["correlation_id"],
		"causation_id":   headers["request_id"],
		"request_id":     uuid.NewString(),
	}
	if err := a.producer.Produce(a.ctx, responseTopic, responseHeaders, msg.Key, responseBytes); err != nil {
		l.Error("Failed to produce response message", zap.Error(err))
	}

	a.consumer.CommitMessages(context.Background(), msg)
}

// buildReasoningPrompt creates the prompt for the LLM.
func (a *Agent) buildReasoningPrompt(req RequestPayload) string {
	return fmt.Sprintf(
		"You are a logical reasoning engine. Review the following content based on these criteria: %v. "+
		"The original goal was: %v. Content to review: '%s'. "+
		"Respond with a JSON object with keys: 'review_passed' (boolean), 'score' (float 0-10), 'suggestions' (array of strings), and 'reasoning' (string).",
		req.Data.ReviewCriteria, req.Data.BriefContext, req.Data.ContentToReview,
	)
}
```yaml
# FILE: configs/reasoning-agent.yaml
# This is a dedicated configuration file for our new specialized service.
service_info:
name: "reasoning-agent"
version: "1.0.0"
environment: "development"

server:
port: "8082" # Runs on a different port from other services

logging:
level: "info"

infrastructure:
kafka_brokers:
- "personae-kafka-cluster-kafka-bootstrap.kafka.svc.cluster.local:9092"
# This agent might not need direct DB access if it's purely computational,
# but it could be configured here if needed.
clients_database: {}
templates_database: {}
auth_database: {}
object_storage: {}

# Custom section for this agent's specific needs
custom:
ai_service:
provider: "anthropic"
model: "claude-3-opus-20240229" # Use a powerful model for reasoning tasks
temperature: 0.2
max_tokens: 2048
api_key_env_var: "ANTHROPIC_API_KEY"
```dockerfile
# FILE: Dockerfile.reasoning
# A dedicated Dockerfile for building the reasoning agent service.

# Stage 1: Build the application
FROM golang:1.21-alpine AS builder

WORKDIR /app

# Copy modules and download dependencies
COPY go.mod go.sum ./
RUN go mod download

# Copy the entire project context
COPY . .

# Build the specific service binary
RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o /app/reasoning-agent ./cmd/reasoning-agent

# Stage 2: Create the final small image
FROM alpine:latest
RUN apk --no-cache add ca-certificates

# Create a non-root user for security
RUN addgroup -S appgroup && adduser -S -G appgroup appuser

WORKDIR /app

# Copy only the compiled binary from the builder stage
COPY --from=builder /app/reasoning-agent /app/reasoning-agent

# Copy its specific configuration file
COPY configs/reasoning-agent.yaml /app/configs/reasoning-agent.yaml

RUN chown appuser:appgroup /app/reasoning-agent

USER appuser

# The command to run the service, pointing to its own config
CMD ["./reasoning-agent", "-config", "configs/reasoning-agent.yaml"]
-------------------------------------------------
filepath = ./cmd/core-manager/main.go
// FILE: cmd/core-manager/main.go
package main

import (
	"context"
	"errors"
	"flag"
	"log"
	"net/http"
	"os"
	"os/signal"
	"syscall"
	"time"

	"github.com/gqls/ai-persona-system/internal/api"
	// --- Use platform packages ---
	"github.com/gqls/ai-persona-system/platform/config"
	"github.com/gqls/ai-persona-system/platform/database"
	"github.com/gqls/ai-persona-system/platform/logger"
	"go.uber.org/zap"
)

func main() {
	// --- Step 1: Load Configuration using the Platform Library ---
	configPath := flag.String("config", "configs/core-manager.yaml", "Path to config file")
	flag.Parse()

	// Use the standardized platform loader.
	cfg, err := config.Load(*configPath)
	if err != nil {
		log.Fatalf("CRITICAL: Failed to load configuration via platform loader: %v", err)
	}

	// --- Step 2: Initialize Logger using the Platform Library ---
	// Use the standardized platform logger.
	appLogger, err := logger.New(cfg.Logging.Level)
	if err != nil {
		log.Fatalf("CRITICAL: Failed to initialize logger: %v", err)
	}
	defer appLogger.Sync()

	appLogger.Info("Core Manager Service starting",
		zap.String("service_name", cfg.ServiceInfo.Name),
		zap.String("version", cfg.ServiceInfo.Version),
		zap.String("environment", cfg.ServiceInfo.Environment),
		zap.String("log_level", cfg.Logging.Level),
	)

	// Create a main context that can be cancelled for graceful shutdown.
	ctx, cancel := context.WithCancel(context.Background())
	defer cancel()

	// --- Step 3: Initialize Database Connections using the Platform Library ---
	// No more local helper function; we use the reusable platform function.

	// 3a. Create connection pool for the Templates Database.
	templatesPool, err := database.NewPostgresConnection(ctx, cfg.Infrastructure.TemplatesDatabase, appLogger)
	if err != nil {
		appLogger.Fatal("Failed to initialize templates database connection", zap.Error(err))
	}
	defer templatesPool.Close()

	// 3b. Create connection pool for the Clients Database.
	clientsPool, err := database.NewPostgresConnection(ctx, cfg.Infrastructure.ClientsDatabase, appLogger)
	if err != nil {
		appLogger.Fatal("Failed to initialize clients database connection", zap.Error(err))
	}
	defer clientsPool.Close()

	// --- Step 4: Initialize and Start the API Server ---
	// The server now receives the already-initialized dependencies.
	apiServer, err := api.NewServer(ctx, cfg, appLogger, templatesPool, clientsPool)
	if err != nil {
		appLogger.Fatal("Failed to initialize API server", zap.Error(err))
	}

	// Run the server in a goroutine so it doesn't block.
	go func() {
		appLogger.Info("Starting HTTP server...", zap.String("address", apiServer.Address()))
		if err := apiServer.Start(); err != nil && !errors.Is(err, http.ErrServerClosed) {
			appLogger.Error("API server ListenAndServe failed unexpectedly", zap.Error(err))
			cancel() // Trigger shutdown on server error
		}
	}()

	// --- Step 5: Handle Graceful Shutdown ---
	sigCh := make(chan os.Signal, 1)
	signal.Notify(sigCh, syscall.SIGINT, syscall.SIGTERM)
	receivedSignal := <-sigCh
	appLogger.Info("Shutdown signal received.", zap.String("signal", receivedSignal.String()))

	shutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer shutdownCancel()

	appLogger.Info("Calling API Server Shutdown...")
	if err := apiServer.Shutdown(shutdownCtx); err != nil {
		appLogger.Error("Error during API server graceful shutdown", zap.Error(err))
	} else {
		appLogger.Info("API server shutdown complete.")
	}

	appLogger.Info("Core Manager Service fully stopped.")
}
-------------------------------------------------
filepath = ./cmd/image-generator-adapter/main.go
// FILE: cmd/image-generator-adapter/main.go
// This is the entrypoint for our specialized adapter service.
package main

import (
	"context"
	"flag"
	"log"
	"os"
	"os/signal"
	"syscall"
	"time"

	"github.com/gqls/ai-persona-system/internal/adapters/imagegenerator" // The adapter's specific logic
	"github.com/gqls/ai-persona-system/platform/config"
	"github.com/gqls/ai-persona-system/platform/logger"
	"go.uber.org/zap"
)

func main() {
	// 1. Load the service's static configuration.
	// This adapter would have its own config file specifying its topics and the external API details.
	configPath := flag.String("config", "configs/image-adapter.yaml", "Path to config file")
	flag.Parse()

	cfg, err := config.Load(*configPath)
	if err != nil {
		log.Fatalf("Failed to load config: %v", err)
	}

	// 2. Initialize the platform logger.
	appLogger, err := logger.New(cfg.Logging.Level)
	if err != nil {
		log.Fatalf("Failed to initialize logger: %v", err)
	}
	defer appLogger.Sync()

	// 3. Create a cancellable context for graceful shutdown.
	ctx, cancel := context.WithCancel(context.Background())
	defer cancel()

	// 4. Initialize the adapter.
	// This is where we pass dependencies like the logger and config.
	adapter, err := imagegenerator.NewAdapter(ctx, cfg, appLogger)
	if err != nil {
		appLogger.Fatal("Failed to initialize image generator adapter", zap.Error(err))
	}

	// 5. Start the adapter's main run loop in a goroutine.
	go func() {
		if err := adapter.Run(); err != nil {
			appLogger.Error("Image generator adapter failed to run", zap.Error(err))
			cancel() // Trigger shutdown
		}
	}()

	// 6. Wait for a shutdown signal.
	quit := make(chan os.Signal, 1)
	signal.Notify(quit, syscall.SIGINT, syscall.SIGTERM)
	<-quit
	appLogger.Info("Shutdown signal received, shutting down image generator adapter...")

	cancel()

	// Allow a moment for graceful shutdown.
	time.Sleep(2 * time.Second)
	appLogger.Info("Image generator adapter stopped.")
}
-------------------------------------------------
filepath = ./k8s/minio.yaml
apiVersion: v1
kind: Service
metadata:
  name: minio
  namespace: ai-persona-system
  labels:
    app: minio
spec:
  ports:
    - port: 9000
      targetPort: 9000
      name: api
    - port: 9001
      targetPort: 9001
      name: console
  selector:
    app: minio
  type: ClusterIP

---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: minio
  namespace: ai-persona-system
spec:
  serviceName: minio
  replicas: 1
  selector:
    matchLabels:
      app: minio
  template:
    metadata:
      labels:
        app: minio
    spec:
      containers:
        - name: minio
          image: minio/minio:latest
          command:
            - /bin/sh
            - -c
          args:
            - |
              mkdir -p /data/agent-artifacts
              minio server /data --console-address :9001
          ports:
            - containerPort: 9000
              name: api
            - containerPort: 9001
              name: console
          env:
            - name: MINIO_ROOT_USER
              valueFrom:
                secretKeyRef:
                  name: minio-secrets
                  key: access-key
            - name: MINIO_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: minio-secrets
                  key: secret-key
            - name: MINIO_BROWSER
              value: "on"
          volumeMounts:
            - name: minio-storage
              mountPath: /data
          resources:
            requests:
              memory: "512Mi"
              cpu: "250m"
            limits:
              memory: "1Gi"
              cpu: "500m"
          livenessProbe:
            httpGet:
              path: /minio/health/live
              port: 9000
            initialDelaySeconds: 30
            periodSeconds: 20
          readinessProbe:
            httpGet:
              path: /minio/health/ready
              port: 9000
            initialDelaySeconds: 30
            periodSeconds: 20
  volumeClaimTemplates:
    - metadata:
        name: minio-storage
      spec:
        accessModes: ["ReadWriteOnce"]
        storageClassName: "standard"
        resources:
          requests:
            storage: 20Gi-------------------------------------------------
filepath = ./k8s/kafka.yaml
apiVersion: v1
kind: Service
metadata:
  name: kafka-headless
  namespace: ai-persona-system
  labels:
    app: kafka
spec:
  ports:
    - port: 9092
      name: broker
    - port: 9093
      name: controller
  clusterIP: None
  selector:
    app: kafka

---
apiVersion: v1
kind: Service
metadata:
  name: kafka-ui
  namespace: ai-persona-system
spec:
  ports:
    - port: 8080
      targetPort: 8080
  selector:
    app: kafka-ui
  type: ClusterIP

---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka
  namespace: ai-persona-system
spec:
  serviceName: kafka-headless
  replicas: 3
  selector:
    matchLabels:
      app: kafka
  template:
    metadata:
      labels:
        app: kafka
    spec:
      containers:
        - name: kafka
          image: confluentinc/cp-kafka:7.5.0
          ports:
            - containerPort: 9092
              name: broker
            - containerPort: 9093
              name: controller
          env:
            - name: KAFKA_NODE_ID
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: KAFKA_PROCESS_ROLES
              value: "broker,controller"
            - name: KAFKA_LISTENERS
              value: "PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093"
            - name: KAFKA_ADVERTISED_LISTENERS
              value: "PLAINTEXT://$(KAFKA_NODE_ID).kafka-headless:9092"
            - name: KAFKA_CONTROLLER_LISTENER_NAMES
              value: "CONTROLLER"
            - name: KAFKA_LISTENER_SECURITY_PROTOCOL_MAP
              value: "CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT"
            - name: KAFKA_CONTROLLER_QUORUM_VOTERS
              value: "kafka-0@kafka-0.kafka-headless:9093,kafka-1@kafka-1.kafka-headless:9093,kafka-2@kafka-2.kafka-headless:9093"
            - name: KAFKA_LOG_DIRS
              value: "/var/lib/kafka/data"
            - name: KAFKA_AUTO_CREATE_TOPICS_ENABLE
              value: "false"
            - name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
              value: "3"
            - name: KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR
              value: "3"
            - name: KAFKA_TRANSACTION_STATE_LOG_MIN_ISR
              value: "2"
            - name: KAFKA_DEFAULT_REPLICATION_FACTOR
              value: "3"
            - name: KAFKA_MIN_INSYNC_REPLICAS
              value: "2"
          volumeMounts:
            - name: kafka-storage
              mountPath: /var/lib/kafka/data
          resources:
            requests:
              memory: "1Gi"
              cpu: "500m"
            limits:
              memory: "2Gi"
              cpu: "1000m"
  volumeClaimTemplates:
    - metadata:
        name: kafka-storage
      spec:
        accessModes: ["ReadWriteOnce"]
        storageClassName: "standard"
        resources:
          requests:
            storage: 10Gi

---
# Kafka UI for monitoring
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka-ui
  namespace: ai-persona-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kafka-ui
  template:
    metadata:
      labels:
        app: kafka-ui
    spec:
      containers:
        - name: kafka-ui
          image: provectuslabs/kafka-ui:latest
          ports:
            - containerPort: 8080
          env:
            - name: KAFKA_CLUSTERS_0_NAME
              value: "ai-persona-cluster"
            - name: KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS
              value: "kafka-0.kafka-headless:9092,kafka-1.kafka-headless:9092,kafka-2.kafka-headless:9092"
          resources:
            requests:
              memory: "256Mi"
              cpu: "100m"
            limits:
              memory: "512Mi"
              cpu: "500m"-------------------------------------------------
filepath = ./k8s/agent-chassis.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: agent-chassis
  namespace: ai-persona-system
  labels:
    app: agent-chassis
spec:
  replicas: 5
  selector:
    matchLabels:
      app: agent-chassis
  template:
    metadata:
      labels:
        app: agent-chassis
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9090"
        prometheus.io/path: "/metrics"
    spec:
      containers:
        - name: agent-chassis
          image: ai-persona-system/agent-chassis:latest
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 9090
              name: metrics
          env:
            - name: SERVICE_NAME
              value: "agent-chassis"
            - name: SERVICE_VERSION
              value: "1.0.0"
            - name: SERVICE_ENVIRONMENT
              value: "production"
            - name: LOGGING_LEVEL
              value: "info"
            - name: AGENT_TYPE
              value: "generic"
            - name: KAFKA_CONSUMER_GROUP
              value: "agent-chassis-group"
            - name: CLIENTS_DB_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: db-secrets
                  key: clients-db-password
            - name: TEMPLATES_DB_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: db-secrets
                  key: templates-db-password
            - name: MINIO_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: minio-secrets
                  key: access-key
            - name: MINIO_SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: minio-secrets
                  key: secret-key
          envFrom:
            - configMapRef:
                name: common-config
          resources:
            requests:
              memory: "512Mi"
              cpu: "250m"
            limits:
              memory: "1Gi"
              cpu: "1000m"
          livenessProbe:
            httpGet:
              path: /health
              port: 9090
            initialDelaySeconds: 30
            periodSeconds: 10
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: agent-chassis-hpa
  namespace: ai-persona-system
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: agent-chassis
  minReplicas: 5
  maxReplicas: 50
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 80-------------------------------------------------
filepath = ./k8s/web-search-adapter.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-search-adapter
  namespace: ai-persona-system
  labels:
    app: web-search-adapter
spec:
  replicas: 2
  selector:
    matchLabels:
      app: web-search-adapter
  template:
    metadata:
      labels:
        app: web-search-adapter
    spec:
      containers:
        - name: web-search-adapter
          image: ai-persona-system/web-search-adapter:latest
          imagePullPolicy: IfNotPresent
          env:
            - name: SERVICE_NAME
              value: "web-search-adapter"
            - name: SERP_API_KEY
              valueFrom:
                secretKeyRef:
                  name: ai-secrets
                  key: serp-api-key
          envFrom:
            - configMapRef:
                name: common-config
          resources:
            requests:
              memory: "256Mi"
              cpu: "100m"
            limits:
              memory: "512Mi"
              cpu: "500m"-------------------------------------------------
filepath = ./k8s/configmap-common.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: common-config
  namespace: ai-persona-system
data:
  # Kafka configuration
  kafka_brokers: "kafka-0.kafka-headless:9092,kafka-1.kafka-headless:9092,kafka-2.kafka-headless:9092"

  # Database hosts
  clients_db_host: "postgres-clients"
  clients_db_port: "5432"
  clients_db_name: "clients_db"
  clients_db_user: "clients_user"

  templates_db_host: "postgres-templates"
  templates_db_port: "5432"
  templates_db_name: "templates_db"
  templates_db_user: "templates_user"

  auth_db_host: "mysql-auth"
  auth_db_port: "3306"
  auth_db_name: "auth_db"
  auth_db_user: "auth_user"

  # Object storage
  minio_endpoint: "http://minio:9000"
  minio_bucket: "agent-artifacts"

  # Service URLs
  core_manager_url: "http://core-manager:8088"
  auth_service_url: "http://auth-service:8081"

  # Observability
  tracing_endpoint: "otel-collector.monitoring.svc.cluster.local:4317"-------------------------------------------------
filepath = ./k8s/secrets-template.yaml
# This is a template - DO NOT apply directly
# Use the setup.sh script or create manually
apiVersion: v1
kind: Secret
metadata:
  name: db-secrets
  namespace: ai-persona-system
type: Opaque
stringData:
  clients-db-password: "CHANGE_ME"
  templates-db-password: "CHANGE_ME"
  auth-db-password: "CHANGE_ME"
  mysql-root-password: "CHANGE_ME"

---
apiVersion: v1
kind: Secret
metadata:
  name: minio-secrets
  namespace: ai-persona-system
type: Opaque
stringData:
  access-key: "CHANGE_ME"
  secret-key: "CHANGE_ME"

---
apiVersion: v1
kind: Secret
metadata:
  name: auth-secrets
  namespace: ai-persona-system
type: Opaque
stringData:
  jwt-secret: "CHANGE_ME"

---
apiVersion: v1
kind: Secret
metadata:
  name: ai-secrets
  namespace: ai-persona-system
type: Opaque
stringData:
  anthropic-api-key: "CHANGE_ME"
  stability-api-key: "CHANGE_ME"
  serp-api-key: "CHANGE_ME"

---
apiVersion: v1
kind: Secret
metadata:
  name: grafana-secrets
  namespace: ai-persona-system
type: Opaque
stringData:
  admin-password: "CHANGE_ME"-------------------------------------------------
filepath = ./k8s/network-policies.yaml
# Default deny all ingress
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny-ingress
  namespace: ai-persona-system
spec:
  podSelector: {}
  policyTypes:
    - Ingress

---
# Allow ingress from same namespace
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-same-namespace
  namespace: ai-persona-system
spec:
  podSelector: {}
  policyTypes:
    - Ingress
  ingress:
    - from:
        - podSelector: {}

---
# Allow ingress from ingress controller
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-ingress-controller
  namespace: ai-persona-system
spec:
  podSelector:
    matchLabels:
      app: auth-service
  policyTypes:
    - Ingress
  ingress:
    - from:
        - namespaceSelector:
            matchLabels:
              name: ingress-nginx
      ports:
        - protocol: TCP
          port: 8081

---
# Allow Prometheus scraping
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-prometheus
  namespace: ai-persona-system
spec:
  podSelector: {}
  policyTypes:
    - Ingress
  ingress:
    - from:
        - podSelector:
            matchLabels:
              app: prometheus
      ports:
        - protocol: TCP
          port: 9090-------------------------------------------------
filepath = ./k8s/postgres-clients.yaml
apiVersion: v1
kind: Service
metadata:
  name: postgres-clients
  namespace: ai-persona-system
  labels:
    app: postgres-clients
spec:
  ports:
    - port: 5432
      targetPort: 5432
      name: postgres
  selector:
    app: postgres-clients
  type: ClusterIP
  clusterIP: None  # Headless service for StatefulSet

---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres-clients
  namespace: ai-persona-system
spec:
  serviceName: postgres-clients
  replicas: 1
  selector:
    matchLabels:
      app: postgres-clients
  template:
    metadata:
      labels:
        app: postgres-clients
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9187"
        prometheus.io/path: "/metrics"
    spec:
      containers:
        - name: postgres
          image: pgvector/pgvector:pg16
          ports:
            - containerPort: 5432
              name: postgres
          env:
            - name: POSTGRES_DB
              value: "clients_db"
            - name: POSTGRES_USER
              value: "clients_user"
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: db-secrets
                  key: clients-db-password
            - name: PGDATA
              value: /var/lib/postgresql/data/pgdata
          volumeMounts:
            - name: postgres-storage
              mountPath: /var/lib/postgresql/data
          resources:
            requests:
              memory: "512Mi"
              cpu: "500m"
            limits:
              memory: "1Gi"
              cpu: "1000m"
          livenessProbe:
            exec:
              command:
                - pg_isready
                - -U
                - clients_user
            initialDelaySeconds: 30
            periodSeconds: 10
          readinessProbe:
            exec:
              command:
                - pg_isready
                - -U
                - clients_user
            initialDelaySeconds: 5
            periodSeconds: 5
        - name: postgres-exporter
          image: prometheuscommunity/postgres-exporter:latest
          ports:
            - containerPort: 9187
              name: metrics
          env:
            - name: DATA_SOURCE_NAME
              value: "postgresql://clients_user:$(POSTGRES_PASSWORD)@localhost:5432/clients_db?sslmode=disable"
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: db-secrets
                  key: clients-db-password
  volumeClaimTemplates:
    - metadata:
        name: postgres-storage
      spec:
        accessModes: ["ReadWriteOnce"]
        storageClassName: "standard"
        resources:
          requests:
            storage: 10Gi-------------------------------------------------
filepath = ./k8s/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ai-persona-ingress
  namespace: ai-persona-system
  annotations:
    kubernetes.io/ingress.class: nginx
    cert-manager.io/cluster-issuer: letsencrypt-prod
    nginx.ingress.kubernetes.io/proxy-body-size: "50m"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "300"
spec:
  tls:
    - hosts:
        - api.aipersona.example.com
        - grafana.aipersona.example.com
      secretName: api-tls
  rules:
    - host: api.aipersona.example.com
      http:
        paths:
          - path: /api/v1/auth
            pathType: Prefix
            backend:
              service:
                name: auth-service
                port:
                  number: 8081
          - path: /api/v1
            pathType: Prefix
            backend:
              service:
                name: auth-service
                port:
                  number: 8081
          - path: /ws
            pathType: Prefix
            backend:
              service:
                name: core-manager
                port:
                  number: 8088
    - host: grafana.aipersona.example.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: grafana
                port:
                  number: 3000-------------------------------------------------
filepath = ./k8s/image-generator-adapter.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: image-generator-adapter
  namespace: ai-persona-system
  labels:
    app: image-generator-adapter
spec:
  replicas: 2
  selector:
    matchLabels:
      app: image-generator-adapter
  template:
    metadata:
      labels:
        app: image-generator-adapter
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9090"
        prometheus.io/path: "/metrics"
    spec:
      containers:
        - name: image-generator-adapter
          image: ai-persona-system/image-generator-adapter:latest
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 9090
              name: metrics
          env:
            - name: SERVICE_NAME
              value: "image-generator-adapter"
            - name: SERVICE_VERSION
              value: "1.0.0"
            - name: SERVICE_ENVIRONMENT
              value: "production"
            - name: LOGGING_LEVEL
              value: "info"
            - name: STABILITY_API_KEY
              valueFrom:
                secretKeyRef:
                  name: ai-secrets
                  key: stability-api-key
            - name: MINIO_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: minio-secrets
                  key: access-key
            - name: MINIO_SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: minio-secrets
                  key: secret-key
          envFrom:
            - configMapRef:
                name: common-config
          resources:
            requests:
              memory: "256Mi"
              cpu: "100m"
            limits:
              memory: "512Mi"
              cpu: "500m"-------------------------------------------------
filepath = ./k8s/namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: ai-persona-system
  labels:
    name: ai-persona-system
    monitoring: enabled-------------------------------------------------
filepath = ./k8s/monitoring/service-monitor.yaml
# ServiceMonitor for Auth Service
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: auth-service
  namespace: ai-persona-system
  labels:
    app: auth-service
    prometheus: kube-prometheus
spec:
  selector:
    matchLabels:
      app: auth-service
  endpoints:
    - port: metrics
      interval: 30s
      path: /metrics
      scheme: http

---
# ServiceMonitor for Core Manager
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: core-manager
  namespace: ai-persona-system
  labels:
    app: core-manager
    prometheus: kube-prometheus
spec:
  selector:
    matchLabels:
      app: core-manager
  endpoints:
    - port: metrics
      interval: 30s
      path: /metrics
      scheme: http

---
# ServiceMonitor for Agent Chassis
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: agent-chassis
  namespace: ai-persona-system
  labels:
    app: agent-chassis
    prometheus: kube-prometheus
spec:
  selector:
    matchLabels:
      app: agent-chassis
  endpoints:
    - port: metrics
      interval: 30s
      path: /metrics
      scheme: http

---
# ServiceMonitor for Reasoning Agent
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: reasoning-agent
  namespace: ai-persona-system
  labels:
    app: reasoning-agent
    prometheus: kube-prometheus
spec:
  selector:
    matchLabels:
      app: reasoning-agent
  endpoints:
    - port: metrics
      interval: 30s
      path: /metrics
      scheme: http

---
# ServiceMonitor for Image Generator Adapter
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: image-generator-adapter
  namespace: ai-persona-system
  labels:
    app: image-generator-adapter
    prometheus: kube-prometheus
spec:
  selector:
    matchLabels:
      app: image-generator-adapter
  endpoints:
    - port: metrics
      interval: 30s
      path: /metrics
      scheme: http

---
# ServiceMonitor for PostgreSQL Exporters
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: postgres-exporter
  namespace: ai-persona-system
  labels:
    app: postgres-exporter
    prometheus: kube-prometheus
spec:
  selector:
    matchLabels:
      app: postgres-exporter
  endpoints:
    - port: metrics
      interval: 30s
      path: /metrics
      scheme: http

---
# ServiceMonitor for Kafka
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: kafka-metrics
  namespace: ai-persona-system
  labels:
    app: kafka
    prometheus: kube-prometheus
spec:
  selector:
    matchLabels:
      app: kafka
  endpoints:
    - port: metrics
      interval: 30s
      path: /metrics
      scheme: http

---
# ServiceMonitor for MinIO
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: minio-metrics
  namespace: ai-persona-system
  labels:
    app: minio
    prometheus: kube-prometheus
spec:
  selector:
    matchLabels:
      app: minio
  endpoints:
    - port: api
      interval: 30s
      path: /minio/v2/metrics/cluster
      scheme: http-------------------------------------------------
filepath = ./k8s/monitoring/prometheus.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: prometheus
  namespace: ai-persona-system

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: prometheus
rules:
  - apiGroups: [""]
    resources:
      - nodes
      - nodes/proxy
      - services
      - endpoints
      - pods
    verbs: ["get", "list", "watch"]
  - apiGroups:
      - extensions
    resources:
      - ingresses
    verbs: ["get", "list", "watch"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prometheus
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus
subjects:
  - kind: ServiceAccount
    name: prometheus
    namespace: ai-persona-system

---
apiVersion: v1
kind: Service
metadata:
  name: prometheus
  namespace: ai-persona-system
  labels:
    app: prometheus
spec:
  ports:
    - port: 9090
      targetPort: 9090
      name: http
  selector:
    app: prometheus
  type: ClusterIP

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
  namespace: ai-persona-system
  labels:
    app: prometheus
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus
  template:
    metadata:
      labels:
        app: prometheus
    spec:
      serviceAccountName: prometheus
      containers:
        - name: prometheus
          image: prom/prometheus:latest
          args:
            - '--config.file=/etc/prometheus/prometheus.yml'
            - '--storage.tsdb.path=/prometheus/'
            - '--web.console.libraries=/usr/share/prometheus/console_libraries'
            - '--web.console.templates=/usr/share/prometheus/consoles'
            - '--web.enable-lifecycle'
          ports:
            - containerPort: 9090
              name: http
          volumeMounts:
            - name: prometheus-config
              mountPath: /etc/prometheus
            - name: prometheus-storage
              mountPath: /prometheus
          resources:
            requests:
              memory: "512Mi"
              cpu: "500m"
            limits:
              memory: "1Gi"
              cpu: "1000m"
      volumes:
        - name: prometheus-config
          configMap:
            name: prometheus-config
        - name: prometheus-storage
          emptyDir: {}-------------------------------------------------
filepath = ./k8s/monitoring/grafana-dashboard-configmap.yaml
-------------------------------------------------
filepath = ./k8s/monitoring/prometheus-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: ai-persona-system
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s

    # Alertmanager configuration
    alerting:
      alertmanagers:
        - static_configs:
            - targets: []

    # Load rules once and periodically evaluate them
    rule_files:
      - '/etc/prometheus/rules/*.yml'

    scrape_configs:
      # Scrape Prometheus itself
      - job_name: 'prometheus'
        static_configs:
          - targets: ['localhost:9090']
      
      # Kubernetes SD for pods
      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
          - role: pod
            namespaces:
              names:
                - ai-persona-system
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: kubernetes_namespace
          - source_labels: [__meta_kubernetes_pod_name]
            action: replace
            target_label: kubernetes_pod_name

  alerts.yml: |
    groups:
      - name: ai-persona-alerts
        interval: 30s
        rules:
          - alert: HighWorkflowFailureRate
            expr: rate(workflows_total{status="failed"}[5m]) > 0.1
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "High workflow failure rate detected"
              description: "{{ $labels.instance }} has a workflow failure rate above 10% (current value: {{ $value }})"
          
          - alert: LowAgentAvailability
            expr: up{job="kubernetes-pods", app="agent-chassis"} < 3
            for: 2m
            labels:
              severity: critical
            annotations:
              summary: "Low agent chassis availability"
              description: "Less than 3 agent chassis pods are running"
          
          - alert: DatabaseDown
            expr: up{job="kubernetes-pods", app=~"postgres-.*|mysql-.*"} == 0
            for: 1m
            labels:
              severity: critical
            annotations:
              summary: "Database {{ $labels.app }} is down"
              description: "Database {{ $labels.app }} has been down for more than 1 minute"
          
          - alert: KafkaLag
            expr: kafka_consumer_lag > 1000
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "High Kafka consumer lag"
              description: "Consumer group {{ $labels.group }} has lag > 1000 messages"-------------------------------------------------
filepath = ./k8s/monitoring/grafana.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-datasources
  namespace: ai-persona-system
data:
  datasources.yaml: |
    apiVersion: 1
    datasources:
      - name: Prometheus
        type: prometheus
        url: http://prometheus:9090
        access: proxy
        isDefault: true
        editable: true

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-dashboards
  namespace: ai-persona-system
data:
  dashboards.yaml: |
    apiVersion: 1
    providers:
      - name: 'default'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        options:
          path: /etc/grafana/dashboards

---
apiVersion: v1
kind: Service
metadata:
  name: grafana
  namespace: ai-persona-system
  labels:
    app: grafana
spec:
  ports:
    - port: 3000
      targetPort: 3000
      name: http
  selector:
    app: grafana
  type: ClusterIP

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
  namespace: ai-persona-system
  labels:
    app: grafana
spec:
  replicas: 1
  selector:
    matchLabels:
      app: grafana
  template:
    metadata:
      labels:
        app: grafana
    spec:
      containers:
        - name: grafana
          image: grafana/grafana:latest
          ports:
            - containerPort: 3000
              name: http
          env:
            - name: GF_SECURITY_ADMIN_USER
              value: "admin"
            - name: GF_SECURITY_ADMIN_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: grafana-secrets
                  key: admin-password
            - name: GF_INSTALL_PLUGINS
              value: "grafana-clock-panel,grafana-simple-json-datasource"
          volumeMounts:
            - name: grafana-datasources
              mountPath: /etc/grafana/provisioning/datasources
            - name: grafana-dashboards-config
              mountPath: /etc/grafana/provisioning/dashboards
            - name: grafana-storage
              mountPath: /var/lib/grafana
          resources:
            requests:
              memory: "256Mi"
              cpu: "100m"
            limits:
              memory: "512Mi"
              cpu: "500m"
      volumes:
        - name: grafana-datasources
          configMap:
            name: grafana-datasources
        - name: grafana-dashboards-config
          configMap:
            name: grafana-dashboards
        - name: grafana-storage
          emptyDir: {}-------------------------------------------------
filepath = ./k8s/monitoring/pod-monitor.yaml
# k8s/monitoring/pod-monitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: PodMonitor
metadata:
  name: ai-persona-pods
  namespace: ai-persona-system
  labels:
    prometheus: kube-prometheus
spec:
  selector:
    matchLabels:
      prometheus.io/scrape: "true"
  namespaceSelector:
    matchNames:
      - ai-persona-system
  podMetricsEndpoints:
    - port: metrics
      interval: 30s
      path: /metrics-------------------------------------------------
filepath = ./k8s/auth-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: auth-service
  namespace: ai-persona-system
  labels:
    app: auth-service
spec:
  ports:
    - port: 8081
      targetPort: 8081
      name: http
  selector:
    app: auth-service
  type: ClusterIP

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: auth-service
  namespace: ai-persona-system
  labels:
    app: auth-service
spec:
  replicas: 2
  selector:
    matchLabels:
      app: auth-service
  template:
    metadata:
      labels:
        app: auth-service
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9090"
        prometheus.io/path: "/metrics"
    spec:
      containers:
        - name: auth-service
          image: ai-persona-system/auth-service:latest
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 8081
              name: http
            - containerPort: 9090
              name: metrics
          env:
            - name: SERVICE_NAME
              value: "auth-service"
            - name: SERVICE_VERSION
              value: "1.0.0"
            - name: SERVICE_ENVIRONMENT
              value: "production"
            - name: SERVER_PORT
              value: "8081"
            - name: LOGGING_LEVEL
              value: "info"
            - name: AUTH_DB_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: db-secrets
                  key: auth-db-password
            - name: JWT_SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: auth-secrets
                  key: jwt-secret
          envFrom:
            - configMapRef:
                name: common-config
          resources:
            requests:
              memory: "256Mi"
              cpu: "100m"
            limits:
              memory: "512Mi"
              cpu: "500m"
          livenessProbe:
            httpGet:
              path: /health
              port: 8081
            initialDelaySeconds: 30
            periodSeconds: 10
          readinessProbe:
            httpGet:
              path: /health
              port: 8081
            initialDelaySeconds: 5
            periodSeconds: 5-------------------------------------------------
filepath = ./k8s/reasoning-agent.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: reasoning-agent
  namespace: ai-persona-system
  labels:
    app: reasoning-agent
spec:
  replicas: 2
  selector:
    matchLabels:
      app: reasoning-agent
  template:
    metadata:
      labels:
        app: reasoning-agent
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9090"
        prometheus.io/path: "/metrics"
    spec:
      containers:
        - name: reasoning-agent
          image: ai-persona-system/reasoning-agent:latest
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 9090
              name: metrics
          env:
            - name: SERVICE_NAME
              value: "reasoning-agent"
            - name: SERVICE_VERSION
              value: "1.0.0"
            - name: SERVICE_ENVIRONMENT
              value: "production"
            - name: LOGGING_LEVEL
              value: "info"
            - name: ANTHROPIC_API_KEY
              valueFrom:
                secretKeyRef:
                  name: ai-secrets
                  key: anthropic-api-key
          envFrom:
            - configMapRef:
                name: common-config
          resources:
            requests:
              memory: "256Mi"
              cpu: "100m"
            limits:
              memory: "512Mi"
              cpu: "500m"
          livenessProbe:
            httpGet:
              path: /health
              port: 9090
            initialDelaySeconds: 30
            periodSeconds: 10-------------------------------------------------
filepath = ./k8s/postgres-templates.yaml
apiVersion: v1
kind: Service
metadata:
  name: postgres-templates
  namespace: ai-persona-system
  labels:
    app: postgres-templates
spec:
  ports:
    - port: 5432
      targetPort: 5432
      name: postgres
  selector:
    app: postgres-templates
  type: ClusterIP
  clusterIP: None

---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres-templates
  namespace: ai-persona-system
spec:
  serviceName: postgres-templates
  replicas: 1
  selector:
    matchLabels:
      app: postgres-templates
  template:
    metadata:
      labels:
        app: postgres-templates
    spec:
      containers:
        - name: postgres
          image: postgres:16-alpine
          ports:
            - containerPort: 5432
              name: postgres
          env:
            - name: POSTGRES_DB
              value: "templates_db"
            - name: POSTGRES_USER
              value: "templates_user"
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: db-secrets
                  key: templates-db-password
            - name: PGDATA
              value: /var/lib/postgresql/data/pgdata
          volumeMounts:
            - name: postgres-storage
              mountPath: /var/lib/postgresql/data
          resources:
            requests:
              memory: "256Mi"
              cpu: "250m"
            limits:
              memory: "512Mi"
              cpu: "500m"
          livenessProbe:
            exec:
              command:
                - pg_isready
                - -U
                - templates_user
            initialDelaySeconds: 30
            periodSeconds: 10
  volumeClaimTemplates:
    - metadata:
        name: postgres-storage
      spec:
        accessModes: ["ReadWriteOnce"]
        storageClassName: "standard"
        resources:
          requests:
            storage: 5Gi-------------------------------------------------
filepath = ./k8s/mysql-auth.yaml
apiVersion: v1
kind: Service
metadata:
  name: mysql-auth
  namespace: ai-persona-system
  labels:
    app: mysql-auth
spec:
  ports:
    - port: 3306
      targetPort: 3306
      name: mysql
  selector:
    app: mysql-auth
  type: ClusterIP
  clusterIP: None

---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mysql-auth
  namespace: ai-persona-system
spec:
  serviceName: mysql-auth
  replicas: 1
  selector:
    matchLabels:
      app: mysql-auth
  template:
    metadata:
      labels:
        app: mysql-auth
    spec:
      containers:
        - name: mysql
          image: mysql:8.0
          ports:
            - containerPort: 3306
              name: mysql
          env:
            - name: MYSQL_DATABASE
              value: "auth_db"
            - name: MYSQL_USER
              value: "auth_user"
            - name: MYSQL_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: db-secrets
                  key: auth-db-password
            - name: MYSQL_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: db-secrets
                  key: mysql-root-password
          volumeMounts:
            - name: mysql-storage
              mountPath: /var/lib/mysql
          resources:
            requests:
              memory: "512Mi"
              cpu: "500m"
            limits:
              memory: "1Gi"
              cpu: "1000m"
          livenessProbe:
            exec:
              command:
                - mysqladmin
                - ping
                - -h
                - localhost
            initialDelaySeconds: 30
            periodSeconds: 10
  volumeClaimTemplates:
    - metadata:
        name: mysql-storage
      spec:
        accessModes: ["ReadWriteOnce"]
        storageClassName: "standard"
        resources:
          requests:
            storage: 5Gi-------------------------------------------------
filepath = ./k8s/core-manager.yaml
apiVersion: v1
kind: Service
metadata:
  name: core-manager
  namespace: ai-persona-system
  labels:
    app: core-manager
spec:
  ports:
    - port: 8088
      targetPort: 8088
      name: http
  selector:
    app: core-manager
  type: ClusterIP

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: core-manager
  namespace: ai-persona-system
  labels:
    app: core-manager
spec:
  replicas: 3
  selector:
    matchLabels:
      app: core-manager
  template:
    metadata:
      labels:
        app: core-manager
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9090"
        prometheus.io/path: "/metrics"
    spec:
      containers:
        - name: core-manager
          image: ai-persona-system/core-manager:latest
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 8088
              name: http
            - containerPort: 9090
              name: metrics
          env:
            - name: SERVICE_NAME
              value: "core-manager"
            - name: SERVICE_VERSION
              value: "1.0.0"
            - name: SERVICE_ENVIRONMENT
              value: "production"
            - name: SERVER_PORT
              value: "8088"
            - name: LOGGING_LEVEL
              value: "info"
            - name: CLIENTS_DB_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: db-secrets
                  key: clients-db-password
            - name: TEMPLATES_DB_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: db-secrets
                  key: templates-db-password
            - name: MINIO_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: minio-secrets
                  key: access-key
            - name: MINIO_SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: minio-secrets
                  key: secret-key
          envFrom:
            - configMapRef:
                name: common-config
          resources:
            requests:
              memory: "512Mi"
              cpu: "250m"
            limits:
              memory: "1Gi"
              cpu: "1000m"
          livenessProbe:
            httpGet:
              path: /health
              port: 8088
            initialDelaySeconds: 30
            periodSeconds: 10
          readinessProbe:
            httpGet:
              path: /health
              port: 8088
            initialDelaySeconds: 5
            periodSeconds: 5-------------------------------------------------
filepath = ./internal/adapters/imagegenerator/adapter.go
// FILE: internal/adapters/imagegenerator/adapter.go
package imagegenerator

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"github.com/aws/aws-sdk-go-v2/aws"
	"github.com/aws/aws-sdk-go-v2/credentials"
	"io"
	"net/http"
	"os"
	"time"

	"github.com/google/uuid"
	"github.com/gqls/ai-persona-system/platform/config"
	"github.com/gqls/ai-persona-system/platform/kafka"
	"github.com/gqls/ai-persona-system/platform/storage" // Our new storage library
	"go.uber.org/zap"
)

const (
	requestTopic  = "system.adapter.image.generate"
	responseTopic = "system.responses.image"
	consumerGroup = "image-generator-adapter-group"
)

// RequestPayload defines the expected data for an image generation request.
type RequestPayload struct {
	Action string `json:"action"` // e.g., "generate_from_prompt"
	Data   struct {
		Prompt      string  `json:"prompt"`
		AspectRatio string  `json:"aspect_ratio,omitempty"`
		Style       string  `json:"style,omitempty"`
		Seed        float64 `json:"seed,omitempty"`
	} `json:"data"`
}

// ResponsePayload defines the data sent back after successful generation.
type ResponsePayload struct {
	ImageURI string `json:"image_uri"`
	Prompt   string `json:"prompt"`
	Seed     int64  `json:"seed"`
}

// Adapter handles the translation between our internal system and an external API.
type Adapter struct {
	ctx           context.Context
	logger        *zap.Logger
	consumer      *kafka.Consumer
	producer      *kafka.Producer
	storageClient storage.Client // Interface for S3/MinIO
	httpClient    *http.Client
	externalAPI   string
	apiKey        string
}

// NewAdapter initializes all dependencies for the adapter.
func NewAdapter(ctx context.Context, cfg *config.ServiceConfig, logger *zap.Logger) (*Adapter, error) {
	// Initialize Kafka consumer and producer from platform library
	consumer, err := kafka.NewConsumer(cfg.Infrastructure.KafkaBrokers, requestTopic, consumerGroup, logger)
	if err != nil {
		return nil, fmt.Errorf("failed to create kafka consumer: %w", err)
	}

	producer, err := kafka.NewProducer(cfg.Infrastructure.KafkaBrokers, logger)
	if err != nil {
		consumer.Close()
		return nil, fmt.Errorf("failed to create kafka producer: %w", err)
	}

	// Initialize Object Storage client from platform library
	storageClient, err := storage.NewS3Client(ctx, cfg.Infrastructure.ObjectStorage)
	if err != nil {
		consumer.Close()
		producer.Close()
		return nil, fmt.Errorf("failed to create storage client: %w", err)
	}

	// In a real config, you'd have a section for this adapter's specific settings
	externalAPIEndpoint := "https://api.stability.ai/v1/generation/stable-diffusion-v1-6/text-to-image"
	apiKey := os.Getenv("STABILITY_API_KEY") // Securely get API key from environment

	return &Adapter{
		ctx:           ctx,
		logger:        logger,
		consumer:      consumer,
		producer:      producer,
		storageClient: storageClient,
		httpClient:    &http.Client{Timeout: 90 * time.Second},
		externalAPI:   externalAPIEndpoint,
		apiKey:        apiKey,
	}, nil
}

// Run starts the consumer loop.
func (a *Adapter) Run() error {
	for {
		select {
		case <-a.ctx.Done():
			a.consumer.Close()
			a.producer.Close()
			return nil
		default:
			msg, err := a.consumer.FetchMessage(a.ctx)
			if err != nil {
				if err == context.Canceled {
					continue
				}
				a.logger.Error("Failed to fetch message", zap.Error(err))
				continue
			}
			go a.handleMessage(msg)
		}
	}
}

// handleMessage processes a single image generation request.
func (a *Adapter) handleMessage(msg kafka.Message) {
	headers := kafka.HeadersToMap(msg.Headers)
	l := a.logger.With(zap.String("correlation_id", headers["correlation_id"]))

	var req RequestPayload
	if err := json.Unmarshal(msg.Value, &req); err != nil {
		l.Error("Failed to unmarshal request payload", zap.Error(err))
		a.consumer.CommitMessages(context.Background(), msg)
		return
	}

	// 1. Call the external API
	imageData, err := a.callExternalImageAPI(req.Data.Prompt)
	if err != nil {
		l.Error("External image API call failed", zap.Error(err))
		// Here you might produce an error message back to a failure topic
		a.consumer.CommitMessages(context.Background(), msg)
		return
	}

	// 2. Upload the resulting image to Object Storage
	fileName := fmt.Sprintf("images/%s/%s.png", headers["client_id"], uuid.NewString())
	imageURI, err := a.storageClient.Upload(a.ctx, fileName, "image/png", bytes.NewReader(imageData))
	if err != nil {
		l.Error("Failed to upload image to object storage", zap.Error(err))
		a.consumer.CommitMessages(context.Background(), msg)
		return
	}
	l.Info("Image successfully uploaded to storage", zap.String("uri", imageURI))

	// 3. Produce a standard response message with the URI
	responsePayload := ResponsePayload{
		ImageURI: imageURI,
		Prompt:   req.Data.Prompt,
	}
	responseBytes, _ := json.Marshal(responsePayload)

	// Prepare response headers
	responseHeaders := map[string]string{
		"correlation_id": headers["correlation_id"],
		"causation_id":   headers["request_id"],
		"request_id":     uuid.NewString(),
	}

	if err := a.producer.Produce(a.ctx, responseTopic, responseHeaders, msg.Key, responseBytes); err != nil {
		l.Error("Failed to produce response message", zap.Error(err))
	}

	// 4. Commit the original message
	a.consumer.CommitMessages(context.Background(), msg)
}

// callExternalImageAPI is a placeholder for the actual HTTP call.
func (a *Adapter) callExternalImageAPI(prompt string) ([]byte, error) {
	// ... This is where you would build the HTTP request for Stability AI,
	// add the `Authorization: Bearer ...` header, and handle the response.
	// For this example, we'll return a placeholder byte slice.
	a.logger.Info("Calling external image API", zap.String("prompt", prompt))
	return []byte("---simulated-png-image-data---"), nil
}
-------------------------------------------------
filepath = ./internal/auth-service/gateway/handlers.go
package gateway

import (
	"io"
	"net/http"
	"net/url"
	"strings"

	"github.com/gin-gonic/gin"
	"go.uber.org/zap"
)

// HTTPHandler handles gateway HTTP requests
type HTTPHandler struct {
	service *Service
	logger  *zap.Logger
}

// NewHTTPHandler creates a new gateway HTTP handler
func NewHTTPHandler(service *Service, logger *zap.Logger) *HTTPHandler {
	return &HTTPHandler{
		service: service,
		logger:  logger,
	}
}

// ProxyToCoreManager proxies requests to the core manager service
func (h *HTTPHandler) ProxyToCoreManager(c *gin.Context) {
	// Build target URL
	targetPath := c.Param("path")
	if targetPath == "" {
		targetPath = strings.TrimPrefix(c.Request.URL.Path, "/api/v1")
	}

	targetURL := h.service.coreManagerURL.ResolveReference(&url.URL{
		Path:     "/api/v1" + targetPath,
		RawQuery: c.Request.URL.RawQuery,
	})

	h.logger.Debug("Proxying request",
		zap.String("method", c.Request.Method),
		zap.String("target", targetURL.String()))

	// Create new request
	req, err := http.NewRequest(c.Request.Method, targetURL.String(), c.Request.Body)
	if err != nil {
		h.logger.Error("Failed to create proxy request", zap.Error(err))
		c.JSON(http.StatusInternalServerError, gin.H{"error": "Failed to create request"})
		return
	}

	// Copy headers
	for key, values := range c.Request.Header {
		for _, value := range values {
			req.Header.Add(key, value)
		}
	}

	// Add user context headers
	req.Header.Set("X-User-ID", c.GetString("user_id"))
	req.Header.Set("X-Client-ID", c.GetString("client_id"))
	req.Header.Set("X-User-Role", c.GetString("user_role"))
	req.Header.Set("X-User-Tier", c.GetString("user_tier"))
	req.Header.Set("X-User-Email", c.GetString("user_email"))

	// Add permissions
	if perms, exists := c.Get("user_permissions"); exists {
		if permissions, ok := perms.([]string); ok {
			req.Header.Set("X-User-Permissions", strings.Join(permissions, ","))
		}
	}

	// Execute request
	resp, err := h.service.httpClient.Do(req)
	if err != nil {
		h.logger.Error("Proxy request failed", zap.Error(err))
		c.JSON(http.StatusBadGateway, gin.H{"error": "Service unavailable"})
		return
	}
	defer resp.Body.Close()

	// Copy response headers
	for key, values := range resp.Header {
		for _, value := range values {
			c.Header(key, value)
		}
	}

	// Set status code
	c.Status(resp.StatusCode)

	// Copy response body
	_, err = io.Copy(c.Writer, resp.Body)
	if err != nil {
		h.logger.Error("Failed to copy response body", zap.Error(err))
	}
}

// Template Management Handlers

func (h *HTTPHandler) HandleListTemplates(c *gin.Context) {
	h.proxyToCoreManager(c, "/templates")
}

func (h *HTTPHandler) HandleCreateTemplate(c *gin.Context) {
	h.proxyToCoreManager(c, "/templates")
}

func (h *HTTPHandler) HandleGetTemplate(c *gin.Context) {
	templateID := c.Param("id")
	h.proxyToCoreManager(c, "/templates/"+templateID)
}

func (h *HTTPHandler) HandleUpdateTemplate(c *gin.Context) {
	templateID := c.Param("id")
	h.proxyToCoreManager(c, "/templates/"+templateID)
}

func (h *HTTPHandler) HandleDeleteTemplate(c *gin.Context) {
	templateID := c.Param("id")
	h.proxyToCoreManager(c, "/templates/"+templateID)
}

// Instance Management Handlers

func (h *HTTPHandler) HandleCreateInstance(c *gin.Context) {
	h.proxyToCoreManager(c, "/personas/instances")
}

func (h *HTTPHandler) HandleListInstances(c *gin.Context) {
	h.proxyToCoreManager(c, "/personas/instances")
}

func (h *HTTPHandler) HandleGetInstance(c *gin.Context) {
	instanceID := c.Param("id")
	h.proxyToCoreManager(c, "/personas/instances/"+instanceID)
}

func (h *HTTPHandler) HandleUpdateInstance(c *gin.Context) {
	instanceID := c.Param("id")
	h.proxyToCoreManager(c, "/personas/instances/"+instanceID)
}

func (h *HTTPHandler) HandleDeleteInstance(c *gin.Context) {
	instanceID := c.Param("id")
	h.proxyToCoreManager(c, "/personas/instances/"+instanceID)
}

// Project Management Handlers

func (h *HTTPHandler) HandleListProjects(c *gin.Context) {
	h.proxyToCoreManager(c, "/projects")
}

func (h *HTTPHandler) HandleCreateProject(c *gin.Context) {
	h.proxyToCoreManager(c, "/projects")
}

func (h *HTTPHandler) HandleGetProject(c *gin.Context) {
	projectID := c.Param("id")
	h.proxyToCoreManager(c, "/projects/"+projectID)
}

func (h *HTTPHandler) HandleUpdateProject(c *gin.Context) {
	projectID := c.Param("id")
	h.proxyToCoreManager(c, "/projects/"+projectID)
}

func (h *HTTPHandler) HandleDeleteProject(c *gin.Context) {
	projectID := c.Param("id")
	h.proxyToCoreManager(c, "/projects/"+projectID)
}

// proxyToCoreManager is a helper method
func (h *HTTPHandler) proxyToCoreManager(c *gin.Context, path string) {
	c.Params = append(c.Params, gin.Param{Key: "path", Value: path})
	h.ProxyToCoreManager(c)
}
-------------------------------------------------
filepath = ./internal/auth-service/gateway/proxy.go
package gateway

import (
	"net/http"
	"net/http/httputil"
	"net/url"

	"github.com/gin-gonic/gin"
	"github.com/gorilla/websocket"
	"go.uber.org/zap"
)

// WebSocketProxy handles WebSocket connections
type WebSocketProxy struct {
	targetURL *url.URL
	upgrader  websocket.Upgrader
	logger    *zap.Logger
}

// NewWebSocketProxy creates a new WebSocket proxy
func NewWebSocketProxy(targetURL *url.URL, logger *zap.Logger) *WebSocketProxy {
	return &WebSocketProxy{
		targetURL: targetURL,
		upgrader: websocket.Upgrader{
			CheckOrigin: func(r *http.Request) bool {
				// Configure based on your security requirements
				return true
			},
			ReadBufferSize:  1024,
			WriteBufferSize: 1024,
		},
		logger: logger,
	}
}

// ProxyWebSocket proxies WebSocket connections
func (p *WebSocketProxy) ProxyWebSocket(c *gin.Context) {
	// Build target WebSocket URL
	targetURL := *p.targetURL
	targetURL.Scheme = "ws"
	if p.targetURL.Scheme == "https" {
		targetURL.Scheme = "wss"
	}
	targetURL.Path = c.Request.URL.Path
	targetURL.RawQuery = c.Request.URL.RawQuery

	p.logger.Debug("Proxying WebSocket connection",
		zap.String("target", targetURL.String()))

	// Connect to target
	targetHeader := http.Header{}
	for key, values := range c.Request.Header {
		if key == "Upgrade" || key == "Connection" || key == "Sec-Websocket-Key" ||
			key == "Sec-Websocket-Version" || key == "Sec-Websocket-Extensions" {
			continue
		}
		targetHeader[key] = values
	}

	// Add user context headers
	targetHeader.Set("X-User-ID", c.GetString("user_id"))
	targetHeader.Set("X-Client-ID", c.GetString("client_id"))

	targetConn, resp, err := websocket.DefaultDialer.Dial(targetURL.String(), targetHeader)
	if err != nil {
		p.logger.Error("Failed to connect to target WebSocket", zap.Error(err))
		if resp != nil {
			c.Status(resp.StatusCode)
		} else {
			c.Status(http.StatusBadGateway)
		}
		return
	}
	defer targetConn.Close()

	// Upgrade client connection
	clientConn, err := p.upgrader.Upgrade(c.Writer, c.Request, nil)
	if err != nil {
		p.logger.Error("Failed to upgrade client connection", zap.Error(err))
		return
	}
	defer clientConn.Close()

	// Proxy messages
	errChan := make(chan error, 2)

	// Client to target
	go func() {
		for {
			messageType, data, err := clientConn.ReadMessage()
			if err != nil {
				errChan <- err
				return
			}

			if err := targetConn.WriteMessage(messageType, data); err != nil {
				errChan <- err
				return
			}
		}
	}()

	// Target to client
	go func() {
		for {
			messageType, data, err := targetConn.ReadMessage()
			if err != nil {
				errChan <- err
				return
			}

			if err := clientConn.WriteMessage(messageType, data); err != nil {
				errChan <- err
				return
			}
		}
	}()

	// Wait for error
	err = <-errChan
	p.logger.Debug("WebSocket proxy closed", zap.Error(err))
}

// ReverseProxy creates a standard HTTP reverse proxy
func (s *Service) ReverseProxy() *httputil.ReverseProxy {
	proxy := httputil.NewSingleHostReverseProxy(s.coreManagerURL)

	// Customize the director
	originalDirector := proxy.Director
	proxy.Director = func(req *http.Request) {
		originalDirector(req)

		// Add user context from gin context if available
		if ginCtx, ok := req.Context().Value("gin_context").(*gin.Context); ok {
			req.Header.Set("X-User-ID", ginCtx.GetString("user_id"))
			req.Header.Set("X-Client-ID", ginCtx.GetString("client_id"))
			req.Header.Set("X-User-Role", ginCtx.GetString("user_role"))
			req.Header.Set("X-User-Tier", ginCtx.GetString("user_tier"))
		}
	}

	// Custom error handler
	proxy.ErrorHandler = func(w http.ResponseWriter, r *http.Request, err error) {
		s.logger.Error("Reverse proxy error", zap.Error(err))
		w.WriteHeader(http.StatusBadGateway)
		w.Write([]byte(`{"error": "Service temporarily unavailable"}`))
	}

	return proxy
}
-------------------------------------------------
filepath = ./internal/auth-service/gateway/service.go
package gateway

import (
	"net/http"
	"net/url"
	"time"

	"github.com/gqls/ai-persona-system/platform/config"
	"go.uber.org/zap"
)

// Service handles API gateway functionality
type Service struct {
	coreManagerURL *url.URL
	httpClient     *http.Client
	logger         *zap.Logger
}

// NewService creates a new gateway service
func NewService(cfg *config.ServiceConfig, logger *zap.Logger) *Service {
	coreManagerURL, _ := url.Parse(cfg.Custom["core_manager_url"].(string))

	return &Service{
		coreManagerURL: coreManagerURL,
		httpClient: &http.Client{
			Timeout: 30 * time.Second,
		},
		logger: logger,
	}
}

// GetCoreManagerURL returns the core manager URL
func (s *Service) GetCoreManagerURL() *url.URL {
	return s.coreManagerURL
}
-------------------------------------------------
filepath = ./internal/auth-service/user/handlers.go
package user

import (
	"net/http"

	"github.com/gin-gonic/gin"
)

// Handlers wraps the user service for HTTP handling
type Handlers struct {
	service *Service
}

// NewHandlers creates new user handlers
func NewHandlers(service *Service) *Handlers {
	return &Handlers{service: service}
}

// HandleGetCurrentUser returns the current user's details
func (h *Handlers) HandleGetCurrentUser(c *gin.Context) {
	userID := c.GetString("user_id")

	user, err := h.service.GetUser(c.Request.Context(), userID)
	if err != nil {
		c.JSON(http.StatusNotFound, gin.H{"error": "User not found"})
		return
	}

	c.JSON(http.StatusOK, user)
}

// HandleUpdateCurrentUser updates the current user's details
func (h *Handlers) HandleUpdateCurrentUser(c *gin.Context) {
	userID := c.GetString("user_id")

	var req UpdateUserRequest
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
		return
	}

	if err := h.service.UpdateUser(c.Request.Context(), userID, &req); err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": "Failed to update user"})
		return
	}

	// Return updated user
	user, _ := h.service.GetUser(c.Request.Context(), userID)
	c.JSON(http.StatusOK, user)
}

// HandleChangePassword changes the user's password
func (h *Handlers) HandleChangePassword(c *gin.Context) {
	userID := c.GetString("user_id")

	var req ChangePasswordRequest
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
		return
	}

	if err := h.service.ChangePassword(c.Request.Context(), userID, &req); err != nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
		return
	}

	c.JSON(http.StatusOK, gin.H{"message": "Password changed successfully"})
}

// HandleDeleteAccount deletes the user's account
func (h *Handlers) HandleDeleteAccount(c *gin.Context) {
	userID := c.GetString("user_id")

	if err := h.service.DeleteUser(c.Request.Context(), userID); err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": "Failed to delete account"})
		return
	}

	c.JSON(http.StatusOK, gin.H{"message": "Account deleted successfully"})
}
-------------------------------------------------
filepath = ./internal/auth-service/user/repository.go
package user

import (
	"context"
	"database/sql"
	"fmt"
	"strings"
	"time"

	"github.com/google/uuid"
	"go.uber.org/zap"
	"golang.org/x/crypto/bcrypt"
)

// Repository handles user data access
type Repository struct {
	db     *sql.DB
	logger *zap.Logger
}

// NewRepository creates a new user repository
func NewRepository(db *sql.DB, logger *zap.Logger) *Repository {
	return &Repository{
		db:     db,
		logger: logger,
	}
}

// CreateUser creates a new user with profile
func (r *Repository) CreateUser(ctx context.Context, req *CreateUserRequest) (*User, error) {
	// Start transaction
	tx, err := r.db.BeginTx(ctx, nil)
	if err != nil {
		return nil, fmt.Errorf("failed to begin transaction: %w", err)
	}
	defer tx.Rollback()

	// Hash password
	hashedPassword, err := bcrypt.GenerateFromPassword([]byte(req.Password), bcrypt.DefaultCost)
	if err != nil {
		return nil, fmt.Errorf("failed to hash password: %w", err)
	}

	user := &User{
		ID:               uuid.New().String(),
		Email:            strings.ToLower(req.Email),
		PasswordHash:     string(hashedPassword),
		Role:             "user", // Default role
		ClientID:         req.ClientID,
		SubscriptionTier: "free", // Default tier
		IsActive:         true,
		EmailVerified:    false,
		CreatedAt:        time.Now(),
		UpdatedAt:        time.Now(),
	}

	// Insert user
	query := `
        INSERT INTO users (id, email, password_hash, role, client_id, subscription_tier, 
                          is_active, email_verified, created_at, updated_at)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    `

	_, err = tx.ExecContext(ctx, query,
		user.ID, user.Email, user.PasswordHash, user.Role, user.ClientID,
		user.SubscriptionTier, user.IsActive, user.EmailVerified,
		user.CreatedAt, user.UpdatedAt)

	if err != nil {
		if strings.Contains(err.Error(), "duplicate") {
			return nil, fmt.Errorf("user with email %s already exists", req.Email)
		}
		return nil, fmt.Errorf("failed to create user: %w", err)
	}

	// Create user profile
	profile := &UserProfile{
		UserID:    user.ID,
		FirstName: req.FirstName,
		LastName:  req.LastName,
		Company:   req.Company,
	}

	profileQuery := `
        INSERT INTO user_profiles (user_id, first_name, last_name, company)
        VALUES (?, ?, ?, ?)
    `

	_, err = tx.ExecContext(ctx, profileQuery,
		profile.UserID, profile.FirstName, profile.LastName, profile.Company)

	if err != nil {
		return nil, fmt.Errorf("failed to create user profile: %w", err)
	}

	// Commit transaction
	if err := tx.Commit(); err != nil {
		return nil, fmt.Errorf("failed to commit transaction: %w", err)
	}

	user.Profile = profile
	r.logger.Info("User created successfully", zap.String("user_id", user.ID))

	return user, nil
}

// GetUserByEmail retrieves a user by email
func (r *Repository) GetUserByEmail(ctx context.Context, email string) (*User, error) {
	email = strings.ToLower(email)

	var user User
	query := `
        SELECT id, email, password_hash, role, client_id, subscription_tier, 
               is_active, email_verified, created_at, updated_at, last_login_at
        FROM users
        WHERE email = ? AND is_active = true
    `

	err := r.db.QueryRowContext(ctx, query, email).Scan(
		&user.ID, &user.Email, &user.PasswordHash, &user.Role, &user.ClientID,
		&user.SubscriptionTier, &user.IsActive, &user.EmailVerified,
		&user.CreatedAt, &user.UpdatedAt, &user.LastLoginAt)

	if err != nil {
		if err == sql.ErrNoRows {
			return nil, fmt.Errorf("user not found")
		}
		return nil, fmt.Errorf("failed to get user: %w", err)
	}

	// Load profile
	profile, err := r.getUserProfile(ctx, user.ID)
	if err == nil {
		user.Profile = profile
	}

	// Load permissions
	permissions, err := r.getUserPermissions(ctx, user.ID)
	if err == nil {
		user.Permissions = permissions
	}

	return &user, nil
}

// GetUserByID retrieves a user by ID
func (r *Repository) GetUserByID(ctx context.Context, userID string) (*User, error) {
	var user User
	query := `
        SELECT id, email, password_hash, role, client_id, subscription_tier, 
               is_active, email_verified, created_at, updated_at, last_login_at
        FROM users
        WHERE id = ? AND is_active = true
    `

	err := r.db.QueryRowContext(ctx, query, userID).Scan(
		&user.ID, &user.Email, &user.PasswordHash, &user.Role, &user.ClientID,
		&user.SubscriptionTier, &user.IsActive, &user.EmailVerified,
		&user.CreatedAt, &user.UpdatedAt, &user.LastLoginAt)

	if err != nil {
		if err == sql.ErrNoRows {
			return nil, fmt.Errorf("user not found")
		}
		return nil, fmt.Errorf("failed to get user: %w", err)
	}

	// Load profile
	profile, err := r.getUserProfile(ctx, user.ID)
	if err == nil {
		user.Profile = profile
	}

	// Load permissions
	permissions, err := r.getUserPermissions(ctx, user.ID)
	if err == nil {
		user.Permissions = permissions
	}

	return &user, nil
}

// getUserProfile loads user profile
func (r *Repository) getUserProfile(ctx context.Context, userID string) (*UserProfile, error) {
	var profile UserProfile
	query := `
        SELECT user_id, first_name, last_name, company, phone, avatar_url, preferences
        FROM user_profiles
        WHERE user_id = ?
    `

	var preferences sql.NullString
	err := r.db.QueryRowContext(ctx, query, userID).Scan(
		&profile.UserID, &profile.FirstName, &profile.LastName,
		&profile.Company, &profile.Phone, &profile.AvatarURL, &preferences)

	if err != nil {
		return nil, err
	}

	if preferences.Valid {
		json.Unmarshal([]byte(preferences.String), &profile.Preferences)
	}

	return &profile, nil
}

// getUserPermissions loads user permissions
func (r *Repository) getUserPermissions(ctx context.Context, userID string) ([]string, error) {
	query := `
        SELECT p.name
        FROM permissions p
        JOIN user_permissions up ON p.id = up.permission_id
        WHERE up.user_id = ?
    `

	rows, err := r.db.QueryContext(ctx, query, userID)
	if err != nil {
		return nil, err
	}
	defer rows.Close()

	var permissions []string
	for rows.Next() {
		var perm string
		if err := rows.Scan(&perm); err != nil {
			continue
		}
		permissions = append(permissions, perm)
	}

	return permissions, nil
}

// UpdateUser updates user information
func (r *Repository) UpdateUser(ctx context.Context, userID string, req *UpdateUserRequest) error {
	tx, err := r.db.BeginTx(ctx, nil)
	if err != nil {
		return fmt.Errorf("failed to begin transaction: %w", err)
	}
	defer tx.Rollback()

	// Update user table
	userQuery := `UPDATE users SET updated_at = ? WHERE id = ?`
	_, err = tx.ExecContext(ctx, userQuery, time.Now(), userID)
	if err != nil {
		return fmt.Errorf("failed to update user: %w", err)
	}

	// Update profile
	var setClauses []string
	var args []interface{}

	if req.FirstName != nil {
		setClauses = append(setClauses, "first_name = ?")
		args = append(args, *req.FirstName)
	}
	if req.LastName != nil {
		setClauses = append(setClauses, "last_name = ?")
		args = append(args, *req.LastName)
	}
	if req.Company != nil {
		setClauses = append(setClauses, "company = ?")
		args = append(args, *req.Company)
	}
	if req.Phone != nil {
		setClauses = append(setClauses, "phone = ?")
		args = append(args, *req.Phone)
	}
	if req.Preferences != nil {
		prefsJSON, _ := json.Marshal(req.Preferences)
		setClauses = append(setClauses, "preferences = ?")
		args = append(args, string(prefsJSON))
	}

	if len(setClauses) > 0 {
		args = append(args, userID)
		profileQuery := fmt.Sprintf(
			"UPDATE user_profiles SET %s WHERE user_id = ?",
			strings.Join(setClauses, ", "),
		)

		_, err = tx.ExecContext(ctx, profileQuery, args...)
		if err != nil {
			return fmt.Errorf("failed to update profile: %w", err)
		}
	}

	if err := tx.Commit(); err != nil {
		return fmt.Errorf("failed to commit transaction: %w", err)
	}

	return nil
}

// ValidatePassword checks if the provided password matches
func (r *Repository) ValidatePassword(user *User, password string) bool {
	err := bcrypt.CompareHashAndPassword([]byte(user.PasswordHash), []byte(password))
	return err == nil
}

// UpdatePassword updates user password
func (r *Repository) UpdatePassword(ctx context.Context, userID, newPassword string) error {
	hashedPassword, err := bcrypt.GenerateFromPassword([]byte(newPassword), bcrypt.DefaultCost)
	if err != nil {
		return fmt.Errorf("failed to hash password: %w", err)
	}

	query := `UPDATE users SET password_hash = ?, updated_at = ? WHERE id = ?`
	_, err = r.db.ExecContext(ctx, query, string(hashedPassword), time.Now(), userID)
	if err != nil {
		return fmt.Errorf("failed to update password: %w", err)
	}

	return nil
}

// UpdateLastLogin updates the last login timestamp
func (r *Repository) UpdateLastLogin(ctx context.Context, userID string) error {
	query := `UPDATE users SET last_login_at = ? WHERE id = ?`
	_, err := r.db.ExecContext(ctx, query, time.Now(), userID)
	return err
}

// UpdateUserTier updates subscription tier
func (r *Repository) UpdateUserTier(ctx context.Context, userID, tier string) error {
	query := `UPDATE users SET subscription_tier = ?, updated_at = ? WHERE id = ?`
	_, err := r.db.ExecContext(ctx, query, tier, time.Now(), userID)
	if err != nil {
		return fmt.Errorf("failed to update user tier: %w", err)
	}
	return nil
}

// DeleteUser soft deletes a user
func (r *Repository) DeleteUser(ctx context.Context, userID string) error {
	query := `UPDATE users SET is_active = false, updated_at = ? WHERE id = ?`
	_, err := r.db.ExecContext(ctx, query, time.Now(), userID)
	if err != nil {
		return fmt.Errorf("failed to delete user: %w", err)
	}
	return nil
}
-------------------------------------------------
filepath = ./internal/auth-service/user/models.go
package user

import (
	"database/sql/driver"
	"fmt"
	"time"
)

// User represents a user in the system
type User struct {
	ID               string     `json:"id" db:"id"`
	Email            string     `json:"email" db:"email"`
	PasswordHash     string     `json:"-" db:"password_hash"`
	Role             string     `json:"role" db:"role"`
	ClientID         string     `json:"client_id" db:"client_id"`
	SubscriptionTier string     `json:"subscription_tier" db:"subscription_tier"`
	IsActive         bool       `json:"is_active" db:"is_active"`
	EmailVerified    bool       `json:"email_verified" db:"email_verified"`
	CreatedAt        time.Time  `json:"created_at" db:"created_at"`
	UpdatedAt        time.Time  `json:"updated_at" db:"updated_at"`
	LastLoginAt      *time.Time `json:"last_login_at,omitempty" db:"last_login_at"`

	// Additional fields
	Profile     *UserProfile `json:"profile,omitempty"`
	Permissions []string     `json:"permissions,omitempty"`
}

// UserProfile contains additional user information
type UserProfile struct {
	UserID      string `json:"user_id" db:"user_id"`
	FirstName   string `json:"first_name" db:"first_name"`
	LastName    string `json:"last_name" db:"last_name"`
	Company     string `json:"company,omitempty" db:"company"`
	Phone       string `json:"phone,omitempty" db:"phone"`
	AvatarURL   string `json:"avatar_url,omitempty" db:"avatar_url"`
	Preferences JSONB  `json:"preferences,omitempty" db:"preferences"`
}

// JSONB handles JSON data in database
type JSONB map[string]interface{}

// Value implements driver.Valuer interface
func (j JSONB) Value() (driver.Value, error) {
	return json.Marshal(j)
}

// Scan implements sql.Scanner interface
func (j *JSONB) Scan(value interface{}) error {
	bytes, ok := value.([]byte)
	if !ok {
		return fmt.Errorf("failed to scan JSONB")
	}
	return json.Unmarshal(bytes, j)
}

// CreateUserRequest for user registration
type CreateUserRequest struct {
	Email     string `json:"email" binding:"required,email"`
	Password  string `json:"password" binding:"required,min=8"`
	ClientID  string `json:"client_id" binding:"required"`
	FirstName string `json:"first_name"`
	LastName  string `json:"last_name"`
	Company   string `json:"company"`
}

// UpdateUserRequest for user updates
type UpdateUserRequest struct {
	FirstName   *string `json:"first_name"`
	LastName    *string `json:"last_name"`
	Company     *string `json:"company"`
	Phone       *string `json:"phone"`
	Preferences *JSONB  `json:"preferences"`
}

// ChangePasswordRequest for password changes
type ChangePasswordRequest struct {
	CurrentPassword string `json:"current_password" binding:"required"`
	NewPassword     string `json:"new_password" binding:"required,min=8"`
}
-------------------------------------------------
filepath = ./internal/auth-service/user/service.go
package user

import (
	"context"
	"fmt"
	"strings"

	"github.com/gqls/ai-persona-system/internal/auth-service/jwt"
	"go.uber.org/zap"
)

// Service handles business logic for users
type Service struct {
	repo   *Repository
	logger *zap.Logger
}

// NewService creates a new user service
func NewService(repo *Repository, logger *zap.Logger) *Service {
	return &Service{
		repo:   repo,
		logger: logger,
	}
}

// Register creates a new user account
func (s *Service) Register(ctx context.Context, req *CreateUserRequest) (*User, error) {
	// Validate email format
	req.Email = strings.ToLower(strings.TrimSpace(req.Email))

	// Check if user already exists
	existingUser, _ := s.repo.GetUserByEmail(ctx, req.Email)
	if existingUser != nil {
		return nil, fmt.Errorf("user with email %s already exists", req.Email)
	}

	// Create user
	user, err := s.repo.CreateUser(ctx, req)
	if err != nil {
		s.logger.Error("Failed to create user", zap.Error(err))
		return nil, err
	}

	// TODO: Send verification email

	s.logger.Info("User registered successfully",
		zap.String("user_id", user.ID),
		zap.String("email", user.Email))

	return user, nil
}

// Login validates user credentials
func (s *Service) Login(ctx context.Context, email, password string) (*User, error) {
	email = strings.ToLower(strings.TrimSpace(email))

	user, err := s.repo.GetUserByEmail(ctx, email)
	if err != nil {
		s.logger.Warn("Login attempt for non-existent user", zap.String("email", email))
		return nil, fmt.Errorf("invalid credentials")
	}

	if !s.repo.ValidatePassword(user, password) {
		s.logger.Warn("Invalid password attempt", zap.String("user_id", user.ID))
		return nil, fmt.Errorf("invalid credentials")
	}

	if !user.IsActive {
		return nil, fmt.Errorf("account is disabled")
	}

	// Update last login
	if err := s.repo.UpdateLastLogin(ctx, user.ID); err != nil {
		s.logger.Error("Failed to update last login", zap.Error(err))
	}

	return user, nil
}

// GetUser retrieves user details
func (s *Service) GetUser(ctx context.Context, userID string) (*User, error) {
	return s.repo.GetUserByID(ctx, userID)
}

// GetUserInfo returns user info for JWT token generation
func (s *Service) GetUserInfo(ctx context.Context, userID string) (*jwt.UserInfo, error) {
	user, err := s.repo.GetUserByID(ctx, userID)
	if err != nil {
		return nil, err
	}

	return &jwt.UserInfo{
		UserID:      user.ID,
		Email:       user.Email,
		ClientID:    user.ClientID,
		Role:        user.Role,
		Tier:        user.SubscriptionTier,
		Permissions: user.Permissions,
	}, nil
}

// UpdateUser updates user information
func (s *Service) UpdateUser(ctx context.Context, userID string, req *UpdateUserRequest) error {
	return s.repo.UpdateUser(ctx, userID, req)
}

// ChangePassword changes user password
func (s *Service) ChangePassword(ctx context.Context, userID string, req *ChangePasswordRequest) error {
	user, err := s.repo.GetUserByID(ctx, userID)
	if err != nil {
		return err
	}

	// Validate current password
	if !s.repo.ValidatePassword(user, req.CurrentPassword) {
		return fmt.Errorf("current password is incorrect")
	}

	// Update password
	return s.repo.UpdatePassword(ctx, userID, req.NewPassword)
}

// DeleteUser deletes a user account
func (s *Service) DeleteUser(ctx context.Context, userID string) error {
	return s.repo.DeleteUser(ctx, userID)
}
-------------------------------------------------
filepath = ./internal/auth-service/middleware/cors.go
-------------------------------------------------
filepath = ./internal/auth-service/middleware/logging.go
-------------------------------------------------
filepath = ./internal/auth-service/middleware/auth.go
-------------------------------------------------
filepath = ./internal/auth-service/jwt/claims.go
package jwt

import (
	"github.com/golang-jwt/jwt/v5"
)

// GetTokenFromString extracts claims without validation (for logging/debugging only)
func GetTokenFromString(tokenString string) (*Claims, error) {
	token, _, err := new(jwt.Parser).ParseUnverified(tokenString, &Claims{})
	if err != nil {
		return nil, err
	}

	if claims, ok := token.Claims.(*Claims); ok {
		return claims, nil
	}

	return nil, fmt.Errorf("invalid claims type")
}

// IsTokenExpired checks if a token is expired without full validation
func IsTokenExpired(claims *Claims) bool {
	return claims.ExpiresAt.Time.Before(time.Now())
}
-------------------------------------------------
filepath = ./internal/auth-service/jwt/service.go
package jwt

import (
	"fmt"
	"time"

	"github.com/golang-jwt/jwt/v5"
	"go.uber.org/zap"
)

// Service handles JWT operations
type Service struct {
	secretKey       []byte
	accessTokenTTL  time.Duration
	refreshTokenTTL time.Duration
	logger          *zap.Logger
}

// Claims represents the JWT claims
type Claims struct {
	UserID      string   `json:"user_id"`
	Email       string   `json:"email"`
	ClientID    string   `json:"client_id"`
	Role        string   `json:"role"`
	Tier        string   `json:"tier"`
	Permissions []string `json:"permissions,omitempty"`
	jwt.RegisteredClaims
}

// RefreshClaims for refresh tokens
type RefreshClaims struct {
	UserID string `json:"user_id"`
	jwt.RegisteredClaims
}

// NewService creates a new JWT service
func NewService(secretKey string, accessMinutes int, logger *zap.Logger) (*Service, error) {
	if secretKey == "" {
		return nil, fmt.Errorf("JWT secret key cannot be empty")
	}

	return &Service{
		secretKey:       []byte(secretKey),
		accessTokenTTL:  time.Duration(accessMinutes) * time.Minute,
		refreshTokenTTL: 7 * 24 * time.Hour, // 7 days
		logger:          logger,
	}, nil
}

// GenerateTokens creates both access and refresh tokens
func (s *Service) GenerateTokens(userID, email, clientID, role, tier string, permissions []string) (string, string, error) {
	accessToken, err := s.generateAccessToken(userID, email, clientID, role, tier, permissions)
	if err != nil {
		return "", "", fmt.Errorf("failed to generate access token: %w", err)
	}

	refreshToken, err := s.generateRefreshToken(userID)
	if err != nil {
		return "", "", fmt.Errorf("failed to generate refresh token: %w", err)
	}

	return accessToken, refreshToken, nil
}

// generateAccessToken creates an access token with full claims
func (s *Service) generateAccessToken(userID, email, clientID, role, tier string, permissions []string) (string, error) {
	now := time.Now()
	claims := Claims{
		UserID:      userID,
		Email:       email,
		ClientID:    clientID,
		Role:        role,
		Tier:        tier,
		Permissions: permissions,
		RegisteredClaims: jwt.RegisteredClaims{
			ExpiresAt: jwt.NewNumericDate(now.Add(s.accessTokenTTL)),
			IssuedAt:  jwt.NewNumericDate(now),
			NotBefore: jwt.NewNumericDate(now),
			Issuer:    "ai-persona-system",
			Subject:   userID,
			ID:        fmt.Sprintf("%d", now.Unix()),
		},
	}

	token := jwt.NewWithClaims(jwt.SigningMethodHS256, claims)
	return token.SignedString(s.secretKey)
}

// generateRefreshToken creates a refresh token with minimal claims
func (s *Service) generateRefreshToken(userID string) (string, error) {
	now := time.Now()
	claims := RefreshClaims{
		UserID: userID,
		RegisteredClaims: jwt.RegisteredClaims{
			ExpiresAt: jwt.NewNumericDate(now.Add(s.refreshTokenTTL)),
			IssuedAt:  jwt.NewNumericDate(now),
			Subject:   userID,
			ID:        fmt.Sprintf("refresh_%d", now.Unix()),
		},
	}

	token := jwt.NewWithClaims(jwt.SigningMethodHS256, claims)
	return token.SignedString(s.secretKey)
}

// ValidateToken validates and parses an access token
func (s *Service) ValidateToken(tokenString string) (*Claims, error) {
	token, err := jwt.ParseWithClaims(tokenString, &Claims{}, func(token *jwt.Token) (interface{}, error) {
		if _, ok := token.Method.(*jwt.SigningMethodHMAC); !ok {
			return nil, fmt.Errorf("unexpected signing method: %v", token.Header["alg"])
		}
		return s.secretKey, nil
	})

	if err != nil {
		return nil, fmt.Errorf("failed to parse token: %w", err)
	}

	if claims, ok := token.Claims.(*Claims); ok && token.Valid {
		return claims, nil
	}

	return nil, fmt.Errorf("invalid token claims")
}

// ValidateRefreshToken validates a refresh token
func (s *Service) ValidateRefreshToken(tokenString string) (*RefreshClaims, error) {
	token, err := jwt.ParseWithClaims(tokenString, &RefreshClaims{}, func(token *jwt.Token) (interface{}, error) {
		if _, ok := token.Method.(*jwt.SigningMethodHMAC); !ok {
			return nil, fmt.Errorf("unexpected signing method: %v", token.Header["alg"])
		}
		return s.secretKey, nil
	})

	if err != nil {
		return nil, fmt.Errorf("failed to parse refresh token: %w", err)
	}

	if claims, ok := token.Claims.(*RefreshClaims); ok && token.Valid {
		return claims, nil
	}

	return nil, fmt.Errorf("invalid refresh token")
}

// RefreshAccessToken creates a new access token from a refresh token
func (s *Service) RefreshAccessToken(refreshToken string, getUserFunc func(userID string) (*UserInfo, error)) (string, error) {
	claims, err := s.ValidateRefreshToken(refreshToken)
	if err != nil {
		return "", err
	}

	// Get updated user details
	userInfo, err := getUserFunc(claims.UserID)
	if err != nil {
		return "", fmt.Errorf("failed to get user details: %w", err)
	}

	// Generate new access token with current user info
	return s.generateAccessToken(
		userInfo.UserID,
		userInfo.Email,
		userInfo.ClientID,
		userInfo.Role,
		userInfo.Tier,
		userInfo.Permissions,
	)
}

// UserInfo holds user information for token generation
type UserInfo struct {
	UserID      string
	Email       string
	ClientID    string
	Role        string
	Tier        string
	Permissions []string
}
-------------------------------------------------
filepath = ./internal/auth-service/auth/middleware.go
package auth

import (
	"fmt"
	"net/http"
	"strings"

	"github.com/gin-gonic/gin"
	"github.com/gqls/ai-persona-system/internal/auth-service/jwt"
	"go.uber.org/zap"
)

// AuthMiddleware validates JWT tokens
func AuthMiddleware(jwtService *jwt.Service, logger *zap.Logger) gin.HandlerFunc {
	return func(c *gin.Context) {
		authHeader := c.GetHeader("Authorization")
		if authHeader == "" {
			c.JSON(http.StatusUnauthorized, gin.H{"error": "Authorization header required"})
			c.Abort()
			return
		}

		// Extract token
		parts := strings.Split(authHeader, " ")
		if len(parts) != 2 || parts[0] != "Bearer" {
			c.JSON(http.StatusUnauthorized, gin.H{"error": "Invalid authorization header format"})
			c.Abort()
			return
		}

		tokenString := parts[1]

		// Validate token
		claims, err := jwtService.ValidateToken(tokenString)
		if err != nil {
			logger.Debug("Token validation failed", zap.Error(err))
			c.JSON(http.StatusUnauthorized, gin.H{"error": "Invalid token"})
			c.Abort()
			return
		}

		// Set user context
		c.Set("user_id", claims.UserID)
		c.Set("client_id", claims.ClientID)
		c.Set("user_email", claims.Email)
		c.Set("user_role", claims.Role)
		c.Set("user_tier", claims.Tier)
		c.Set("user_permissions", claims.Permissions)
		c.Set("token_id", claims.ID)
		c.Set("claims", claims)

		c.Next()
	}
}

// RequirePermission checks if user has specific permission
func RequirePermission(permission string) gin.HandlerFunc {
	return func(c *gin.Context) {
		permissions, exists := c.Get("user_permissions")
		if !exists {
			c.JSON(http.StatusForbidden, gin.H{"error": "No permissions found"})
			c.Abort()
			return
		}

		userPerms, ok := permissions.([]string)
		if !ok {
			c.JSON(http.StatusInternalServerError, gin.H{"error": "Invalid permissions format"})
			c.Abort()
			return
		}

		// Check permission
		hasPermission := false
		for _, p := range userPerms {
			if p == permission || p == "*" { // "*" is superuser
				hasPermission = true
				break
			}
		}

		if !hasPermission {
			c.JSON(http.StatusForbidden, gin.H{"error": "Insufficient permissions"})
			c.Abort()
			return
		}

		c.Next()
	}
}

// RequireRole checks if user has specific role
func RequireRole(roles ...string) gin.HandlerFunc {
	return func(c *gin.Context) {
		userRole, exists := c.Get("user_role")
		if !exists {
			c.JSON(http.StatusForbidden, gin.H{"error": "No role found"})
			c.Abort()
			return
		}

		role, ok := userRole.(string)
		if !ok {
			c.JSON(http.StatusInternalServerError, gin.H{"error": "Invalid role format"})
			c.Abort()
			return
		}

		// Check role
		hasRole := false
		for _, r := range roles {
			if r == role {
				hasRole = true
				break
			}
		}

		if !hasRole {
			c.JSON(http.StatusForbidden, gin.H{"error": "Insufficient role"})
			c.Abort()
			return
		}

		c.Next()
	}
}

// RequireTier checks if user has minimum subscription tier
func RequireTier(minTier string) gin.HandlerFunc {
	tierLevels := map[string]int{
		"free":       0,
		"basic":      1,
		"premium":    2,
		"enterprise": 3,
	}

	return func(c *gin.Context) {
		userTier, exists := c.Get("user_tier")
		if !exists {
			c.JSON(http.StatusForbidden, gin.H{"error": "No subscription tier found"})
			c.Abort()
			return
		}

		tier, ok := userTier.(string)
		if !ok {
			c.JSON(http.StatusInternalServerError, gin.H{"error": "Invalid tier format"})
			c.Abort()
			return
		}

		userLevel, exists := tierLevels[tier]
		if !exists {
			userLevel = 0 // Default to free
		}

		requiredLevel, exists := tierLevels[minTier]
		if !exists {
			c.JSON(http.StatusInternalServerError, gin.H{"error": "Invalid required tier"})
			c.Abort()
			return
		}

		if userLevel < requiredLevel {
			c.JSON(http.StatusForbidden, gin.H{
				"error":         fmt.Sprintf("This feature requires %s tier or higher", minTier),
				"current_tier":  tier,
				"required_tier": minTier,
			})
			c.Abort()
			return
		}

		c.Next()
	}
}
-------------------------------------------------
filepath = ./internal/auth-service/auth/handlers.go
package auth

import (
	"net/http"
	"strings"

	"github.com/gin-gonic/gin"
	"github.com/gqls/ai-persona-system/internal/auth-service/user"
)

// Handlers wraps the auth service for HTTP handling
type Handlers struct {
	service *Service
}

// NewHandlers creates new auth handlers
func NewHandlers(service *Service) *Handlers {
	return &Handlers{service: service}
}

// RegisterRequest represents registration data
type RegisterRequest struct {
	Email     string `json:"email" binding:"required,email"`
	Password  string `json:"password" binding:"required,min=8"`
	ClientID  string `json:"client_id" binding:"required"`
	FirstName string `json:"first_name"`
	LastName  string `json:"last_name"`
	Company   string `json:"company"`
}

// LoginRequest represents login data
type LoginRequest struct {
	Email    string `json:"email" binding:"required,email"`
	Password string `json:"password" binding:"required"`
}

// RefreshRequest represents token refresh data
type RefreshRequest struct {
	RefreshToken string `json:"refresh_token" binding:"required"`
}

// HandleRegister handles user registration
func (h *Handlers) HandleRegister(c *gin.Context) {
	var req RegisterRequest
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
		return
	}

	// Convert to user create request
	userReq := &user.CreateUserRequest{
		Email:     req.Email,
		Password:  req.Password,
		ClientID:  req.ClientID,
		FirstName: req.FirstName,
		LastName:  req.LastName,
		Company:   req.Company,
	}

	response, err := h.service.Register(c.Request.Context(), userReq)
	if err != nil {
		if strings.Contains(err.Error(), "already exists") {
			c.JSON(http.StatusConflict, gin.H{"error": err.Error()})
			return
		}
		c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
		return
	}

	c.JSON(http.StatusCreated, response)
}

// HandleLogin handles user login
func (h *Handlers) HandleLogin(c *gin.Context) {
	var req LoginRequest
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
		return
	}

	response, err := h.service.Login(c.Request.Context(), req.Email, req.Password)
	if err != nil {
		c.JSON(http.StatusUnauthorized, gin.H{"error": "Invalid credentials"})
		return
	}

	c.JSON(http.StatusOK, response)
}

// HandleRefresh handles token refresh
func (h *Handlers) HandleRefresh(c *gin.Context) {
	var req RefreshRequest
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
		return
	}

	response, err := h.service.RefreshToken(c.Request.Context(), req.RefreshToken)
	if err != nil {
		c.JSON(http.StatusUnauthorized, gin.H{"error": err.Error()})
		return
	}

	c.JSON(http.StatusOK, response)
}

// HandleLogout handles user logout
func (h *Handlers) HandleLogout(c *gin.Context) {
	// Get token ID from claims
	tokenID := c.GetString("token_id")

	if err := h.service.Logout(c.Request.Context(), tokenID); err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": "Failed to logout"})
		return
	}

	c.JSON(http.StatusOK, gin.H{"message": "Successfully logged out"})
}

// HandleValidate validates the current token
func (h *Handlers) HandleValidate(c *gin.Context) {
	// Token is already validated by middleware if we reach here
	claims := c.MustGet("claims").(*jwt.Claims)

	c.JSON(http.StatusOK, gin.H{
		"valid": true,
		"user": gin.H{
			"id":        claims.UserID,
			"email":     claims.Email,
			"role":      claims.Role,
			"tier":      claims.Tier,
			"client_id": claims.ClientID,
		},
	})
}
-------------------------------------------------
filepath = ./internal/auth-service/auth/service.go
package auth

import (
	"context"
	"fmt"
	"time"

	"github.com/gqls/ai-persona-system/internal/auth-service/jwt"
	"github.com/gqls/ai-persona-system/internal/auth-service/user"
	"go.uber.org/zap"
)

// Service handles authentication logic
type Service struct {
	userService *user.Service
	jwtService  *jwt.Service
	logger      *zap.Logger
}

// NewService creates a new auth service
func NewService(userService *user.Service, jwtService *jwt.Service, logger *zap.Logger) *Service {
	return &Service{
		userService: userService,
		jwtService:  jwtService,
		logger:      logger,
	}
}

// TokenResponse represents the auth response
type TokenResponse struct {
	AccessToken  string    `json:"access_token"`
	RefreshToken string    `json:"refresh_token"`
	TokenType    string    `json:"token_type"`
	ExpiresIn    int       `json:"expires_in"`
	User         *UserInfo `json:"user"`
}

// UserInfo in token response
type UserInfo struct {
	ID            string   `json:"id"`
	Email         string   `json:"email"`
	ClientID      string   `json:"client_id"`
	Role          string   `json:"role"`
	Tier          string   `json:"tier"`
	EmailVerified bool     `json:"email_verified"`
	Permissions   []string `json:"permissions"`
}

// Register handles user registration
func (s *Service) Register(ctx context.Context, req *user.CreateUserRequest) (*TokenResponse, error) {
	// Create user
	newUser, err := s.userService.Register(ctx, req)
	if err != nil {
		return nil, err
	}

	// Generate tokens
	accessToken, refreshToken, err := s.jwtService.GenerateTokens(
		newUser.ID,
		newUser.Email,
		newUser.ClientID,
		newUser.Role,
		newUser.SubscriptionTier,
		newUser.Permissions,
	)
	if err != nil {
		s.logger.Error("Failed to generate tokens", zap.Error(err))
		return nil, fmt.Errorf("failed to generate tokens")
	}

	return &TokenResponse{
		AccessToken:  accessToken,
		RefreshToken: refreshToken,
		TokenType:    "Bearer",
		ExpiresIn:    3600, // 1 hour
		User: &UserInfo{
			ID:            newUser.ID,
			Email:         newUser.Email,
			ClientID:      newUser.ClientID,
			Role:          newUser.Role,
			Tier:          newUser.SubscriptionTier,
			EmailVerified: newUser.EmailVerified,
			Permissions:   newUser.Permissions,
		},
	}, nil
}

// Login handles user login
func (s *Service) Login(ctx context.Context, email, password string) (*TokenResponse, error) {
	// Validate credentials
	user, err := s.userService.Login(ctx, email, password)
	if err != nil {
		return nil, err
	}

	// Generate tokens
	accessToken, refreshToken, err := s.jwtService.GenerateTokens(
		user.ID,
		user.Email,
		user.ClientID,
		user.Role,
		user.SubscriptionTier,
		user.Permissions,
	)
	if err != nil {
		s.logger.Error("Failed to generate tokens", zap.Error(err))
		return nil, fmt.Errorf("failed to generate tokens")
	}

	return &TokenResponse{
		AccessToken:  accessToken,
		RefreshToken: refreshToken,
		TokenType:    "Bearer",
		ExpiresIn:    3600,
		User: &UserInfo{
			ID:            user.ID,
			Email:         user.Email,
			ClientID:      user.ClientID,
			Role:          user.Role,
			Tier:          user.SubscriptionTier,
			EmailVerified: user.EmailVerified,
			Permissions:   user.Permissions,
		},
	}, nil
}

// RefreshToken handles token refresh
func (s *Service) RefreshToken(ctx context.Context, refreshToken string) (*TokenResponse, error) {
	// Validate refresh token and get new access token
	getUserFunc := func(userID string) (*jwt.UserInfo, error) {
		return s.userService.GetUserInfo(ctx, userID)
	}

	accessToken, err := s.jwtService.RefreshAccessToken(refreshToken, getUserFunc)
	if err != nil {
		return nil, fmt.Errorf("invalid refresh token")
	}

	// Get user info for response
	claims, _ := s.jwtService.ValidateToken(accessToken)

	return &TokenResponse{
		AccessToken:  accessToken,
		RefreshToken: refreshToken, // Return same refresh token
		TokenType:    "Bearer",
		ExpiresIn:    3600,
		User: &UserInfo{
			ID:          claims.UserID,
			Email:       claims.Email,
			ClientID:    claims.ClientID,
			Role:        claims.Role,
			Tier:        claims.Tier,
			Permissions: claims.Permissions,
		},
	}, nil
}

// Logout handles user logout (for future implementation with token blacklisting)
func (s *Service) Logout(ctx context.Context, tokenID string) error {
	// In a stateless JWT system, logout is typically handled client-side
	// For added security, you could implement token blacklisting here
	s.logger.Info("User logged out", zap.String("token_id", tokenID))
	return nil
}

// ValidateToken validates an access token
func (s *Service) ValidateToken(tokenString string) (*jwt.Claims, error) {
	return s.jwtService.ValidateToken(tokenString)
}
-------------------------------------------------
filepath = ./internal/auth-service/subscription/subscription.go
-------------------------------------------------
filepath = ./internal/auth-service/subscription/handlers.go
package main

func main() {

}
-------------------------------------------------
filepath = ./internal/auth-service/subscription/models.go
package subscription

import (
	"time"
)

// Subscription represents a user's subscription
type Subscription struct {
	ID                   string     `json:"id" db:"id"`
	UserID               string     `json:"user_id" db:"user_id"`
	Tier                 string     `json:"tier" db:"tier"`
	Status               string     `json:"status" db:"status"`
	StartDate            time.Time  `json:"start_date" db:"start_date"`
	EndDate              *time.Time `json:"end_date,omitempty" db:"end_date"`
	TrialEndsAt          *time.Time `json:"trial_ends_at,omitempty" db:"trial_ends_at"`
	CancelledAt          *time.Time `json:"cancelled_at,omitempty" db:"cancelled_at"`
	PaymentMethod        string     `json:"payment_method" db:"payment_method"`
	StripeCustomerID     string     `json:"-" db:"stripe_customer_id"`
	StripeSubscriptionID string     `json:"-" db:"stripe_subscription_id"`
	CreatedAt            time.Time  `json:"created_at" db:"created_at"`
	UpdatedAt            time.Time  `json:"updated_at" db:"updated_at"`
}

// SubscriptionTier defines tier details
type SubscriptionTier struct {
	ID              string   `json:"id" db:"id"`
	Name            string   `json:"name" db:"name"`
	DisplayName     string   `json:"display_name" db:"display_name"`
	Description     string   `json:"description" db:"description"`
	PriceMonthly    float64  `json:"price_monthly" db:"price_monthly"`
	PriceYearly     float64  `json:"price_yearly" db:"price_yearly"`
	MaxPersonas     int      `json:"max_personas" db:"max_personas"`
	MaxProjects     int      `json:"max_projects" db:"max_projects"`
	MaxContentItems int      `json:"max_content_items" db:"max_content_items"`
	Features        []string `json:"features" db:"features"`
	IsActive        bool     `json:"is_active" db:"is_active"`
}

// UsageStats tracks user's resource usage
type UsageStats struct {
	UserID        string    `json:"user_id" db:"user_id"`
	PersonasCount int       `json:"personas_count" db:"personas_count"`
	ProjectsCount int       `json:"projects_count" db:"projects_count"`
	ContentCount  int       `json:"content_count" db:"content_count"`
	LastUpdated   time.Time `json:"last_updated" db:"last_updated"`
}

// SubscriptionStatus constants
const (
	StatusActive   = "active"
	StatusTrialing = "trialing"
	StatusPastDue  = "past_due"
	StatusCanceled = "canceled"
	StatusExpired  = "expired"
)

// Tier constants
const (
	TierFree       = "free"
	TierBasic      = "basic"
	TierPremium    = "premium"
	TierEnterprise = "enterprise"
)

// CreateSubscriptionRequest for new subscriptions
type CreateSubscriptionRequest struct {
	UserID          string `json:"user_id" binding:"required"`
	Tier            string `json:"tier" binding:"required"`
	PaymentMethodID string `json:"payment_method_id"`
	TrialDays       int    `json:"trial_days"`
}

// UpdateSubscriptionRequest for subscription changes
type UpdateSubscriptionRequest struct {
	Tier            *string `json:"tier"`
	PaymentMethodID *string `json:"payment_method_id"`
}

// CheckoutSession for payment processing
type CheckoutSession struct {
	ID         string `json:"id"`
	URL        string `json:"url"`
	SuccessURL string `json:"success_url"`
	CancelURL  string `json:"cancel_url"`
	ExpiresAt  int64  `json:"expires_at"`
}
-------------------------------------------------
filepath = ./internal/auth-service/subscription/service.go
package subscription
-------------------------------------------------
filepath = ./internal/agents/reasoning/agent.go
// FILE: internal/agents/reasoning/agent.go
package reasoning

import (
	"context"
	"encoding/json"
	"fmt"

	"github.com/google/uuid"
	"github.com/gqls/ai-persona-system/platform/aiservice"
	"github.com/gqls/ai-persona-system/platform/config"
	"github.com/gqls/ai-persona-system/platform/kafka"
	"go.uber.org/zap"
)

const (
	requestTopic  = "system.agent.reasoning.process"
	responseTopic = "system.responses.reasoning"
	consumerGroup = "reasoning-agent-group"
)

// RequestPayload defines the data this agent expects
type RequestPayload struct {
	Action string `json:"action"`
	Data   struct {
		ContentToReview string                 `json:"content_to_review"`
		ReviewCriteria  []string               `json:"review_criteria"`
		BriefContext    map[string]interface{} `json:"brief_context"`
	} `json:"data"`
}

// ResponsePayload defines the response format
type ResponsePayload struct {
	ReviewPassed bool     `json:"review_passed"`
	Score        float64  `json:"score"`
	Suggestions  []string `json:"suggestions"`
	Reasoning    string   `json:"reasoning"`
}

// Agent is the reasoning specialist
type Agent struct {
	ctx      context.Context
	logger   *zap.Logger
	consumer *kafka.Consumer
	producer *kafka.Producer
	aiClient aiservice.AIService
}

// NewAgent creates a new reasoning agent
func NewAgent(ctx context.Context, cfg *config.ServiceConfig, logger *zap.Logger) (*Agent, error) {
	consumer, err := kafka.NewConsumer(cfg.Infrastructure.KafkaBrokers, requestTopic, consumerGroup, logger)
	if err != nil {
		return nil, fmt.Errorf("failed to create consumer: %w", err)
	}

	producer, err := kafka.NewProducer(cfg.Infrastructure.KafkaBrokers, logger)
	if err != nil {
		consumer.Close()
		return nil, fmt.Errorf("failed to create producer: %w", err)
	}

	// Initialize AI client from custom config
	aiConfig := cfg.Custom["ai_service"].(map[string]interface{})
	aiClient, err := aiservice.NewAnthropicClient(ctx, aiConfig)
	if err != nil {
		consumer.Close()
		producer.Close()
		return nil, fmt.Errorf("failed to create AI client: %w", err)
	}

	return &Agent{
		ctx:      ctx,
		logger:   logger,
		consumer: consumer,
		producer: producer,
		aiClient: aiClient,
	}, nil
}

// Run starts the agent's main loop
func (a *Agent) Run() error {
	a.logger.Info("Reasoning Agent is running and waiting for tasks...")

	for {
		select {
		case <-a.ctx.Done():
			a.consumer.Close()
			a.producer.Close()
			return nil
		default:
			msg, err := a.consumer.FetchMessage(a.ctx)
			if err != nil {
				if err == context.Canceled {
					continue
				}
				a.logger.Error("Failed to fetch message", zap.Error(err))
				continue
			}
			go a.handleMessage(msg)
		}
	}
}

// handleMessage processes a single reasoning request
func (a *Agent) handleMessage(msg kafka.Message) {
	headers := kafka.HeadersToMap(msg.Headers)
	l := a.logger.With(zap.String("correlation_id", headers["correlation_id"]))

	var req RequestPayload
	if err := json.Unmarshal(msg.Value, &req); err != nil {
		l.Error("Failed to unmarshal request", zap.Error(err))
		a.consumer.CommitMessages(context.Background(), msg)
		return
	}

	// Build the reasoning prompt
	prompt := a.buildReasoningPrompt(req)

	// Call the AI service
	result, err := a.aiClient.GenerateText(a.ctx, prompt, nil)
	if err != nil {
		l.Error("AI reasoning call failed", zap.Error(err))
		a.sendErrorResponse(headers, "Failed to perform reasoning")
		a.consumer.CommitMessages(context.Background(), msg)
		return
	}

	// Parse the AI response
	var responsePayload ResponsePayload
	if err := json.Unmarshal([]byte(result), &responsePayload); err != nil {
		l.Error("Failed to parse AI response", zap.Error(err))
		// Fallback response
		responsePayload = ResponsePayload{
			ReviewPassed: false,
			Score:        0,
			Suggestions:  []string{"Could not parse AI response"},
			Reasoning:    result,
		}
	}

	// Send response
	a.sendResponse(headers, responsePayload)

	// Commit message
	a.consumer.CommitMessages(context.Background(), msg)
}

// buildReasoningPrompt creates the prompt for the LLM
func (a *Agent) buildReasoningPrompt(req RequestPayload) string {
	return fmt.Sprintf(`You are a logical reasoning engine. Review the following content based on these criteria: %v.

Context: %v

Content to review: "%s"

Provide your analysis as a JSON object with the following structure:
{
    "review_passed": boolean,
    "score": number (0-10),
    "suggestions": ["suggestion1", "suggestion2", ...],
    "reasoning": "detailed explanation of your analysis"
}

Be thorough but concise in your reasoning.`,
		req.Data.ReviewCriteria,
		req.Data.BriefContext,
		req.Data.ContentToReview,
	)
}

// sendResponse sends a successful response
func (a *Agent) sendResponse(headers map[string]string, payload ResponsePayload) {
	responseBytes, _ := json.Marshal(payload)
	responseHeaders := map[string]string{
		"correlation_id": headers["correlation_id"],
		"causation_id":   headers["request_id"],
		"request_id":     uuid.NewString(),
	}

	if err := a.producer.Produce(a.ctx, responseTopic, responseHeaders,
		[]byte(headers["correlation_id"]), responseBytes); err != nil {
		a.logger.Error("Failed to produce response", zap.Error(err))
	}
}

// sendErrorResponse sends an error response
func (a *Agent) sendErrorResponse(headers map[string]string, errorMsg string) {
	payload := map[string]interface{}{
		"success": false,
		"error":   errorMsg,
	}
	responseBytes, _ := json.Marshal(payload)
	responseHeaders := map[string]string{
		"correlation_id": headers["correlation_id"],
		"causation_id":   headers["request_id"],
		"request_id":     uuid.NewString(),
	}

	a.producer.Produce(a.ctx, responseTopic, responseHeaders,
		[]byte(headers["correlation_id"]), responseBytes)
}
-------------------------------------------------
filepath = ./internal/core-manager/databases/personas.go
// FILE: internal/core-manager/database/personas.go
package database

import (
	"context"
	"encoding/json"
	"fmt"
	"time"

	"github.com/google/uuid"
	"github.com/gqls/ai-persona-system/pkg/models"
	"github.com/jackc/pgx/v5"
	"github.com/jackc/pgx/v5/pgxpool"
	"go.uber.org/zap"
)

type personaRepository struct {
	templatesDB *pgxpool.Pool
	clientsDB   *pgxpool.Pool
	logger      *zap.Logger
}

// NewPersonaRepository creates a new repository instance
func NewPersonaRepository(templatesDB, clientsDB *pgxpool.Pool, logger *zap.Logger) models.PersonaRepository {
	return &personaRepository{
		templatesDB: templatesDB,
		clientsDB:   clientsDB,
		logger:      logger,
	}
}

// Template Methods

func (r *personaRepository) CreateTemplate(ctx context.Context, template *models.Persona) (*models.Persona, error) {
	r.logger.Info("Creating new persona template", zap.String("name", template.Name))

	configJSON, _ := json.Marshal(template.Config)

	query := `
        INSERT INTO persona_templates (id, name, description, category, config, is_active, created_at, updated_at)
        VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
        RETURNING id
    `

	err := r.templatesDB.QueryRow(ctx, query,
		template.ID,
		template.Name,
		template.Description,
		template.Category,
		configJSON,
		true,
		template.CreatedAt,
		template.UpdatedAt,
	).Scan(&template.ID)

	if err != nil {
		r.logger.Error("Failed to create template", zap.Error(err))
		return nil, fmt.Errorf("failed to create template: %w", err)
	}

	return template, nil
}

func (r *personaRepository) GetTemplateByID(ctx context.Context, id string) (*models.Persona, error) {
	r.logger.Info("Getting template by ID", zap.String("id", id))

	var template models.Persona
	var configJSON []byte

	query := `
        SELECT id, name, description, category, config, is_active, created_at, updated_at
        FROM persona_templates
        WHERE id = $1 AND is_active = true
    `

	err := r.templatesDB.QueryRow(ctx, query, id).Scan(
		&template.ID,
		&template.Name,
		&template.Description,
		&template.Category,
		&configJSON,
		&template.IsActive,
		&template.CreatedAt,
		&template.UpdatedAt,
	)

	if err != nil {
		if err == pgx.ErrNoRows {
			return nil, fmt.Errorf("template not found")
		}
		return nil, fmt.Errorf("failed to get template: %w", err)
	}

	json.Unmarshal(configJSON, &template.Config)
	template.IsTemplate = true

	return &template, nil
}

func (r *personaRepository) ListTemplates(ctx context.Context) ([]models.Persona, error) {
	r.logger.Info("Listing all templates")

	query := `
        SELECT id, name, description, category, config, is_active, created_at, updated_at
        FROM persona_templates
        WHERE is_active = true
        ORDER BY category, name
    `

	rows, err := r.templatesDB.Query(ctx, query)
	if err != nil {
		return nil, fmt.Errorf("failed to list templates: %w", err)
	}
	defer rows.Close()

	var templates []models.Persona
	for rows.Next() {
		var template models.Persona
		var configJSON []byte

		err := rows.Scan(
			&template.ID,
			&template.Name,
			&template.Description,
			&template.Category,
			&configJSON,
			&template.IsActive,
			&template.CreatedAt,
			&template.UpdatedAt,
		)
		if err != nil {
			r.logger.Error("Failed to scan template row", zap.Error(err))
			continue
		}

		json.Unmarshal(configJSON, &template.Config)
		template.IsTemplate = true
		templates = append(templates, template)
	}

	return templates, nil
}

func (r *personaRepository) UpdateTemplate(ctx context.Context, template *models.Persona) (*models.Persona, error) {
	r.logger.Info("Updating template", zap.String("id", template.ID.String()))

	configJSON, _ := json.Marshal(template.Config)

	query := `
        UPDATE persona_templates
        SET name = $2, description = $3, category = $4, config = $5, updated_at = $6
        WHERE id = $1
        RETURNING updated_at
    `

	err := r.templatesDB.QueryRow(ctx, query,
		template.ID,
		template.Name,
		template.Description,
		template.Category,
		configJSON,
		time.Now(),
	).Scan(&template.UpdatedAt)

	if err != nil {
		return nil, fmt.Errorf("failed to update template: %w", err)
	}

	return template, nil
}

func (r *personaRepository) DeleteTemplate(ctx context.Context, id string) error {
	r.logger.Info("Deleting template", zap.String("id", id))

	// Soft delete
	query := `UPDATE persona_templates SET is_active = false, updated_at = $2 WHERE id = $1`

	_, err := r.templatesDB.Exec(ctx, query, id, time.Now())
	if err != nil {
		return fmt.Errorf("failed to delete template: %w", err)
	}

	return nil
}

// Instance Methods

func (r *personaRepository) CreateInstanceFromTemplate(ctx context.Context, templateID string, userID string, instanceName string) (*models.Persona, error) {
	r.logger.Info("Creating instance from template",
		zap.String("templateID", templateID),
		zap.String("userID", userID))

	// Get client ID from context
	clientID, ok := ctx.Value("client_id").(string)
	if !ok {
		return nil, fmt.Errorf("client_id not found in context")
	}

	// First, fetch the template
	template, err := r.GetTemplateByID(ctx, templateID)
	if err != nil {
		return nil, fmt.Errorf("failed to fetch template: %w", err)
	}

	// Create the instance
	instance := &models.Persona{
		ID:          uuid.New(),
		Name:        instanceName,
		Description: template.Description,
		Category:    template.Category,
		Config:      template.Config,
		IsTemplate:  false,
		IsActive:    true,
		CreatedAt:   time.Now(),
		UpdatedAt:   time.Now(),
	}

	configJSON, _ := json.Marshal(instance.Config)

	// Use client-specific schema
	query := fmt.Sprintf(`
        INSERT INTO client_%s.agent_instances 
        (id, template_id, owner_user_id, name, config, is_active, created_at, updated_at)
        VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
    `, clientID)

	_, err = r.clientsDB.Exec(ctx, query,
		instance.ID,
		templateID,
		userID,
		instance.Name,
		configJSON,
		true,
		instance.CreatedAt,
		instance.UpdatedAt,
	)

	if err != nil {
		return nil, fmt.Errorf("failed to create instance: %w", err)
	}

	return instance, nil
}

func (r *personaRepository) GetInstanceByID(ctx context.Context, id string) (*models.Persona, error) {
	clientID, _ := ctx.Value("client_id").(string)

	var instance models.Persona
	var configJSON []byte

	query := fmt.Sprintf(`
        SELECT id, name, config, is_active, created_at, updated_at
        FROM client_%s.agent_instances
        WHERE id = $1 AND is_active = true
    `, clientID)

	err := r.clientsDB.QueryRow(ctx, query, id).Scan(
		&instance.ID,
		&instance.Name,
		&configJSON,
		&instance.IsActive,
		&instance.CreatedAt,
		&instance.UpdatedAt,
	)

	if err != nil {
		return nil, fmt.Errorf("failed to get instance: %w", err)
	}

	json.Unmarshal(configJSON, &instance.Config)
	return &instance, nil
}

func (r *personaRepository) ListInstances(ctx context.Context, userID string) ([]models.Persona, error) {
	clientID, _ := ctx.Value("client_id").(string)

	query := fmt.Sprintf(`
        SELECT id, name, config, is_active, created_at, updated_at
        FROM client_%s.agent_instances
        WHERE owner_user_id = $1 AND is_active = true
        ORDER BY created_at DESC
    `, clientID)

	rows, err := r.clientsDB.Query(ctx, query, userID)
	if err != nil {
		return nil, fmt.Errorf("failed to list instances: %w", err)
	}
	defer rows.Close()

	var instances []models.Persona
	for rows.Next() {
		var instance models.Persona
		var configJSON []byte

		err := rows.Scan(
			&instance.ID,
			&instance.Name,
			&configJSON,
			&instance.IsActive,
			&instance.CreatedAt,
			&instance.UpdatedAt,
		)
		if err != nil {
			continue
		}

		json.Unmarshal(configJSON, &instance.Config)
		instances = append(instances, instance)
	}

	return instances, nil
}

func (r *personaRepository) UpdateInstance(ctx context.Context, id string, name *string, config map[string]interface{}) (*models.Persona, error) {
	clientID, _ := ctx.Value("client_id").(string)

	// First get the current instance
	instance, err := r.GetInstanceByID(ctx, id)
	if err != nil {
		return nil, err
	}

	// Update fields
	if name != nil {
		instance.Name = *name
	}
	if config != nil {
		// Merge configs
		for k, v := range config {
			instance.Config[k] = v
		}
	}

	configJSON, _ := json.Marshal(instance.Config)

	query := fmt.Sprintf(`
        UPDATE client_%s.agent_instances
        SET name = $2, config = $3, updated_at = $4
        WHERE id = $1
    `, clientID)

	_, err = r.clientsDB.Exec(ctx, query, id, instance.Name, configJSON, time.Now())
	if err != nil {
		return nil, fmt.Errorf("failed to update instance: %w", err)
	}

	return instance, nil
}

func (r *personaRepository) DeleteInstance(ctx context.Context, id string) error {
	clientID, _ := ctx.Value("client_id").(string)

	query := fmt.Sprintf(`
        UPDATE client_%s.agent_instances
        SET is_active = false, updated_at = $2
        WHERE id = $1
    `, clientID)

	_, err := r.clientsDB.Exec(ctx, query, id, time.Now())
	if err != nil {
		return fmt.Errorf("failed to delete instance: %w", err)
	}

	return nil
}
-------------------------------------------------
filepath = ./internal/core-manager/api/server.go
// FILE: internal/core-manager/api/server.go
package api

import (
	"context"
	"fmt"
	"net/http"
	"time"

	"github.com/gin-gonic/gin"
	"github.com/google/uuid"
	"github.com/gqls/ai-persona-system/internal/core-manager/database"
	"github.com/gqls/ai-persona-system/internal/core-manager/middleware"
	"github.com/gqls/ai-persona-system/pkg/models"
	"github.com/gqls/ai-persona-system/platform/config"
	"github.com/jackc/pgx/v5/pgxpool"
	"go.uber.org/zap"
)

// Server represents the Core Manager API server
type Server struct {
	ctx         context.Context
	cfg         *config.ServiceConfig
	logger      *zap.Logger
	router      *gin.Engine
	httpServer  *http.Server
	personaRepo models.PersonaRepository
}

// NewServer creates a new API server instance
func NewServer(ctx context.Context, cfg *config.ServiceConfig, logger *zap.Logger, templatesDB, clientsDB *pgxpool.Pool) (*Server, error) {
	// Initialize repositories
	personaRepo := database.NewPersonaRepository(templatesDB, clientsDB, logger)

	// Create Gin router
	router := gin.New()
	router.Use(gin.Recovery())

	server := &Server{
		ctx:         ctx,
		cfg:         cfg,
		logger:      logger,
		router:      router,
		personaRepo: personaRepo,
	}

	// Setup routes
	server.setupRoutes(router)

	// Create HTTP server
	server.httpServer = &http.Server{
		Addr:    ":" + cfg.Server.Port,
		Handler: router,
	}

	return server, nil
}

// setupRoutes configures all API routes
func (s *Server) setupRoutes(router *gin.Engine) {
	// Health check
	router.GET("/health", s.handleHealth)

	// API v1 group with authentication
	apiV1 := router.Group("/api/v1")
	apiV1.Use(middleware.AuthMiddleware(s.logger))
	apiV1.Use(middleware.TenantMiddleware(s.logger))
	{
		// Template Management (Admin Only)
		templates := apiV1.Group("/templates")
		templates.Use(middleware.AdminOnly())
		{
			templates.POST("", s.handleCreateTemplate)
			templates.GET("", s.handleListTemplates)
			templates.GET("/:id", s.handleGetTemplate)
			templates.PUT("/:id", s.handleUpdateTemplate)
			templates.DELETE("/:id", s.handleDeleteTemplate)
		}

		// Persona Instance Management
		instances := apiV1.Group("/personas/instances")
		{
			instances.POST("", s.handleCreateInstance)
			instances.GET("", s.handleListInstances)
			instances.GET("/:id", s.handleGetInstance)
			instances.PATCH("/:id", s.handleUpdateInstance)
			instances.DELETE("/:id", s.handleDeleteInstance)
		}

		// Projects
		projects := apiV1.Group("/projects")
		{
			projects.POST("", s.handleCreateProject)
			projects.GET("", s.handleListProjects)
			projects.GET("/:id", s.handleGetProject)
			projects.PUT("/:id", s.handleUpdateProject)
			projects.DELETE("/:id", s.handleDeleteProject)
		}
	}
}

// Start starts the HTTP server
func (s *Server) Start() error {
	s.logger.Info("Starting Core Manager API server", zap.String("address", s.httpServer.Addr))
	return s.httpServer.ListenAndServe()
}

// Shutdown gracefully shuts down the server
func (s *Server) Shutdown(ctx context.Context) error {
	return s.httpServer.Shutdown(ctx)
}

// Address returns the server's address
func (s *Server) Address() string {
	return s.httpServer.Addr
}

// Health check handler
func (s *Server) handleHealth(c *gin.Context) {
	c.JSON(http.StatusOK, gin.H{
		"status":  "healthy",
		"service": s.cfg.ServiceInfo.Name,
		"version": s.cfg.ServiceInfo.Version,
	})
}

// Template Handlers

func (s *Server) handleCreateTemplate(c *gin.Context) {
	var req models.Persona
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": "Invalid request body: " + err.Error()})
		return
	}

	req.ID = uuid.New()
	req.IsTemplate = true
	req.CreatedAt = time.Now()
	req.UpdatedAt = time.Now()

	createdTemplate, err := s.personaRepo.CreateTemplate(c.Request.Context(), &req)
	if err != nil {
		s.logger.Error("Failed to create template", zap.Error(err))
		c.JSON(http.StatusInternalServerError, gin.H{"error": "Failed to create template"})
		return
	}

	c.JSON(http.StatusCreated, createdTemplate)
}

func (s *Server) handleListTemplates(c *gin.Context) {
	templates, err := s.personaRepo.ListTemplates(c.Request.Context())
	if err != nil {
		s.logger.Error("Failed to list templates", zap.Error(err))
		c.JSON(http.StatusInternalServerError, gin.H{"error": "Failed to retrieve templates"})
		return
	}
	c.JSON(http.StatusOK, gin.H{"templates": templates})
}

func (s *Server) handleGetTemplate(c *gin.Context) {
	templateID := c.Param("id")
	template, err := s.personaRepo.GetTemplateByID(c.Request.Context(), templateID)
	if err != nil {
		c.JSON(http.StatusNotFound, gin.H{"error": "Template not found"})
		return
	}
	c.JSON(http.StatusOK, template)
}

func (s *Server) handleUpdateTemplate(c *gin.Context) {
	templateID := c.Param("id")
	var req models.Persona
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": "Invalid request body"})
		return
	}

	req.ID, _ = uuid.Parse(templateID)
	req.UpdatedAt = time.Now()

	updatedTemplate, err := s.personaRepo.UpdateTemplate(c.Request.Context(), &req)
	if err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": "Failed to update template"})
		return
	}
	c.JSON(http.StatusOK, updatedTemplate)
}

func (s *Server) handleDeleteTemplate(c *gin.Context) {
	templateID := c.Param("id")
	if err := s.personaRepo.DeleteTemplate(c.Request.Context(), templateID); err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": "Failed to delete template"})
		return
	}
	c.Status(http.StatusNoContent)
}

// Instance Handlers

func (s *Server) handleCreateInstance(c *gin.Context) {
	claims := c.MustGet("user_claims").(*middleware.AuthClaims)

	var req struct {
		TemplateID   string `json:"template_id" binding:"required,uuid"`
		InstanceName string `json:"instance_name" binding:"required"`
	}
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": "Invalid request: " + err.Error()})
		return
	}

	instance, err := s.personaRepo.CreateInstanceFromTemplate(c.Request.Context(),
		req.TemplateID, claims.UserID, req.InstanceName)
	if err != nil {
		s.logger.Error("Failed to create instance", zap.Error(err))
		c.JSON(http.StatusInternalServerError, gin.H{"error": "Could not create instance"})
		return
	}
	c.JSON(http.StatusCreated, instance)
}

func (s *Server) handleListInstances(c *gin.Context) {
	claims := c.MustGet("user_claims").(*middleware.AuthClaims)
	instances, err := s.personaRepo.ListInstances(c.Request.Context(), claims.UserID)
	if err != nil {
		s.logger.Error("Failed to list instances", zap.Error(err))
		c.JSON(http.StatusInternalServerError, gin.H{"error": "Could not retrieve instances"})
		return
	}
	c.JSON(http.StatusOK, gin.H{"instances": instances})
}

func (s *Server) handleGetInstance(c *gin.Context) {
	instanceID := c.Param("id")
	instance, err := s.personaRepo.GetInstanceByID(c.Request.Context(), instanceID)
	if err != nil {
		c.JSON(http.StatusNotFound, gin.H{"error": "Instance not found"})
		return
	}
	c.JSON(http.StatusOK, instance)
}

func (s *Server) handleUpdateInstance(c *gin.Context) {
	instanceID := c.Param("id")
	var req struct {
		Name   *string                `json:"name"`
		Config map[string]interface{} `json:"config"`
	}
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": "Invalid request body"})
		return
	}

	updatedInstance, err := s.personaRepo.UpdateInstance(c.Request.Context(), instanceID, req.Name, req.Config)
	if err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": "Failed to update instance"})
		return
	}
	c.JSON(http.StatusOK, updatedInstance)
}

func (s *Server) handleDeleteInstance(c *gin.Context) {
	instanceID := c.Param("id")
	if err := s.personaRepo.DeleteInstance(c.Request.Context(), instanceID); err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": "Failed to delete instance"})
		return
	}
	c.Status(http.StatusNoContent)
}

// Project Handlers (placeholders)

func (s *Server) handleCreateProject(c *gin.Context) {
	c.JSON(http.StatusNotImplemented, gin.H{"error": "Not implemented"})
}

func (s *Server) handleListProjects(c *gin.Context) {
	c.JSON(http.StatusOK, gin.H{"projects": []interface{}{}})
}

func (s *Server) handleGetProject(c *gin.Context) {
	c.JSON(http.StatusNotImplemented, gin.H{"error": "Not implemented"})
}

func (s *Server) handleUpdateProject(c *gin.Context) {
	c.JSON(http.StatusNotImplemented, gin.H{"error": "Not implemented"})
}

func (s *Server) handleDeleteProject(c *gin.Context) {
	c.JSON(http.StatusNotImplemented, gin.H{"error": "Not implemented"})
}
-------------------------------------------------
filepath = ./internal/core-manager/pkg/models/interfaces.go
// FILE: core-manager/pkg/models/interfaces.go
// We update the repository interface to include the new methods.
package models

import (
	"context"
	"github.com/google/uuid"
)

type PersonaRepository interface {
	// ... (existing methods: CreateProject, GetProjectDetails, etc.)

	// --- NEW Template Methods ---
	CreateTemplate(ctx context.Context, template *Persona) (*Persona, error)
	GetTemplateByID(ctx context.Context, id string) (*Persona, error)
	ListTemplates(ctx context.Context) ([]Persona, error)
	UpdateTemplate(ctx context.Context, template *Persona) (*Persona, error)
	DeleteTemplate(ctx context.Context, id string) error

	// --- NEW Instance Methods ---
	// Note: CreateInstanceFromTemplate was already defined, but we refine it here.
	CreateInstanceFromTemplate(ctx context.Context, templateID string, userID string, instanceName string) (*Persona, error)
	GetInstanceByID(ctx context.Context, id string) (*Persona, error)
	ListInstances(ctx context.Context, userID string) ([]Persona, error)
	UpdateInstance(ctx context.Context, id string, name *string, config map[string]interface{}) (*Persona, error)
	DeleteInstance(ctx context.Context, id string) error
}
-------------------------------------------------
filepath = ./internal/core-manager/middleware/auth.go
// FILE: internal/core-manager/middleware/auth.go
package middleware

import (
	"net/http"
	"strings"

	"github.com/gin-gonic/gin"
	"github.com/golang-jwt/jwt/v5"
	"go.uber.org/zap"
)

// AuthClaims represents the JWT claims
type AuthClaims struct {
	UserID   string `json:"user_id"`
	ClientID string `json:"client_id"`
	Email    string `json:"email"`
	Role     string `json:"role"`
	jwt.RegisteredClaims
}

// AuthMiddleware validates JWT tokens
func AuthMiddleware(logger *zap.Logger) gin.HandlerFunc {
	return func(c *gin.Context) {
		authHeader := c.GetHeader("Authorization")
		if authHeader == "" {
			c.JSON(http.StatusUnauthorized, gin.H{"error": "Authorization header required"})
			c.Abort()
			return
		}

		tokenString := strings.Replace(authHeader, "Bearer ", "", 1)

		// Parse token
		token, err := jwt.ParseWithClaims(tokenString, &AuthClaims{}, func(token *jwt.Token) (interface{}, error) {
			// TODO: Get actual JWT secret from config
			return []byte("your-secret-key"), nil
		})

		if err != nil {
			logger.Error("Failed to parse JWT", zap.Error(err))
			c.JSON(http.StatusUnauthorized, gin.H{"error": "Invalid token"})
			c.Abort()
			return
		}

		if claims, ok := token.Claims.(*AuthClaims); ok && token.Valid {
			c.Set("user_claims", claims)
			c.Next()
		} else {
			c.JSON(http.StatusUnauthorized, gin.H{"error": "Invalid token claims"})
			c.Abort()
			return
		}
	}
}

// TenantMiddleware sets up tenant context
func TenantMiddleware(logger *zap.Logger) gin.HandlerFunc {
	return func(c *gin.Context) {
		claims := c.MustGet("user_claims").(*AuthClaims)

		// Set tenant context for database operations
		c.Set("client_id", claims.ClientID)
		c.Set("user_id", claims.UserID)

		c.Next()
	}
}

// AdminOnly restricts access to admin users
func AdminOnly() gin.HandlerFunc {
	return func(c *gin.Context) {
		claims := c.MustGet("user_claims").(*AuthClaims)

		if claims.Role != "admin" {
			c.JSON(http.StatusForbidden, gin.H{"error": "Admin access required"})
			c.Abort()
			return
		}

		c.Next()
	}
}
-------------------------------------------------
filepath = ./platform/kafka/consumer.go
// FILE: platform/kafka/consumer.go
package kafka

import (
	"context"
	"fmt"

	"github.com/segmentio/kafka-go"
	"go.uber.org/zap"
)

// Consumer wraps the kafka-go reader for standardized consumption
type Consumer struct {
	reader *kafka.Reader
	logger *zap.Logger
}

// NewConsumer creates a new standardized Kafka consumer
func NewConsumer(brokers []string, topic, groupID string, logger *zap.Logger) (*Consumer, error) {
	if len(brokers) == 0 {
		return nil, fmt.Errorf("kafka brokers list cannot be empty")
	}
	if topic == "" {
		return nil, fmt.Errorf("kafka topic cannot be empty")
	}
	if groupID == "" {
		return nil, fmt.Errorf("kafka groupID cannot be empty")
	}

	reader := kafka.NewReader(kafka.ReaderConfig{
		Brokers:        brokers,
		GroupID:        groupID,
		Topic:          topic,
		MinBytes:       10e3, // 10KB
		MaxBytes:       10e6, // 10MB
		CommitInterval: 0,    // Manual commit
	})

	logger.Info("Kafka consumer created",
		zap.Strings("brokers", brokers),
		zap.String("topic", topic),
		zap.String("groupID", groupID),
	)

	return &Consumer{
		reader: reader,
		logger: logger,
	}, nil
}

// FetchMessage fetches the next message from the topic
func (c *Consumer) FetchMessage(ctx context.Context) (kafka.Message, error) {
	msg, err := c.reader.FetchMessage(ctx)
	if err != nil {
		if err == context.Canceled {
			return kafka.Message{}, err
		}
		c.logger.Error("Failed to fetch message from Kafka", zap.Error(err))
		return kafka.Message{}, err
	}
	return msg, nil
}

// CommitMessages commits the offset for the given messages
func (c *Consumer) CommitMessages(ctx context.Context, msgs ...kafka.Message) error {
	err := c.reader.CommitMessages(ctx, msgs...)
	if err != nil {
		c.logger.Error("Failed to commit Kafka messages", zap.Error(err))
	}
	return err
}

// Close gracefully closes the consumer's reader
func (c *Consumer) Close() error {
	c.logger.Info("Closing Kafka consumer...")
	return c.reader.Close()
}
-------------------------------------------------
filepath = ./platform/kafka/utils.go
// FILE: platform/kafka/utils.go
package kafka

import "github.com/segmentio/kafka-go"

// HeadersToMap converts Kafka headers to a map for easier access
func HeadersToMap(headers []kafka.Header) map[string]string {
	result := make(map[string]string)
	for _, h := range headers {
		result[h.Key] = string(h.Value)
	}
	return result
}
-------------------------------------------------
filepath = ./platform/kafka/producer.go
// FILE: platform/kafka/producer.go
package kafka

import (
	"context"
	"fmt"
	"time"

	"github.com/segmentio/kafka-go"
	"go.uber.org/zap"
)

// Producer wraps the kafka-go writer for standardized message production
type Producer struct {
	writer *kafka.Writer
	logger *zap.Logger
}

// NewProducer creates a new standardized Kafka producer
func NewProducer(brokers []string, logger *zap.Logger) (*Producer, error) {
	if len(brokers) == 0 {
		return nil, fmt.Errorf("kafka brokers list cannot be empty")
	}

	writer := &kafka.Writer{
		Addr:         kafka.TCP(brokers...),
		Balancer:     &kafka.LeastBytes{},
		RequiredAcks: kafka.RequireAll,
		Async:        false,
		WriteTimeout: 10 * time.Second,
	}

	logger.Info("Kafka producer created", zap.Strings("brokers", brokers))

	return &Producer{
		writer: writer,
		logger: logger,
	}, nil
}

// Produce sends a message to a specific topic with standard headers
func (p *Producer) Produce(ctx context.Context, topic string, headers map[string]string, key, value []byte) error {
	kafkaHeaders := make([]kafka.Header, 0, len(headers))
	for k, v := range headers {
		kafkaHeaders = append(kafkaHeaders, kafka.Header{Key: k, Value: []byte(v)})
	}

	msg := kafka.Message{
		Topic:   topic,
		Key:     key,
		Value:   value,
		Headers: kafkaHeaders,
		Time:    time.Now().UTC(),
	}

	err := p.writer.WriteMessages(ctx, msg)
	if err != nil {
		p.logger.Error("Failed to produce Kafka message",
			zap.String("topic", topic),
			zap.Error(err),
		)
		return fmt.Errorf("failed to write message to kafka: %w", err)
	}

	p.logger.Debug("Successfully produced message", zap.String("topic", topic), zap.String("key", string(key)))
	return nil
}

// Close gracefully closes the producer's writer
func (p *Producer) Close() error {
	p.logger.Info("Closing Kafka producer...")
	return p.writer.Close()
}
-------------------------------------------------
filepath = ./platform/logger/logger.go
// FILE: platform/logger/logger.go
package logger

import (
	"fmt"
	"log"

	"go.uber.org/zap"
	"go.uber.org/zap/zapcore"
)

// New creates a new Zap logger with a specified log level
func New(logLevel string) (*zap.Logger, error) {
	var level zapcore.Level
	if err := level.UnmarshalText([]byte(logLevel)); err != nil {
		log.Printf("logger: invalid log level '%s', defaulting to 'info'", logLevel)
		level = zapcore.InfoLevel
	}

	config := zap.Config{
		Level:       zap.NewAtomicLevelAt(level),
		Development: false,
		Encoding:    "json",
		EncoderConfig: zapcore.EncoderConfig{
			TimeKey:        "ts",
			LevelKey:       "level",
			NameKey:        "logger",
			CallerKey:      "caller",
			MessageKey:     "msg",
			StacktraceKey:  "stacktrace",
			LineEnding:     zapcore.DefaultLineEnding,
			EncodeLevel:    zapcore.LowercaseLevelEncoder,
			EncodeTime:     zapcore.ISO8601TimeEncoder,
			EncodeDuration: zapcore.SecondsDurationEncoder,
			EncodeCaller:   zapcore.ShortCallerEncoder,
		},
		OutputPaths:      []string{"stdout"},
		ErrorOutputPaths: []string{"stderr"},
	}

	logger, err := config.Build()
	if err != nil {
		return nil, fmt.Errorf("logger: failed to initialize zap logger: %w", err)
	}

	logger.Info("Logger initialized successfully", zap.String("level", level.String()))
	return logger, nil
}
-------------------------------------------------
filepath = ./platform/storage/s3.go
// FILE: platform/storage/s3.go
package storage

import (
	"context"
	"fmt"
	"io"
	"os"

	"github.com/aws/aws-sdk-go-v2/aws"
	"github.com/aws/aws-sdk-go-v2/config"
	"github.com/aws/aws-sdk-go-v2/credentials"
	"github.com/aws/aws-sdk-go-v2/service/s3"
	platform_config "github.com/gqls/ai-persona-system/platform/config"
)

// Client defines the interface for our object storage operations
type Client interface {
	Upload(ctx context.Context, key, contentType string, body io.Reader) (string, error)
	Download(ctx context.Context, key string) (io.ReadCloser, error)
}

// S3Client implements the Client interface for S3-compatible services
type S3Client struct {
	client *s3.Client
	bucket string
}

// NewS3Client creates a new client for interacting with S3 or MinIO
func NewS3Client(ctx context.Context, cfg platform_config.ObjectStorageConfig) (*S3Client, error) {
	accessKey := os.Getenv(cfg.AccessKeyEnvVar)
	secretKey := os.Getenv(cfg.SecretKeyEnvVar)

	if accessKey == "" || secretKey == "" {
		return nil, fmt.Errorf("object storage credentials not found in environment variables (%s, %s)",
			cfg.AccessKeyEnvVar, cfg.SecretKeyEnvVar)
	}

	resolver := aws.EndpointResolverWithOptionsFunc(func(service, region string, options ...interface{}) (aws.Endpoint, error) {
		return aws.Endpoint{
			URL:           cfg.Endpoint,
			SigningRegion: "us-east-1", // This can be anything for MinIO
		}, nil
	})

	awsCfg, err := config.LoadDefaultConfig(ctx,
		config.WithEndpointResolverWithOptions(resolver),
		config.WithCredentialsProvider(credentials.NewStaticCredentialsProvider(accessKey, secretKey, "")),
	)
	if err != nil {
		return nil, fmt.Errorf("failed to load s3 config: %w", err)
	}

	// For MinIO, you must use path-style addressing
	s3Client := s3.NewFromConfig(awsCfg, func(o *s3.Options) {
		o.UsePathStyle = true
	})

	return &S3Client{
		client: s3Client,
		bucket: cfg.Bucket,
	}, nil
}

// Upload puts a new object into the storage bucket
func (c *S3Client) Upload(ctx context.Context, key, contentType string, body io.Reader) (string, error) {
	_, err := c.client.PutObject(ctx, &s3.PutObjectInput{
		Bucket:      aws.String(c.bucket),
		Key:         aws.String(key),
		Body:        body,
		ContentType: aws.String(contentType),
	})
	if err != nil {
		return "", fmt.Errorf("failed to upload object to s3: %w", err)
	}
	// Return the S3 URI for the object
	return fmt.Sprintf("s3://%s/%s", c.bucket, key), nil
}

// Download retrieves an object from the storage bucket
func (c *S3Client) Download(ctx context.Context, key string) (io.ReadCloser, error) {
	output, err := c.client.GetObject(ctx, &s3.GetObjectInput{
		Bucket: aws.String(c.bucket),
		Key:    aws.String(key),
	})
	if err != nil {
		return nil, fmt.Errorf("failed to download object from s3: %w", err)
	}
	return output.Body, nil
}
-------------------------------------------------
filepath = ./platform/storage/interface.go
package storage
-------------------------------------------------
filepath = ./platform/aiservice/anthropic.go
// FILE: platform/aiservice/anthropic.go
package aiservice

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"os"
)

// AnthropicClient implements the AIService interface for Anthropic's Claude
type AnthropicClient struct {
	apiKey     string
	model      string
	httpClient *http.Client
}

// NewAnthropicClient creates a new Anthropic client
func NewAnthropicClient(ctx context.Context, config map[string]interface{}) (*AnthropicClient, error) {
	apiKeyEnvVar := config["api_key_env_var"].(string)
	apiKey := os.Getenv(apiKeyEnvVar)
	if apiKey == "" {
		return nil, fmt.Errorf("API key not found in environment variable %s", apiKeyEnvVar)
	}

	model := config["model"].(string)

	return &AnthropicClient{
		apiKey:     apiKey,
		model:      model,
		httpClient: &http.Client{},
	}, nil
}

// GenerateText generates text using Claude
func (c *AnthropicClient) GenerateText(ctx context.Context, prompt string, options map[string]interface{}) (string, error) {
	// Build request
	requestBody := map[string]interface{}{
		"model":       c.model,
		"max_tokens":  2048,
		"temperature": 0.7,
		"messages": []map[string]string{
			{
				"role":    "user",
				"content": prompt,
			},
		},
	}

	// Override with provided options
	if options != nil {
		if maxTokens, ok := options["max_tokens"]; ok {
			requestBody["max_tokens"] = maxTokens
		}
		if temperature, ok := options["temperature"]; ok {
			requestBody["temperature"] = temperature
		}
	}

	jsonBody, err := json.Marshal(requestBody)
	if err != nil {
		return "", fmt.Errorf("failed to marshal request: %w", err)
	}

	// Create HTTP request
	req, err := http.NewRequestWithContext(ctx, "POST", "https://api.anthropic.com/v1/messages", bytes.NewBuffer(jsonBody))
	if err != nil {
		return "", fmt.Errorf("failed to create request: %w", err)
	}

	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("x-api-key", c.apiKey)
	req.Header.Set("anthropic-version", "2023-06-01")

	// Execute request
	resp, err := c.httpClient.Do(req)
	if err != nil {
		return "", fmt.Errorf("failed to execute request: %w", err)
	}
	defer resp.Body.Close()

	// Read response
	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return "", fmt.Errorf("failed to read response: %w", err)
	}

	if resp.StatusCode != http.StatusOK {
		return "", fmt.Errorf("API request failed with status %d: %s", resp.StatusCode, string(body))
	}

	// Parse response
	var response struct {
		Content []struct {
			Text string `json:"text"`
		} `json:"content"`
	}

	if err := json.Unmarshal(body, &response); err != nil {
		return "", fmt.Errorf("failed to parse response: %w", err)
	}

	if len(response.Content) == 0 {
		return "", fmt.Errorf("no content in response")
	}

	return response.Content[0].Text, nil
}

// GenerateEmbedding generates embeddings (not implemented for Anthropic)
func (c *AnthropicClient) GenerateEmbedding(ctx context.Context, text string) ([]float32, error) {
	return nil, fmt.Errorf("embedding generation not supported by Anthropic")
}
-------------------------------------------------
filepath = ./platform/aiservice/interface.go
// FILE: platform/aiservice/interface.go
package aiservice

import "context"

// AIService defines the interface for AI providers
type AIService interface {
	GenerateText(ctx context.Context, prompt string, options map[string]interface{}) (string, error)
	GenerateEmbedding(ctx context.Context, text string) ([]float32, error)
}

// TextGenerationOptions contains common options for text generation
type TextGenerationOptions struct {
	Temperature float64
	MaxTokens   int
	Model       string
}
-------------------------------------------------
filepath = ./platform/observability/tracing.go
package observability
-------------------------------------------------
filepath = ./platform/config/loader.go
// FILE: platform/config/loader.go
package config

import (
	"fmt"
	"log"
	"os"
	"strings"

	"github.com/spf13/viper"
)

// ServiceConfig is the top-level configuration struct for any service
type ServiceConfig struct {
	ServiceInfo    ServiceInfoConfig      `mapstructure:"service_info"`
	Server         ServerConfig           `mapstructure:"server"`
	Logging        LoggingConfig          `mapstructure:"logging"`
	Observability  ObservabilityConfig    `mapstructure:"observability"`
	Infrastructure InfrastructureConfig   `mapstructure:"infrastructure"`
	Custom         map[string]interface{} `mapstructure:"custom"`
}

type ServiceInfoConfig struct {
	Name        string `mapstructure:"name"`
	Version     string `mapstructure:"version"`
	Environment string `mapstructure:"environment"`
}

type ServerConfig struct {
	Port string `mapstructure:"port"`
}

type LoggingConfig struct {
	Level string `mapstructure:"level"`
}

type ObservabilityConfig struct {
	TracingEndpoint string `mapstructure:"tracing_endpoint"`
}

type InfrastructureConfig struct {
	KafkaBrokers      []string            `mapstructure:"kafka_brokers"`
	ClientsDatabase   DatabaseConfig      `mapstructure:"clients_database"`
	TemplatesDatabase DatabaseConfig      `mapstructure:"templates_database"`
	AuthDatabase      DatabaseConfig      `mapstructure:"auth_database"`
	ObjectStorage     ObjectStorageConfig `mapstructure:"object_storage"`
}

type DatabaseConfig struct {
	Host           string `mapstructure:"host"`
	Port           int    `mapstructure:"port"`
	User           string `mapstructure:"user"`
	PasswordEnvVar string `mapstructure:"password_env_var"`
	DBName         string `mapstructure:"db_name"`
	SSLMode        string `mapstructure:"sslmode"`
}

type ObjectStorageConfig struct {
	Provider        string `mapstructure:"provider"`
	Endpoint        string `mapstructure:"endpoint"`
	Bucket          string `mapstructure:"bucket"`
	AccessKeyEnvVar string `mapstructure:"access_key_env_var"`
	SecretKeyEnvVar string `mapstructure:"secret_key_env_var"`
}

// Load reads a YAML config file and overrides with environment variables
func Load(path string) (*ServiceConfig, error) {
	v := viper.New()
	v.SetDefault("server.port", "8080")
	v.SetDefault("logging.level", "info")
	v.SetDefault("infrastructure.database.sslmode", "disable")

	v.SetConfigFile(path)
	v.SetConfigType("yaml")
	if err := v.ReadInConfig(); err != nil {
		if _, ok := err.(viper.ConfigFileNotFoundError); ok {
			log.Printf("config: file not found at %s, relying on defaults and environment variables", path)
		} else {
			return nil, fmt.Errorf("config: error reading config file %s: %w", path, err)
		}
	}

	v.SetEnvPrefix("SERVICE")
	v.SetEnvKeyReplacer(strings.NewReplacer(".", "_"))
	v.AutomaticEnv()

	var cfg ServiceConfig
	if err := v.Unmarshal(&cfg); err != nil {
		return nil, fmt.Errorf("config: unable to unmarshal config: %w", err)
	}

	return &cfg, nil
}
-------------------------------------------------
filepath = ./platform/agentbase/agent.go
// FILE: platform/agentbase/agent.go
package agentbase

import (
	"context"
	"database/sql"
	"encoding/json"
	"fmt"
	"time"

	"github.com/google/uuid"
	"github.com/gqls/ai-persona-system/pkg/models"
	"github.com/gqls/ai-persona-system/platform/config"
	"github.com/gqls/ai-persona-system/platform/database"
	"github.com/gqls/ai-persona-system/platform/kafka"
	"github.com/gqls/ai-persona-system/platform/orchestration"
	"github.com/jackc/pgx/v5/pgxpool"
	"go.uber.org/zap"
)

// Agent is the core struct for the "Agent Chassis"
type Agent struct {
	ctx           context.Context
	cfg           *config.ServiceConfig
	logger        *zap.Logger
	clientsDB     *pgxpool.Pool
	kafkaConsumer *kafka.Consumer
	kafkaProducer *kafka.Producer
	orchestrator  *orchestration.SagaCoordinator
	agentType     string
}

// New creates and initializes the agent chassis
func New(ctx context.Context, cfg *config.ServiceConfig, logger *zap.Logger, agentType string, topic string) (*Agent, error) {
	// Initialize database connection
	clientsPool, err := database.NewPostgresConnection(ctx, cfg.Infrastructure.ClientsDatabase, logger)
	if err != nil {
		return nil, fmt.Errorf("failed to connect to clients database: %w", err)
	}

	// Initialize Kafka consumer
	consumer, err := kafka.NewConsumer(cfg.Infrastructure.KafkaBrokers, topic, agentType+"-group", logger)
	if err != nil {
		clientsPool.Close()
		return nil, fmt.Errorf("failed to create kafka consumer: %w", err)
	}

	// Initialize Kafka producer
	producer, err := kafka.NewProducer(cfg.Infrastructure.KafkaBrokers, logger)
	if err != nil {
		clientsPool.Close()
		consumer.Close()
		return nil, fmt.Errorf("failed to create kafka producer: %w", err)
	}

	// Create standard DB handle for orchestrator
	stdDB, err := sql.Open("pgx", clientsPool.Config().ConnString())
	if err != nil {
		return nil, fmt.Errorf("failed to get standard DB handle: %w", err)
	}

	// Initialize orchestrator
	sagaCoordinator := orchestration.NewSagaCoordinator(stdDB, producer, logger)

	return &Agent{
		ctx:           ctx,
		cfg:           cfg,
		logger:        logger,
		clientsDB:     clientsPool,
		kafkaConsumer: consumer,
		kafkaProducer: producer,
		orchestrator:  sagaCoordinator,
		agentType:     agentType,
	}, nil
}

// Run starts the main Kafka consumer loop
func (a *Agent) Run() error {
	a.logger.Info("Agent running", zap.String("type", a.agentType))

	for {
		select {
		case <-a.ctx.Done():
			a.logger.Info("Agent shutting down")
			a.kafkaConsumer.Close()
			a.kafkaProducer.Close()
			a.clientsDB.Close()
			return nil
		default:
			msg, err := a.kafkaConsumer.FetchMessage(a.ctx)
			if err != nil {
				if err == context.Canceled {
					continue
				}
				a.logger.Error("Failed to fetch message", zap.Error(err))
				time.Sleep(1 * time.Second)
				continue
			}

			// Process each message in a goroutine
			go a.handleMessage(msg)
		}
	}
}

// handleMessage processes a single task
func (a *Agent) handleMessage(msg kafka.Message) {
	headers := kafka.HeadersToMap(msg.Headers)

	clientID := headers["client_id"]
	agentInstanceID := headers["agent_instance_id"]

	if clientID == "" || agentInstanceID == "" {
		a.logger.Error("Message missing required headers",
			zap.String("topic", msg.Topic),
			zap.Int64("offset", msg.Offset))
		a.kafkaConsumer.CommitMessages(context.Background(), msg)
		return
	}

	l := a.logger.With(
		zap.String("correlation_id", headers["correlation_id"]),
		zap.String("request_id", headers["request_id"]),
		zap.String("client_id", clientID),
		zap.String("agent_instance_id", agentInstanceID),
	)

	// Load agent configuration
	agentConfig, err := a.loadAgentConfig(clientID, agentInstanceID)
	if err != nil {
		l.Error("Failed to load agent configuration", zap.Error(err))
		a.kafkaConsumer.CommitMessages(context.Background(), msg)
		return
	}

	l.Info("Agent instance loaded", zap.String("agent_type", agentConfig.AgentType))

	// Execute workflow
	if err := a.orchestrator.ExecuteWorkflow(a.ctx, agentConfig.Workflow, headers, msg.Value); err != nil {
		l.Error("Workflow execution failed", zap.Error(err))
	}

	// Commit message
	if err := a.kafkaConsumer.CommitMessages(context.Background(), msg); err != nil {
		l.Error("Failed to commit kafka message", zap.Error(err))
	}
}

// loadAgentConfig fetches the agent's configuration from the database
func (a *Agent) loadAgentConfig(clientID, agentInstanceID string) (*models.AgentConfig, error) {
	// TODO: Implement actual database query
	// This would query the agent_instances table in the client's schema

	// For now, return a mock configuration
	return &models.AgentConfig{
		AgentID:   agentInstanceID,
		AgentType: a.agentType,
		Version:   1,
		CoreLogic: map[string]interface{}{
			"model":       "claude-3-opus",
			"temperature": 0.7,
		},
		Workflow: models.WorkflowPlan{
			StartStep: "generate",
			Steps: map[string]models.Step{
				"generate": {
					Action:      "ai_text_generate",
					Description: "Generate text using AI",
					NextStep:    "complete",
				},
				"complete": {
					Action: "complete_workflow",
				},
			},
		},
	}, nil
}

// Helper function to create response headers
func (a *Agent) createResponseHeaders(originalHeaders map[string]string) map[string]string {
	return map[string]string{
		"correlation_id": originalHeaders["correlation_id"],
		"causation_id":   originalHeaders["request_id"],
		"request_id":     uuid.NewString(),
		"client_id":      originalHeaders["client_id"],
	}
}
-------------------------------------------------
filepath = ./platform/contracts/contracts.go
// FILE: platform/contracts/contracts.go
// This package defines the core data structures used for agent configuration
// and communication throughout the entire system. It is the "shared language"
// that all services and agents will use.
package contracts

// AgentConfig is the master configuration for a single agent instance.
// This is stored as a JSONB object in the `agent_instances` table and
// loaded by the Agent Chassis at runtime to determine its behavior.
type AgentConfig struct {
	AgentID   string          `json:"agent_id"`
	AgentType string          `json:"agent_type"` // e.g., "copywriter", "orchestrator", "reasoning-agent"
	Version   int             `json:"version"`
	CoreLogic CoreLogicConfig `json:"core_logic"` // The "Who" - parameters for its main skill
	Workflow  WorkflowPlan    `json:"workflow"`   // The "How" - the plan it follows to do its job
}

// CoreLogicConfig is a generic map to hold the specific parameters
// for an agent's primary function.
// For an AI agent, this would contain prompts and model info.
// For an adapter, it might contain API endpoints and credentials.
type CoreLogicConfig map[string]interface{}

// WorkflowPlan defines the orchestration logic for an agent.
// It is a declarative, directed graph of steps.
type WorkflowPlan struct {
	StartStep string          `json:"start_step"`
	Steps     map[string]Step `json:"steps"`
}

// Step represents a single node in the workflow graph. It can be either
// a direct action for the agent to perform, or a call to another agent.
type Step struct {
	// Action is the specific function this agent should perform for this step.
	// e.g., "generate_text", "fan_out", "pause_for_human_input".
	Action string `json:"action"`

	// Description provides a human-readable explanation of the step's purpose.
	Description string `json:"description"`

	// Topic is the Kafka topic to send a message to if this step involves
	// calling another agent or service.
	Topic string `json:"topic,omitempty"`

	// Dependencies lists the `step_name`s that must be completed before
	// this step can begin. The orchestrator will not execute this step
	// until it has received responses from all dependencies.
	Dependencies []string `json:"dependencies,omitempty"`

	// NextStep defines the name of the next step to execute upon successful
	// completion of this one, for simple linear workflows.
	NextStep string `json:"next_step,omitempty"`

	// SubTasks is used for "fan_out" actions, defining a list of parallel
	// tasks to be executed.
	SubTasks []SubTask `json:"sub_tasks,omitempty"`
}

// SubTask defines a single task to be executed in parallel within a "fan_out" step.
type SubTask struct {
	// StepName is the logical name for this sub-task, used for dependency tracking.
	StepName string `json:"step_name"`
	// Topic is the Kafka topic to which the request for this sub-task will be sent.
	Topic string `json:"topic"`
}
-------------------------------------------------
filepath = ./platform/orchestration/coordinator_test.go
// FILE: platform/orchestration/coordinator_test.go
package orchestration

import (
	"context"
	"database/sql"
	"encoding/json"
	"errors"
	"regexp"
	"testing"
	"time"

	"github.com/DATA-DOG/go-sqlmock"
	"github.com/google/uuid"
	"github.com/gqls/ai-persona-system/pkg/models"
	"github.com/gqls/ai-persona-system/platform/governance"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/mock"
	"github.com/stretchr/testify/require"
	"go.uber.org/zap"
)

// MockKafkaProducer allows us to test the coordinator without a real Kafka connection.
type MockKafkaProducer struct {
	mock.Mock
}

func (m *MockKafkaProducer) Produce(ctx context.Context, topic string, headers map[string]string, key, value []byte) error {
	args := m.Called(ctx, topic, headers, key, value)
	return args.Error(0)
}

func (m *MockKafkaProducer) Close() error {
	args := m.Called()
	return args.Error(0)
}

// setupTest creates the coordinator with mocked dependencies for testing.
func setupTest(t *testing.T) (*SagaCoordinator, *MockKafkaProducer, *sql.DB, sqlmock.Sqlmock) {
	db, mockDB, err := sqlmock.New(sqlmock.QueryMatcherOption(sqlmock.QueryMatcherRegexp))
	require.NoError(t, err)

	mockProducer := new(MockKafkaProducer)
	logger := zap.NewNop()

	coordinator := NewSagaCoordinator(db, mockProducer, logger)
	require.NotNil(t, coordinator)

	return coordinator, mockProducer, db, mockDB
}

// TestExecuteWorkflow_InitialStep verifies the start of a new workflow.
func TestExecuteWorkflow_InitialStep(t *testing.T) {
	coordinator, mockProducer, db, mockDB := setupTest(t)
	defer db.Close()

	ctx := context.Background()
	correlationID := uuid.NewString()
	headers := map[string]string{
		"correlation_id":      correlationID,
		"request_id":          uuid.NewString(),
		governance.FuelHeader: "1000",
	}
	initialData, _ := json.Marshal(map[string]string{"goal": "test"})

	plan := models.WorkflowPlan{
		StartStep: "step1",
		Steps: map[string]models.Step{
			"step1":  {Action: "do_something", Topic: "topic.do_something", NextStep: "finish"},
			"finish": {Action: "complete_workflow"},
		},
	}

	// Expect the coordinator to check if state exists (it won't).
	mockDB.ExpectQuery("SELECT .* FROM orchestrator_state WHERE correlation_id = ?").
		WithArgs(correlationID).
		WillReturnError(sql.ErrNoRows)

	// Expect it to create the initial state.
	mockDB.ExpectExec("INSERT INTO orchestrator_state").
		WithArgs(correlationID, StatusRunning, "step1", mock.Anything, mock.Anything, initialData, mock.Anything, mock.Anything, mock.Anything, mock.Anything).
		WillReturnResult(sqlmock.NewResult(1, 1))

	// Expect it to fetch the state again after creation.
	rows := sqlmock.NewRows([]string{"correlation_id", "status", "current_step", "awaited_steps", "collected_data", "initial_request_data"}).
		AddRow(correlationID, StatusRunning, "step1", "[]", "{}", initialData)
	mockDB.ExpectQuery("SELECT .* FROM orchestrator_state WHERE correlation_id = ?").
		WithArgs(correlationID).
		WillReturnRows(rows)

	// Expect it to produce a Kafka message for the first step.
	mockProducer.On("Produce", ctx, "topic.do_something", mock.Anything, mock.Anything, mock.Anything).Return(nil).Once()

	// Expect it to update the state to AWAITING_RESPONSES.
	mockDB.ExpectExec("UPDATE orchestrator_state SET").
		WillReturnResult(sqlmock.NewResult(1, 1))

	err := coordinator.ExecuteWorkflow(ctx, plan, headers, initialData)
	require.NoError(t, err)

	mockProducer.AssertExpectations(t)
	require.NoError(t, mockDB.ExpectationsWereMet())
}

// TestExecuteWorkflow_DependenciesNotMet verifies the workflow waits correctly.
func TestExecuteWorkflow_DependenciesNotMet(t *testing.T) {
	coordinator, mockProducer, db, mockDB := setupTest(t)
	defer db.Close()

	ctx := context.Background()
	correlationID := uuid.NewString()
	headers := map[string]string{"correlation_id": correlationID, governance.FuelHeader: "1000"}

	plan := models.WorkflowPlan{
		StartStep: "step2", // Start at a step that has dependencies
		Steps: map[string]models.Step{
			"step1": {Action: "do_something"},
			"step2": {Action: "do_something_else", Dependencies: []string{"step1"}},
		},
	}

	// Mock the state where step2 is current, but step1 has not responded.
	stateJSON := `{"get_other_data": {"status": "complete"}}` // Missing "step1" data
	rows := sqlmock.NewRows([]string{"correlation_id", "status", "current_step", "awaited_steps", "collected_data"}).
		AddRow(correlationID, StatusRunning, "step2", "[]", stateJSON)
	mockDB.ExpectQuery("SELECT .* FROM orchestrator_state WHERE correlation_id = ?").
		WithArgs(correlationID).
		WillReturnRows(rows)

	err := coordinator.ExecuteWorkflow(ctx, plan, headers, nil)
	require.NoError(t, err, "Waiting for dependencies should not be an error")

	// Crucially, the producer should NOT have been called.
	mockProducer.AssertNotCalled(t, "Produce")
	require.NoError(t, mockDB.ExpectationsWereMet())
}

// TestExecuteWorkflow_FuelCheckFail verifies that a workflow stops if out of fuel.
func TestExecuteWorkflow_FuelCheckFail(t *testing.T) {
	coordinator, mockProducer, db, mockDB := setupTest(t)
	defer db.Close()

	ctx := context.Background()
	correlationID := uuid.NewString()
	// Provide a low fuel budget.
	headers := map[string]string{"correlation_id": correlationID, governance.FuelHeader: "5"}

	plan := models.WorkflowPlan{
		StartStep: "step1",
		Steps: map[string]models.Step{
			// The cost of this action (50) is higher than the budget (5).
			"step1": {Action: "ai_text_generate_claude_opus", Topic: "topic.expensive"},
		},
	}

	rows := sqlmock.NewRows([]string{"correlation_id", "status", "current_step", "awaited_steps", "collected_data"}).
		AddRow(correlationID, StatusRunning, "step1", "[]", "{}")
	mockDB.ExpectQuery("SELECT .* FROM orchestrator_state WHERE correlation_id = ?").
		WithArgs(correlationID).
		WillReturnRows(rows)

	// Expect an UPDATE to set the state to FAILED.
	mockDB.ExpectExec("UPDATE orchestrator_state SET status = ?, error = ?").
		WithArgs(StatusFailed, sqlmock.AnyArg()).
		WillReturnResult(sqlmock.NewResult(1, 1))

	err := coordinator.ExecuteWorkflow(ctx, plan, headers, nil)
	require.Error(t, err)
	assert.Contains(t, err.Error(), "insufficient fuel")

	mockProducer.AssertNotCalled(t, "Produce")
	require.NoError(t, mockDB.ExpectationsWereMet())
}

// TestHandleFanOut verifies that multiple messages are sent in parallel.
func TestHandleFanOut(t *testing.T) {
	coordinator, mockProducer, db, mockDB := setupTest(t)
	defer db.Close()

	ctx := context.Background()
	correlationID := uuid.NewString()
	headers := map[string]string{
		"correlation_id":      correlationID,
		"request_id":          "parent_req_1",
		governance.FuelHeader: "1000",
	}

	step := models.Step{
		Action:   "fan_out",
		NextStep: "aggregate_results",
		SubTasks: []models.SubTask{
			{StepName: "get_research", Topic: "topic.research"},
			{StepName: "get_style", Topic: "topic.style"},
		},
	}
	state := &OrchestrationState{CorrelationID: correlationID}
	repo := NewStateRepository(db, zap.NewNop())

	// Expect a message to be produced to each sub-task topic.
	mockProducer.On("Produce", ctx, "topic.research", mock.Anything, mock.Anything, mock.Anything).Return(nil).Once()
	mockProducer.On("Produce", ctx, "topic.style", mock.Anything, mock.Anything, mock.Anything).Return(nil).Once()

	// Expect the state to be updated to AWAITING_RESPONSES with the correct next step.
	mockDB.ExpectExec(regexp.QuoteMeta("UPDATE orchestrator_state SET status = ?, current_step = ?, awaited_steps = ?")).
		WithArgs(StatusAwaitingResponses, "aggregate_results", mock.Anything).
		WillReturnResult(sqlmock.NewResult(1, 1))

	err := coordinator.handleFanOut(ctx, headers, step, state, repo)
	require.NoError(t, err)

	mockProducer.AssertExpectations(t)
	require.NoError(t, mockDB.ExpectationsWereMet())
}
-------------------------------------------------
filepath = ./platform/orchestration/coordinator.go
// FILE: platform/orchestration/coordinator.go
package orchestration

import (
	"context"
	"database/sql"
	"encoding/json"
	"fmt"
	"strconv"

	"github.com/google/uuid"
	"github.com/gqls/ai-persona-system/pkg/models"
	"github.com/gqls/ai-persona-system/platform/governance"
	"github.com/gqls/ai-persona-system/platform/kafka"
	"go.uber.org/zap"
)

const (
	// Topic for notifications to the UI
	NotificationTopic = "system.notifications.ui"
	// Topic for receiving resume commands
	ResumeWorkflowTopic = "system.commands.workflow.resume"
)

// SagaCoordinator manages the execution of complex workflows
type SagaCoordinator struct {
	db          *sql.DB
	producer    kafka.Producer
	logger      *zap.Logger
	fuelManager *governance.FuelManager
}

// NewSagaCoordinator creates a new coordinator instance
func NewSagaCoordinator(db *sql.DB, producer kafka.Producer, logger *zap.Logger) *SagaCoordinator {
	return &SagaCoordinator{
		db:          db,
		producer:    producer,
		logger:      logger,
		fuelManager: governance.NewFuelManager(),
	}
}

// ExecuteWorkflow manages the execution of a workflow plan
func (s *SagaCoordinator) ExecuteWorkflow(ctx context.Context, plan models.WorkflowPlan, headers map[string]string, initialData []byte) error {
	correlationID := headers["correlation_id"]
	l := s.logger.With(zap.String("correlation_id", correlationID))

	// Get or create state
	state, err := s.getOrCreateState(ctx, correlationID, plan, initialData)
	if err != nil {
		return err
	}

	// Check if workflow is already complete
	if state.Status == StatusCompleted || state.Status == StatusFailed {
		l.Info("Workflow already finished", zap.String("status", string(state.Status)))
		return nil
	}

	// Get current step configuration
	currentStepConfig, ok := plan.Steps[state.CurrentStep]
	if !ok {
		return s.failWorkflow(ctx, state, fmt.Sprintf("step '%s' not found in plan", state.CurrentStep))
	}

	// Check dependencies
	if !s.dependenciesMet(currentStepConfig.Dependencies, state) {
		l.Info("Dependencies not met, waiting", zap.Strings("dependencies", currentStepConfig.Dependencies))
		return nil
	}

	// Check fuel budget
	fuel, err := governance.GetFuelFromHeader(headers)
	if err != nil {
		return s.failWorkflow(ctx, state, fmt.Sprintf("failed to get fuel from headers: %v", err))
	}

	if !s.fuelManager.HasEnoughFuel(fuel, currentStepConfig.Action) {
		return s.failWorkflow(ctx, state, fmt.Sprintf("insufficient fuel for action '%s': have %d, need %d",
			currentStepConfig.Action, fuel, s.fuelManager.GetCost(currentStepConfig.Action)))
	}

	// Deduct fuel and update headers
	remainingFuel := s.fuelManager.DeductFuel(fuel, currentStepConfig.Action)
	governance.SetFuelHeader(headers, remainingFuel)

	// Execute the action
	switch currentStepConfig.Action {
	case "fan_out":
		return s.handleFanOut(ctx, headers, currentStepConfig, state)
	case "pause_for_human_input":
		return s.handlePauseForHumanInput(ctx, headers, currentStepConfig, state)
	case "complete_workflow":
		return s.completeWorkflow(ctx, state)
	default:
		return s.handleStandardAction(ctx, headers, currentStepConfig, state)
	}
}

// getOrCreateState retrieves existing state or creates new one
func (s *SagaCoordinator) getOrCreateState(ctx context.Context, correlationID string, plan models.WorkflowPlan, initialData []byte) (*OrchestrationState, error) {
	repo := NewStateRepository(s.db, s.logger)

	state, err := repo.GetState(ctx, correlationID)
	if err != nil {
		// State doesn't exist, create it
		if err := repo.CreateInitialState(ctx, correlationID, plan.StartStep, initialData); err != nil {
			return nil, fmt.Errorf("failed to create initial state: %w", err)
		}
		return repo.GetState(ctx, correlationID)
	}

	return state, nil
}

// dependenciesMet checks if all required dependencies have been completed
func (s *SagaCoordinator) dependenciesMet(dependencies []string, state *OrchestrationState) bool {
	for _, dep := range dependencies {
		if _, ok := state.CollectedData[dep]; !ok {
			return false
		}
	}
	return true
}

// handleStandardAction sends a message to the specified topic
func (s *SagaCoordinator) handleStandardAction(ctx context.Context, headers map[string]string, step models.Step, state *OrchestrationState) error {
	l := s.logger.With(zap.String("correlation_id", state.CorrelationID))

	// Prepare the message payload
	payload := models.TaskRequest{
		Action: step.Action,
		Data:   state.CollectedData,
	}
	payloadBytes, _ := json.Marshal(payload)

	// Create new request ID for this sub-task
	newRequestID := uuid.NewString()
	outHeaders := make(map[string]string)
	for k, v := range headers {
		outHeaders[k] = v
	}
	outHeaders["causation_id"] = headers["request_id"]
	outHeaders["request_id"] = newRequestID

	// Send the message
	if err := s.producer.Produce(ctx, step.Topic, outHeaders, []byte(state.CorrelationID), payloadBytes); err != nil {
		return fmt.Errorf("failed to produce message: %w", err)
	}

	// Update state to await response
	state.Status = StatusAwaitingResponses
	state.CurrentStep = step.NextStep
	state.AwaitedSteps = []string{newRequestID}

	repo := NewStateRepository(s.db, s.logger)
	if err := repo.UpdateState(ctx, state); err != nil {
		return fmt.Errorf("failed to update state: %w", err)
	}

	l.Info("Standard action executed", zap.String("action", step.Action), zap.String("topic", step.Topic))
	return nil
}

// handleFanOut sends multiple parallel requests
func (s *SagaCoordinator) handleFanOut(ctx context.Context, headers map[string]string, step models.Step, state *OrchestrationState) error {
	l := s.logger.With(zap.String("correlation_id", state.CorrelationID))

	awaitedSteps := make([]string, 0, len(step.SubTasks))

	for _, subTask := range step.SubTasks {
		payload := models.TaskRequest{
			Action: subTask.StepName,
			Data:   state.CollectedData,
		}
		payloadBytes, _ := json.Marshal(payload)

		newRequestID := uuid.NewString()
		outHeaders := make(map[string]string)
		for k, v := range headers {
			outHeaders[k] = v
		}
		outHeaders["causation_id"] = headers["request_id"]
		outHeaders["request_id"] = newRequestID

		if err := s.producer.Produce(ctx, subTask.Topic, outHeaders, []byte(state.CorrelationID), payloadBytes); err != nil {
			return fmt.Errorf("failed to produce fan-out message: %w", err)
		}

		awaitedSteps = append(awaitedSteps, newRequestID)
	}

	// Update state
	state.Status = StatusAwaitingResponses
	state.CurrentStep = step.NextStep
	state.AwaitedSteps = awaitedSteps

	repo := NewStateRepository(s.db, s.logger)
	if err := repo.UpdateState(ctx, state); err != nil {
		return fmt.Errorf("failed to update state: %w", err)
	}

	l.Info("Fan-out executed", zap.Int("subtasks", len(step.SubTasks)))
	return nil
}

// handlePauseForHumanInput pauses the workflow and notifies the UI
func (s *SagaCoordinator) handlePauseForHumanInput(ctx context.Context, headers map[string]string, step models.Step, state *OrchestrationState) error {
	l := s.logger.With(zap.String("correlation_id", state.CorrelationID))

	state.Status = StatusPausedForHuman
	state.CurrentStep = step.NextStep

	repo := NewStateRepository(s.db, s.logger)
	if err := repo.UpdateState(ctx, state); err != nil {
		return fmt.Errorf("failed to update state: %w", err)
	}

	// Send notification
	notification := map[string]interface{}{
		"event_type":      "WORKFLOW_PAUSED_FOR_APPROVAL",
		"correlation_id":  state.CorrelationID,
		"project_id":      headers["project_id"],
		"client_id":       headers["client_id"],
		"message":         fmt.Sprintf("Step '%s' requires your approval", step.Description),
		"data_for_review": state.CollectedData,
	}
	notificationBytes, _ := json.Marshal(notification)

	if err := s.producer.Produce(ctx, NotificationTopic, headers, []byte(state.CorrelationID), notificationBytes); err != nil {
		return fmt.Errorf("failed to send notification: %w", err)
	}

	l.Info("Workflow paused for human input")
	return nil
}

// HandleResponse processes a response from a sub-task
func (s *SagaCoordinator) HandleResponse(ctx context.Context, headers map[string]string, response []byte) error {
	correlationID := headers["correlation_id"]
	causationID := headers["causation_id"]

	l := s.logger.With(
		zap.String("correlation_id", correlationID),
		zap.String("causation_id", causationID),
	)

	repo := NewStateRepository(s.db, s.logger)
	state, err := repo.GetState(ctx, correlationID)
	if err != nil {
		return fmt.Errorf("failed to get state: %w", err)
	}

	// Parse response
	var taskResponse models.TaskResponse
	if err := json.Unmarshal(response, &taskResponse); err != nil {
		return fmt.Errorf("failed to unmarshal response: %w", err)
	}

	// Store response data
	state.CollectedData[causationID] = taskResponse.Data

	// Remove from awaited steps
	newAwaitedSteps := make([]string, 0)
	for _, step := range state.AwaitedSteps {
		if step != causationID {
			newAwaitedSteps = append(newAwaitedSteps, step)
		}
	}
	state.AwaitedSteps = newAwaitedSteps

	// If all responses received, set status back to running
	if len(state.AwaitedSteps) == 0 {
		state.Status = StatusRunning
	}

	if err := repo.UpdateState(ctx, state); err != nil {
		return fmt.Errorf("failed to update state: %w", err)
	}

	l.Info("Response processed", zap.Int("remaining_awaited", len(state.AwaitedSteps)))

	// If all responses received, continue workflow
	if len(state.AwaitedSteps) == 0 {
		// Need to reload the workflow plan - this would come from the agent config
		// For now, we'll need to pass it through somehow
		// This is a limitation we'll address in the actual implementation
	}

	return nil
}

// ResumeWorkflow resumes a paused workflow after human input
func (s *SagaCoordinator) ResumeWorkflow(ctx context.Context, headers map[string]string, resumeData []byte) error {
	correlationID := headers["correlation_id"]
	l := s.logger.With(zap.String("correlation_id", correlationID))

	var resumePayload struct {
		Approved bool                   `json:"approved"`
		Feedback map[string]interface{} `json:"feedback,omitempty"`
	}
	if err := json.Unmarshal(resumeData, &resumePayload); err != nil {
		return fmt.Errorf("failed to unmarshal resume payload: %w", err)
	}

	repo := NewStateRepository(s.db, s.logger)
	state, err := repo.GetState(ctx, correlationID)
	if err != nil {
		return fmt.Errorf("failed to get state: %w", err)
	}

	if state.Status != StatusPausedForHuman {
		return fmt.Errorf("workflow not in paused state: %s", state.Status)
	}

	if !resumePayload.Approved {
		state.Status = StatusFailed
		state.Error = "Workflow rejected by user"
		return repo.UpdateState(ctx, state)
	}

	// Add feedback to collected data
	if resumePayload.Feedback != nil {
		state.CollectedData["human_feedback"] = resumePayload.Feedback
	}

	state.Status = StatusRunning
	if err := repo.UpdateState(ctx, state); err != nil {
		return fmt.Errorf("failed to update state: %w", err)
	}

	l.Info("Workflow resumed after human approval")

	// Continue workflow execution
	// This would trigger re-execution with the current state

	return nil
}

// completeWorkflow marks the workflow as completed
func (s *SagaCoordinator) completeWorkflow(ctx context.Context, state *OrchestrationState) error {
	state.Status = StatusCompleted
	finalResult, _ := json.Marshal(state.CollectedData)
	state.FinalResult = finalResult

	repo := NewStateRepository(s.db, s.logger)
	return repo.UpdateState(ctx, state)
}

// failWorkflow marks the workflow as failed
func (s *SagaCoordinator) failWorkflow(ctx context.Context, state *OrchestrationState, errorMsg string) error {
	state.Status = StatusFailed
	state.Error = errorMsg

	repo := NewStateRepository(s.db, s.logger)
	return repo.UpdateState(ctx, state)
}
-------------------------------------------------
filepath = ./platform/orchestration/state.go
// FILE: platform/orchestration/state.go
package orchestration

import (
	"context"
	"database/sql"
	"encoding/json"
	"fmt"
	"time"

	"go.uber.org/zap"
)

// OrchestrationStatus represents the current state of a workflow
type OrchestrationStatus string

const (
	StatusRunning           OrchestrationStatus = "RUNNING"
	StatusAwaitingResponses OrchestrationStatus = "AWAITING_RESPONSES"
	StatusPausedForHuman    OrchestrationStatus = "PAUSED_FOR_HUMAN_INPUT"
	StatusCompleted         OrchestrationStatus = "COMPLETED"
	StatusFailed            OrchestrationStatus = "FAILED"
)

// OrchestrationState is the database model for a Saga instance
type OrchestrationState struct {
	CorrelationID      string                 `db:"correlation_id"`
	Status             OrchestrationStatus    `db:"status"`
	CurrentStep        string                 `db:"current_step"`
	AwaitedSteps       []string               `db:"awaited_steps"`
	CollectedData      map[string]interface{} `db:"collected_data"`
	InitialRequestData json.RawMessage        `db:"initial_request_data"`
	FinalResult        json.RawMessage        `db:"final_result"`
	Error              string                 `db:"error"`
	CreatedAt          time.Time              `db:"created_at"`
	UpdatedAt          time.Time              `db:"updated_at"`
}

// StateRepository provides an interface for persisting and retrieving workflow state
type StateRepository struct {
	db     *sql.DB
	logger *zap.Logger
}

// NewStateRepository creates a new state repository
func NewStateRepository(db *sql.DB, logger *zap.Logger) *StateRepository {
	return &StateRepository{db: db, logger: logger}
}

// CreateInitialState creates a new record for a workflow
func (r *StateRepository) CreateInitialState(ctx context.Context, correlationID, startStep string, initialData []byte) error {
	awaitedStepsJSON, _ := json.Marshal([]string{})
	collectedDataJSON, _ := json.Marshal(map[string]interface{}{})

	query := `
        INSERT INTO orchestrator_state 
        (correlation_id, status, current_step, awaited_steps, collected_data, initial_request_data, created_at, updated_at)
        VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
    `

	now := time.Now().UTC()
	_, err := r.db.ExecContext(ctx, query,
		correlationID, StatusRunning, startStep, awaitedStepsJSON, collectedDataJSON, initialData, now, now)

	if err != nil {
		r.logger.Error("Failed to create initial orchestration state", zap.Error(err))
		return fmt.Errorf("failed to create initial state: %w", err)
	}

	r.logger.Info("Initial orchestration state created", zap.String("correlation_id", correlationID))
	return nil
}

// GetState retrieves the current state of a workflow
func (r *StateRepository) GetState(ctx context.Context, correlationID string) (*OrchestrationState, error) {
	query := `
        SELECT correlation_id, status, current_step, awaited_steps, collected_data, 
               initial_request_data, COALESCE(final_result, '{}'), COALESCE(error, ''), created_at, updated_at
        FROM orchestrator_state
        WHERE correlation_id = $1
    `

	var state OrchestrationState
	var awaitedStepsJSON, collectedDataJSON []byte

	err := r.db.QueryRowContext(ctx, query, correlationID).Scan(
		&state.CorrelationID,
		&state.Status,
		&state.CurrentStep,
		&awaitedStepsJSON,
		&collectedDataJSON,
		&state.InitialRequestData,
		&state.FinalResult,
		&state.Error,
		&state.CreatedAt,
		&state.UpdatedAt,
	)

	if err != nil {
		if err == sql.ErrNoRows {
			return nil, fmt.Errorf("state not found for correlation_id: %s", correlationID)
		}
		return nil, fmt.Errorf("failed to get state: %w", err)
	}

	// Unmarshal JSON fields
	if err := json.Unmarshal(awaitedStepsJSON, &state.AwaitedSteps); err != nil {
		return nil, fmt.Errorf("failed to unmarshal awaited_steps: %w", err)
	}
	if err := json.Unmarshal(collectedDataJSON, &state.CollectedData); err != nil {
		return nil, fmt.Errorf("failed to unmarshal collected_data: %w", err)
	}

	return &state, nil
}

// UpdateState persists changes to a workflow's state
func (r *StateRepository) UpdateState(ctx context.Context, state *OrchestrationState) error {
	awaitedStepsJSON, _ := json.Marshal(state.AwaitedSteps)
	collectedDataJSON, _ := json.Marshal(state.CollectedData)

	query := `
        UPDATE orchestrator_state 
        SET status = $2, current_step = $3, awaited_steps = $4, collected_data = $5, 
            final_result = $6, error = $7, updated_at = $8
        WHERE correlation_id = $1
    `

	_, err := r.db.ExecContext(ctx, query,
		state.CorrelationID,
		state.Status,
		state.CurrentStep,
		awaitedStepsJSON,
		collectedDataJSON,
		state.FinalResult,
		state.Error,
		time.Now().UTC(),
	)

	if err != nil {
		r.logger.Error("Failed to update orchestration state", zap.Error(err))
		return fmt.Errorf("failed to update state: %w", err)
	}

	r.logger.Debug("Orchestration state updated",
		zap.String("correlation_id", state.CorrelationID),
		zap.String("status", string(state.Status)))
	return nil
}

// GetOrchestratorStateTableSchema returns the SQL for creating the state table
func GetOrchestratorStateTableSchema() string {
	return `
CREATE TABLE IF NOT EXISTS orchestrator_state (
    correlation_id UUID PRIMARY KEY,
    status VARCHAR(50) NOT NULL,
    current_step VARCHAR(255) NOT NULL,
    awaited_steps JSONB DEFAULT '[]',
    collected_data JSONB DEFAULT '{}',
    initial_request_data JSONB,
    final_result JSONB,
    error TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

CREATE INDEX idx_orchestrator_state_status ON orchestrator_state(status);
CREATE INDEX idx_orchestrator_state_updated_at ON orchestrator_state(updated_at);
`
}
-------------------------------------------------
filepath = ./platform/governance/fuel.go
// FILE: platform/governance/fuel.go
package governance

import (
	"fmt"
	"strconv"
)

const (
	// FuelHeader is the standard Kafka message header key for the fuel budget
	FuelHeader = "fuel_budget"
)

// CostTable defines the "price" in fuel units for various agent actions
var CostTable = map[string]int{
	"default_step":                   1,
	"fan_out":                        5,
	"ai_text_generate_claude_haiku":  10,
	"ai_text_generate_claude_sonnet": 25,
	"ai_text_generate_claude_opus":   50,
	"ai_image_generate_sdxl":         40,
	"web_search":                     5,
	"database_query":                 1,
	"memory_store":                   2,
	"memory_search":                  2,
	"pause_for_human_input":          0, // No cost for waiting
}

// FuelManager provides methods for checking and managing task fuel
type FuelManager struct{}

// NewFuelManager creates a new fuel manager
func NewFuelManager() *FuelManager {
	return &FuelManager{}
}

// GetCost returns the fuel cost for a given action
func (fm *FuelManager) GetCost(action string) int {
	if cost, ok := CostTable[action]; ok {
		return cost
	}
	// Return a default cost if the specific action isn't priced
	return CostTable["default_step"]
}

// HasEnoughFuel checks if the current budget is sufficient for an action
func (fm *FuelManager) HasEnoughFuel(currentFuel int, action string) bool {
	cost := fm.GetCost(action)
	return currentFuel >= cost
}

// DeductFuel subtracts the cost of an action from the current budget
func (fm *FuelManager) DeductFuel(currentFuel int, action string) int {
	cost := fm.GetCost(action)
	return currentFuel - cost
}

// GetFuelFromHeader safely parses the fuel value from Kafka message headers
func GetFuelFromHeader(headers map[string]string) (int, error) {
	fuelStr, ok := headers[FuelHeader]
	if !ok {
		return 0, fmt.Errorf("'%s' header not found", FuelHeader)
	}
	fuel, err := strconv.Atoi(fuelStr)
	if err != nil {
		return 0, fmt.Errorf("invalid fuel value in header: %w", err)
	}
	return fuel, nil
}

// SetFuelHeader sets the fuel budget in the headers map
func SetFuelHeader(headers map[string]string, fuel int) {
	headers[FuelHeader] = strconv.Itoa(fuel)
}
-------------------------------------------------
filepath = ./platform/database/migrations/001_enable_pgvector.sql
-- FILE: platform/database/migrations/001_enable_pgvector.sql
-- Run this on the clients database as superuser
CREATE EXTENSION IF NOT EXISTS vector;
-------------------------------------------------
filepath = ./platform/database/migrations/003_create_client_schema.sql
-- FILE: platform/database/migrations/003_create_client_schema.sql
-- This should be run for each new client
-- Replace {client_id} with actual client ID

CREATE SCHEMA IF NOT EXISTS client_{client_id};

-- Agent instances table
CREATE TABLE IF NOT EXISTS client_{client_id}.agent_instances (
                                                                  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    template_id UUID NOT NULL,
    owner_user_id VARCHAR(255) NOT NULL,
    name VARCHAR(255) NOT NULL,
    config JSONB NOT NULL DEFAULT '{}',
    is_active BOOLEAN DEFAULT true,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
    );

CREATE INDEX idx_instances_owner ON client_{client_id}.agent_instances(owner_user_id);
CREATE INDEX idx_instances_template ON client_{client_id}.agent_instances(template_id);

-- Agent memory table with vector support
CREATE TABLE IF NOT EXISTS client_{client_id}.agent_memory (
                                                               id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    agent_instance_id UUID NOT NULL REFERENCES client_{client_id}.agent_instances(id),
    content TEXT NOT NULL,
    embedding vector(1536) NOT NULL,
    metadata JSONB DEFAULT '{}',
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
    );

-- Create vector index for similarity search
CREATE INDEX ON client_{client_id}.agent_memory USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);

-- Orchestrator state table
CREATE TABLE IF NOT EXISTS client_{client_id}.orchestrator_state (
                                                                     correlation_id UUID PRIMARY KEY,
                                                                     status VARCHAR(50) NOT NULL,
    current_step VARCHAR(255) NOT NULL,
    awaited_steps JSONB DEFAULT '[]',
    collected_data JSONB DEFAULT '{}',
    initial_request_data JSONB,
    final_result JSONB,
    error TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
    );

CREATE INDEX idx_orchestrator_status ON client_{client_id}.orchestrator_state(status);
-------------------------------------------------
filepath = ./platform/database/migrations/004_auth_schema.sql
-- FILE: platform/database/migrations/004_auth_schema.sql
-- Auth database schema
CREATE TABLE IF NOT EXISTS users (
                                     id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    email VARCHAR(255) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    role VARCHAR(50) DEFAULT 'user',
    client_id VARCHAR(100) NOT NULL,
    subscription_tier VARCHAR(50) DEFAULT 'free',
    is_active BOOLEAN DEFAULT true,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
    );

CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_users_client ON users(client_id);

CREATE TABLE IF NOT EXISTS auth_tokens (
                                           id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES users(id),
    token_hash VARCHAR(255) NOT NULL,
    expires_at TIMESTAMPTZ NOT NULL,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
    );

CREATE INDEX idx_tokens_user ON auth_tokens(user_id);
CREATE INDEX idx_tokens_expires ON auth_tokens(expires_at);-------------------------------------------------
filepath = ./platform/database/migrations/002_create_templates_schema.sql
-- FILE: platform/database/migrations/002_create_templates_schema.sql
-- Templates database schema
CREATE TABLE IF NOT EXISTS persona_templates (
                                                 id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(255) NOT NULL,
    description TEXT,
    category VARCHAR(100),
    config JSONB NOT NULL DEFAULT '{}',
    is_active BOOLEAN DEFAULT true,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
    );

CREATE INDEX idx_templates_category ON persona_templates(category);
CREATE INDEX idx_templates_active ON persona_templates(is_active);
-------------------------------------------------
filepath = ./platform/database/postgres.go
// FILE: platform/database/postgres.go
package database

import (
	"context"
	"fmt"
	"os"
	"time"

	"github.com/gqls/ai-persona-system/platform/config"
	"github.com/jackc/pgx/v5/pgxpool"
	"go.uber.org/zap"
)

// NewPostgresConnection creates a new PostgreSQL connection pool with retry logic
func NewPostgresConnection(ctx context.Context, dbCfg config.DatabaseConfig, logger *zap.Logger) (*pgxpool.Pool, error) {
	password := os.Getenv(dbCfg.PasswordEnvVar)
	if password == "" {
		return nil, fmt.Errorf("database password environment variable %s is not set", dbCfg.PasswordEnvVar)
	}

	connStr := fmt.Sprintf("postgresql://%s:%s@%s:%d/%s?sslmode=%s",
		dbCfg.User, password, dbCfg.Host, dbCfg.Port, dbCfg.DBName, dbCfg.SSLMode)

	poolConfig, err := pgxpool.ParseConfig(connStr)
	if err != nil {
		return nil, fmt.Errorf("failed to parse postgres connection string: %w", err)
	}

	poolConfig.MaxConns = 10
	poolConfig.MinConns = 2
	poolConfig.MaxConnLifetime = time.Hour
	poolConfig.MaxConnIdleTime = 30 * time.Minute

	var pool *pgxpool.Pool
	for i := 0; i < 5; i++ {
		pool, err = pgxpool.NewWithConfig(ctx, poolConfig)
		if err == nil {
			pingCtx, cancel := context.WithTimeout(ctx, 5*time.Second)
			defer cancel()
			if err = pool.Ping(pingCtx); err == nil {
				logger.Info("Successfully connected to PostgreSQL database.", zap.String("database", dbCfg.DBName))
				return pool, nil
			}
		}
		logger.Warn("Failed to connect to PostgreSQL, retrying...",
			zap.Int("attempt", i+1),
			zap.String("database", dbCfg.DBName),
			zap.Error(err),
		)
		time.Sleep(5 * time.Second)
	}

	return nil, fmt.Errorf("failed to connect to postgres after multiple attempts: %w", err)
}
-------------------------------------------------
filepath = ./platform/database/mysql.go
// FILE: platform/database/mysql.go
package database

import (
	"context"
	"database/sql"
	"fmt"
	"os"
	"time"

	_ "github.com/go-sql-driver/mysql"
	"github.com/gqls/ai-persona-system/platform/config"
	"go.uber.org/zap"
)

// NewMySQLConnection creates a new MySQL database connection pool with retry logic
func NewMySQLConnection(ctx context.Context, dbCfg config.DatabaseConfig, logger *zap.Logger) (*sql.DB, error) {
	password := os.Getenv(dbCfg.PasswordEnvVar)
	if password == "" {
		return nil, fmt.Errorf("database password environment variable %s is not set", dbCfg.PasswordEnvVar)
	}

	// DSN format for MySQL
	dsn := fmt.Sprintf("%s:%s@tcp(%s:%d)/%s?parseTime=true",
		dbCfg.User, password, dbCfg.Host, dbCfg.Port, dbCfg.DBName)

	var db *sql.DB
	var err error

	// Retry loop for initial connection
	for i := 0; i < 5; i++ {
		db, err = sql.Open("mysql", dsn)
		if err == nil {
			pingCtx, cancel := context.WithTimeout(ctx, 5*time.Second)
			defer cancel()
			if err = db.PingContext(pingCtx); err == nil {
				// Set connection pool parameters
				db.SetMaxOpenConns(10)
				db.SetMaxIdleConns(5)
				db.SetConnMaxLifetime(time.Hour)

				logger.Info("Successfully connected to MySQL database.", zap.String("database", dbCfg.DBName))
				return db, nil
			}
		}
		logger.Warn("Failed to connect to MySQL, retrying...",
			zap.Int("attempt", i+1),
			zap.String("database", dbCfg.DBName),
			zap.Error(err),
		)
		time.Sleep(5 * time.Second)
	}

	return nil, fmt.Errorf("failed to connect to mysql after multiple attempts: %w", err)
}
-------------------------------------------------
filepath = ./platform/database/pgvector.go
// FILE: platform/database/pgvector.go
package database

import (
	"context"
	"fmt"

	"github.com/google/uuid"
	"github.com/jackc/pgx/v5/pgxpool"
	"github.com/pgvector/pgvector-go"
	"go.uber.org/zap"
)

// MemoryRecord represents a single entry in the agent_memory table
type MemoryRecord struct {
	ID              uuid.UUID
	AgentInstanceID uuid.UUID
	Content         string
	Embedding       []float32
	Metadata        map[string]interface{}
}

// MemoryRepository provides methods for storing and retrieving agent memories
type MemoryRepository struct {
	pool   *pgxpool.Pool
	logger *zap.Logger
}

// NewMemoryRepository creates a new repository for memory operations
func NewMemoryRepository(pool *pgxpool.Pool, logger *zap.Logger) *MemoryRepository {
	return &MemoryRepository{pool: pool, logger: logger}
}

// StoreMemory saves a new memory record to the database for a specific agent
func (r *MemoryRepository) StoreMemory(ctx context.Context, agentID uuid.UUID, content string, embedding []float32, metadata map[string]interface{}) error {
	l := r.logger.With(zap.String("agent_id", agentID.String()))
	l.Info("Storing new memory")

	query := `
        INSERT INTO agent_memory (agent_instance_id, content, embedding, metadata)
        VALUES ($1, $2, $3, $4)
    `
	_, err := r.pool.Exec(ctx, query, agentID, content, pgvector.NewVector(embedding), metadata)
	if err != nil {
		l.Error("Failed to store agent memory", zap.Error(err))
		return fmt.Errorf("failed to insert memory record: %w", err)
	}

	l.Debug("Successfully stored memory record")
	return nil
}

// SearchMemory performs a semantic similarity search to find the most relevant memories
func (r *MemoryRepository) SearchMemory(ctx context.Context, agentID uuid.UUID, queryEmbedding []float32, limit int) ([]MemoryRecord, error) {
	l := r.logger.With(zap.String("agent_id", agentID.String()))
	l.Info("Searching for relevant memories", zap.Int("limit", limit))

	query := `
        SELECT id, content, metadata
        FROM agent_memory
        WHERE agent_instance_id = $1
        ORDER BY embedding <=> $2
        LIMIT $3
    `
	rows, err := r.pool.Query(ctx, query, agentID, pgvector.NewVector(queryEmbedding), limit)
	if err != nil {
		l.Error("Failed to execute memory search query", zap.Error(err))
		return nil, fmt.Errorf("failed to search memory: %w", err)
	}
	defer rows.Close()

	var results []MemoryRecord
	for rows.Next() {
		var record MemoryRecord
		record.AgentInstanceID = agentID
		if err := rows.Scan(&record.ID, &record.Content, &record.Metadata); err != nil {
			l.Error("Failed to scan memory search result", zap.Error(err))
			continue
		}
		results = append(results, record)
	}

	l.Info("Memory search completed", zap.Int("results_found", len(results)))
	return results, nil
}
-------------------------------------------------
filepath = ./docker-compose.yaml
# FILE: docker-compose.yml
version: '3.8'

services:
  # Infrastructure
  kafka:
    image: confluentinc/cp-kafka:latest
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
    depends_on:
      - zookeeper

  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  postgres-clients:
    image: pgvector/pgvector:pg16
    environment:
      POSTGRES_DB: clients_db
      POSTGRES_USER: clients_user
      POSTGRES_PASSWORD: ${CLIENTS_DB_PASSWORD}
    volumes:
      - clients_data:/var/lib/postgresql/data

  postgres-templates:
    image: postgres:16
    environment:
      POSTGRES_DB: templates_db
      POSTGRES_USER: templates_user
      POSTGRES_PASSWORD: ${TEMPLATES_DB_PASSWORD}
    volumes:
      - templates_data:/var/lib/postgresql/data

  mysql-auth:
    image: mysql:8
    environment:
      MYSQL_DATABASE: auth_db
      MYSQL_USER: auth_user
      MYSQL_PASSWORD: ${AUTH_DB_PASSWORD}
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
    volumes:
      - auth_data:/var/lib/mysql

  minio:
    image: minio/minio:latest
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ACCESS_KEY}
      MINIO_ROOT_PASSWORD: ${MINIO_SECRET_KEY}
    volumes:
      - minio_data:/data

  # Core Services
  auth-service:
    build:
      context: .
      dockerfile: Dockerfile.auth-service
    environment:
      AUTH_DB_PASSWORD: ${AUTH_DB_PASSWORD}
      JWT_SECRET_KEY: ${JWT_SECRET_KEY}
    depends_on:
      - mysql-auth
    ports:
      - "8081:8081"

  core-manager:
    build:
      context: .
      dockerfile: Dockerfile.core-manager
    environment:
      CLIENTS_DB_PASSWORD: ${CLIENTS_DB_PASSWORD}
      TEMPLATES_DB_PASSWORD: ${TEMPLATES_DB_PASSWORD}
      MINIO_ACCESS_KEY: ${MINIO_ACCESS_KEY}
      MINIO_SECRET_KEY: ${MINIO_SECRET_KEY}
    depends_on:
      - postgres-clients
      - postgres-templates
      - kafka
    ports:
      - "8088:8088"

  # Agent Services
  agent-chassis:
    build:
      context: .
      dockerfile: Dockerfile.agent-chassis
    environment:
      CLIENTS_DB_PASSWORD: ${CLIENTS_DB_PASSWORD}
      TEMPLATES_DB_PASSWORD: ${TEMPLATES_DB_PASSWORD}
      MINIO_ACCESS_KEY: ${MINIO_ACCESS_KEY}
      MINIO_SECRET_KEY: ${MINIO_SECRET_KEY}
    depends_on:
      - postgres-clients
      - kafka
    deploy:
      replicas: 3

  reasoning-agent:
    build:
      context: .
      dockerfile: Dockerfile.reasoning
    environment:
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY}
    depends_on:
      - kafka

volumes:
  clients_data:
  templates_data:
  auth_data:
  minio_data:-------------------------------------------------
filepath = ./outputtotext.sh
#!/bin/bash

output_file="resulttextoutput.txt"

# Clear or create the output file
> "$output_file"

find . -type f \
    -not \( -name "go.mod" -o -name "go.sum" -o -name "*.hcl" -o -name "*.tar" -o -name "*.log" -o -name "*.tfstate" -o -name "$output_file" \) \
    -not \( -name "*.tfstate.backup" -o -name "terraform.tfstate.*prod-cluster" \) \
		-not \( -name "persona-cli" -o -name "README.md" -o -name "create_persona.sql" -o -name "*.secret" -o -name "*-lock.json" -o -name "*.txt" \) \
    -not -path "*/\\.*/*" \
		-not -path "*/backup/*" \
		-not -path "*/images/*" \
		-not -path "*/frontend/build/*" \
		-not -path "*/frontend/node_modules/*" \
		-not -path "*/project3/*" \
		-not -path "*/docs/*" \
		-not -path "./projects/*" \
		-not -path "*/gateway/templates/*" \
		-not -path "*/strimzi-yaml-0.45.0/*" \
		-not -path "*/production/sydney/*" \
    -print0 | \
while IFS= read -r -d $'\0' file; do
    echo "filepath = $file" >> "$output_file" || { echo "Failed to write to $output_file"; exit 1; }
    cat "$file" >> "$output_file" || { echo "Failed to write to $output_file"; exit 1; }
    echo "-------------------------------------------------" >> "$output_file" || { echo "Failed to write to $output_file"; exit 1; }
done
-------------------------------------------------
